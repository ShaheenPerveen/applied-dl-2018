{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EDgSCpeOzpR8"
   },
   "source": [
    "# Tel-Aviv Deep Learning Boot-camp: 12 Applied Deep Learning Labs\n",
    "\n",
    "## Lab 0: Plant Seedlings Classification (PyTorch): The most basic lab :)  \n",
    "\n",
    "<img src=\"assets/seedlings.png\" align=\"center\">\n",
    "\n",
    "### Instructors:\n",
    "\n",
    "- Shlomo Kashani: shlomo@bayesian.io ,\n",
    "- Nathaniel Shimoni nathaniel.shimoni@grid4c.com \n",
    "\n",
    "<img src=\"assets/pt.jpg\" width=\"35%\" align=\"center\">\n",
    "\n",
    "## Progress\n",
    "\n",
    "- [x] PyTorch DataSet\n",
    "- [x] PyTorch DataLoader\n",
    "- [x] Augmentations\n",
    "- [x] Simple CNN\n",
    "- [x] Training + train test split\n",
    "- [x] TensorBoard Support from PyTorch\n",
    "- [x] Accuray and Log Loss\n",
    "- [x] Tqdm progress\n",
    "- [x] Persisting the model\n",
    "- [x] Testing on a test set\n",
    "\n",
    "\n",
    "\n",
    "### Links:\n",
    "\n",
    "- https://www.meetup.com/Tel-Aviv-Deep-Learning-Bootcamp/ \n",
    "- Git: https://github.com/bayesianio/applied-dl-2018\n",
    "- Full info: https://www.evernote.com/shard/s341/sh/3855640e-2b0b-42e5-b5b9-00216d02ac9a/b47968226e49a81ee813901cd41d3924\n",
    "\n",
    "### Date and Location: \n",
    "- July 2018\n",
    "\n",
    "\n",
    "### Requirements:\n",
    "- Python 3.5, CUDA 9, cuDNN 7, PyTorch 2.0 or above, Keras 2 or above\n",
    "\n",
    "#### For Windows 10 and Windows Server 2016, CUDA 9\n",
    "`conda install -c peterjc123 pytorch cuda90`\n",
    "\n",
    "\n",
    "### Data\n",
    "- Download: https://www.kaggle.com/c/plant-seedlings-classification\n",
    "\n",
    "- Please make sure you have already set up a Pytorch tree structure of your dataset:\n",
    "- `data_dir= '/home/data/bone/train/' `\n",
    "\n",
    "```\n",
    "    data_dir= '/home/data/bone/train/\n",
    "    \n",
    "    ├── valid\n",
    "    │   └── Type_1\n",
    "        ├── Type_2\n",
    "        └── Type_3\n",
    "    └── train\n",
    "        ├── Type_1\n",
    "        ├── Type_2\n",
    "        └── Type_3\n",
    "```\n",
    "\n",
    "### PyTorch Datasets\n",
    "\n",
    "To create a dataset, we subclass Dataset and define a constructor, a `__len__` method, and a `__getitem__` method. \n",
    "Here is full example:\n",
    "\n",
    "```python\n",
    "class BoneDataset(Dataset):\n",
    "    def __init__(self, labels, root_dir, subset=False, transform=None):\n",
    "        self.labels = labels\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.labels.iloc[idx, 0] # file name\n",
    "        fullname = join(self.root_dir, img_name)\n",
    "        image = Image.open(fullname).convert('RGB')\n",
    "        labels = self.labels.iloc[idx, 2] # category_id\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, labels\n",
    "```\n",
    "\n",
    "### The PyTorch DataLoader Class¶\n",
    "- Will load our BoneDataset\n",
    "- Can be regarded as a list (or iterator, technically).\n",
    "- Each time it is invoked will provide a minibatch of (img, label) pairs.\n",
    "\n",
    "\n",
    "### Training with TensorBoard\n",
    "\n",
    "With the aid of [Crayon](https://github.com/torrvision/crayon),\n",
    "we can access the visualisation power of TensorBoard for any \n",
    "deep learning framework.\n",
    "\n",
    "To use the TensorBoard, install Crayon (https://github.com/torrvision/crayon)\n",
    "and set `use_tensorboard = True`\n",
    "\n",
    "\n",
    "## Google Colab links:\n",
    "- https://medium.com/deep-learning-turkey/google-colab-free-gpu-tutorial-e113627b9f5d\n",
    "- https://jovianlin.io/pytorch-with-gpu-in-google-colab/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 105,
     "output_extras": [
      {
       "item_id": 4
      }
     ]
    },
    "colab_type": "code",
    "collapsed": true,
    "executionInfo": {
     "elapsed": 14961,
     "status": "ok",
     "timestamp": 1521474027916,
     "user": {
      "displayName": "Shlomo Kashani",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "110613709458758208639"
     },
     "user_tz": -120
    },
    "id": "t2YZ6BK06iNd",
    "outputId": "027cd22f-df7e-42cf-8190-870ce9d5e734"
   },
   "outputs": [],
   "source": [
    "# Google specific code\n",
    "\n",
    "# !pip3 install http://download.pytorch.org/whl/cu80/torch-0.3.0.post4-cp36-cp36m-linux_x86_64.whl \n",
    "# !pip3 install torchvision\n",
    "# !pip3 install tqdm\n",
    "\n",
    "# !apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
    "# !add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
    "# !apt-get update -qq 2>&1 > /dev/null\n",
    "# !apt-get -y install -qq google-drive-ocamlfuse fuse\n",
    "# from google.colab import auth\n",
    "# auth.authenticate_user()\n",
    "# from oauth2client.client import GoogleCredentials\n",
    "# creds = GoogleCredentials.get_application_default()\n",
    "# import getpass\n",
    "# !google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
    "# vcode = getpass.getpass()\n",
    "# !echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}\n",
    "\n",
    "# !mkdir -p med-drive\n",
    "# !google-drive-ocamlfuse med-drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 221,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 883,
     "status": "ok",
     "timestamp": 1521474180497,
     "user": {
      "displayName": "Shlomo Kashani",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "110613709458758208639"
     },
     "user_tz": -120
    },
    "id": "rmr9jTsazpR-",
    "outputId": "041c3cdd-b901-49c6-fc44-9c4a147cf089"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__Python VERSION: 3.6.2 |Anaconda custom (64-bit)| (default, Sep 19 2017, 08:03:39) [MSC v.1900 64 bit (AMD64)]\n",
      "__pyTorch VERSION: 0.3.1.post2\n",
      "__CUDA VERSION\n",
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2017 NVIDIA Corporation\n",
      "Built on Fri_Sep__1_21:08:32_Central_Daylight_Time_2017\n",
      "Cuda compilation tools, release 9.0, V9.0.176\n",
      "__CUDNN VERSION: 7003\n",
      "__Number CUDA Devices: 1\n",
      "__Devices\n",
      "Active CUDA Device: GPU 0\n",
      "Available devices  1\n",
      "Current cuda device  0\n",
      "USE CUDA=True\n"
     ]
    }
   ],
   "source": [
    "%reset -f \n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from shutil import copyfile\n",
    "from os.path import isfile, join, abspath, exists, isdir, expanduser\n",
    "from os import listdir, makedirs, getcwd, remove\n",
    "from PIL import Image\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as func\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets, models\n",
    "import random \n",
    "\n",
    "\n",
    "import sys\n",
    "print('__Python VERSION:', sys.version)\n",
    "print('__pyTorch VERSION:', torch.__version__)\n",
    "print('__CUDA VERSION')\n",
    "from subprocess import call\n",
    "# call([\"nvcc\", \"--version\"]) does not work\n",
    "! nvcc --version\n",
    "print('__CUDNN VERSION:', torch.backends.cudnn.version())\n",
    "print('__Number CUDA Devices:', torch.cuda.device_count())\n",
    "print('__Devices')\n",
    "# call([\"nvidia-smi\", \"--format=csv\", \"--query-gpu=index,name,driver_version,memory.total,memory.used,memory.free\"])\n",
    "print('Active CUDA Device: GPU', torch.cuda.current_device())\n",
    "\n",
    "print ('Available devices ', torch.cuda.device_count())\n",
    "print ('Current cuda device ', torch.cuda.current_device())\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "# use_cuda = False\n",
    "\n",
    "print(\"USE CUDA=\" + str (use_cuda))\n",
    "FloatTensor = torch.cuda.FloatTensor if use_cuda else torch.FloatTensor\n",
    "LongTensor = torch.cuda.LongTensor if use_cuda else torch.LongTensor\n",
    "Tensor = FloatTensor\n",
    "\n",
    "manualSeed = 2222\n",
    "def fixSeed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if use_cuda:\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "\n",
    "if manualSeed is None:\n",
    "        manualSeed = 999\n",
    "fixSeed(manualSeed)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 520,
     "output_extras": [
      {
       "item_id": 1
      },
      {
       "item_id": 2
      }
     ]
    },
    "colab_type": "code",
    "collapsed": true,
    "executionInfo": {
     "elapsed": 870,
     "status": "error",
     "timestamp": 1521473824394,
     "user": {
      "displayName": "Shlomo Kashani",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "110613709458758208639"
     },
     "user_tz": -120
    },
    "id": "0FfUc7TNzpSI",
    "outputId": "fc73b302-6037-4adc-e7af-cf9a49ac1007"
   },
   "outputs": [],
   "source": [
    "import os,sys,inspect\n",
    "currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parentdir = os.path.dirname(currentdir)\n",
    "sys.path.insert(0,parentdir) \n",
    "\n",
    "from kmodels import *\n",
    "from kdataset import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yHvMFEY0zpSJ"
   },
   "source": [
    "### Define Custom Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {},
      {}
     ]
    },
    "colab_type": "code",
    "id": "T2jcuWuYzpSL",
    "outputId": "2d841d05-260e-449f-e26d-5fdf69f18208"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Black-grass', 'Charlock', 'Cleavers', 'Common Chickweed', 'Common wheat', 'Fat Hen', 'Loose Silky-bent', 'Maize', 'Scentless Mayweed', 'Shepherds Purse', 'Small-flowered Cranesbill', 'Sugar beet']\n",
      "{'Black-grass': 0, 'Charlock': 1, 'Cleavers': 2, 'Common Chickweed': 3, 'Common wheat': 4, 'Fat Hen': 5, 'Loose Silky-bent': 6, 'Maize': 7, 'Scentless Mayweed': 8, 'Shepherds Purse': 9, 'Small-flowered Cranesbill': 10, 'Sugar beet': 11}\n",
      "{0: 'Black-grass', 1: 'Charlock', 2: 'Cleavers', 3: 'Common Chickweed', 4: 'Common wheat', 5: 'Fat Hen', 6: 'Loose Silky-bent', 7: 'Maize', 8: 'Scentless Mayweed', 9: 'Shepherds Purse', 10: 'Small-flowered Cranesbill', 11: 'Sugar beet'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>category</th>\n",
       "      <th>category_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Black-grass/0050f38b3.png</td>\n",
       "      <td>Black-grass</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Black-grass/0183fdf68.png</td>\n",
       "      <td>Black-grass</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Black-grass/0260cffa8.png</td>\n",
       "      <td>Black-grass</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Black-grass/05eedce4d.png</td>\n",
       "      <td>Black-grass</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Black-grass/075d004bc.png</td>\n",
       "      <td>Black-grass</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        file     category  category_id\n",
       "0  Black-grass/0050f38b3.png  Black-grass            0\n",
       "1  Black-grass/0183fdf68.png  Black-grass            0\n",
       "2  Black-grass/0260cffa8.png  Black-grass            0\n",
       "3  Black-grass/05eedce4d.png  Black-grass            0\n",
       "4  Black-grass/075d004bc.png  Black-grass            0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "dataset='seedlings' # bone , cat-dog   d:/db/data/cat-dog/train/ ISIC2017\n",
    "data_dir= 'd:/db/data/' +  dataset + '/train/'\n",
    "# data_dir_valid= 'd:/db/data/' +  dataset + '/valid/'\n",
    "\n",
    "classes, class_to_idx, num_to_class, df =GenericDataset.find_classes (data_dir )\n",
    "\n",
    "print (classes)\n",
    "print (class_to_idx)\n",
    "print (num_to_class)\n",
    "df.head(5)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {}
     ]
    },
    "colab_type": "code",
    "id": "kocQq6yLzpSN",
    "outputId": "8d66b443-5e8b-4c12-b38b-a0e4c3a5242c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aY-XSyxWzpSR"
   },
   "source": [
    "# Target distribution : Train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {},
      {}
     ]
    },
    "colab_type": "code",
    "id": "vNJsLwcEzpSR",
    "outputId": "beb4caeb-f462-46a9-94bd-55f47d2c89a1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Anaconda3\\lib\\site-packages\\seaborn\\categorical.py:1460: FutureWarning: remove_na is deprecated and is a private function. Do not use.\n",
      "  stat_data = remove_na(group_data)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABJAAAAH9CAYAAABFgoYKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAcvi2fpgAloaAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1ce14d5b470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.set(color_codes=True)\n",
    "pal = sns.color_palette()\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "labels = df['category'].apply(lambda x: x.split(' '))\n",
    "from collections import Counter, defaultdict\n",
    "counts = defaultdict(int)\n",
    "for l in labels:\n",
    "    for l2 in l:\n",
    "        counts[l2] += 1\n",
    "\n",
    "counts_df = pd.DataFrame.from_dict(counts, orient='index')\n",
    "counts_df.columns = ['count']\n",
    "counts_df.sort_values('count', ascending=False, inplace=True)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax = sns.barplot(x=counts_df.index, y=counts_df['count'], ax=ax)\n",
    "fig.set_size_inches(20,8)\n",
    "ax.set_xticklabels(ax.xaxis.get_majorticklabels(), rotation=-45);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8pPClZv8zpSW"
   },
   "source": [
    "# Augmentation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "ij6OFiLBzpSW"
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "\n",
    "from torchvision.transforms import *\n",
    "\n",
    "from PIL import Image, ImageDraw\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import torchvision\n",
    "import random\n",
    "from PIL import Image, ImageOps\n",
    "import numpy as np\n",
    "import numbers\n",
    "import math\n",
    "import torch\n",
    "import torch\n",
    "import random\n",
    "import PIL.ImageEnhance as ie\n",
    "import PIL.Image as im\n",
    "\n",
    "# adapted from https://github.com/kuangliu/pytorch-retinanet/blob/master/transform.py\n",
    "# https://github.com/mratsim/Amazon-Forest-Computer-Vision/blob/master/src/p_data_augmentation.py\n",
    "\n",
    "normalize_img = torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "\n",
    "from ktransforms import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RmEroGFfzpSY"
   },
   "source": [
    "## Setup transforms, datasets, and dataloaders\n",
    "\n",
    "- Data loaders spit out data from a dataset in batches. This is what you actually feed the neural network during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {},
      {},
      {}
     ]
    },
    "colab_type": "code",
    "id": "38MhTpO4zpSY",
    "outputId": "d94a5935-288a-4bdd-d305-aacb4048b53e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': 4038, 'valid': 712}\n",
      "6     566\n",
      "3     513\n",
      "8     445\n",
      "10    421\n",
      "5     408\n",
      "1     327\n",
      "11    316\n",
      "2     247\n",
      "0     225\n",
      "9     202\n",
      "7     185\n",
      "4     183\n",
      "Name: category_id, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1ce0522d240>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD6CAYAAACxrrxPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nVGvLb6MAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1ce137434e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_size = 224\n",
    "\n",
    "normalize_img = torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "\n",
    "\n",
    "train_trans = transforms.Compose([\n",
    "    transforms.RandomSizedCrop(image_size),\n",
    "    PowerPIL(),\n",
    "    transforms.ToTensor(),\n",
    "#     normalize_img,\n",
    "    RandomErasing()\n",
    "])\n",
    "\n",
    "## Normalization only for validation and test\n",
    "valid_trans = transforms.Compose([\n",
    "    transforms.Scale(256),\n",
    "    transforms.CenterCrop(image_size),\n",
    "    transforms.ToTensor(),\n",
    "#     normalize_img\n",
    "])\n",
    "\n",
    "batch_size = 8\n",
    "train_data = df.sample(frac=0.85)\n",
    "valid_data = df[~df['file'].isin(train_data['file'])]\n",
    "\n",
    "train_set = GenericDataset(train_data, data_dir, transform = train_trans)\n",
    "valid_set = GenericDataset(valid_data, data_dir, transform = valid_trans)\n",
    "        \n",
    "\n",
    "t_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "v_loader = DataLoader(valid_set, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "# test_loader  = DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "dataset_sizes = {\n",
    "    'train': len(t_loader.dataset), \n",
    "    'valid': len(v_loader.dataset)\n",
    "}\n",
    "\n",
    "\n",
    "print (dataset_sizes)\n",
    "print (train_data[\"category_id\"].value_counts())\n",
    "\n",
    "train_data['category_id'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {},
      {}
     ]
    },
    "colab_type": "code",
    "id": "noA4FHS7zpSb",
    "outputId": "a514a7ec-d0ad-4be8-b43b-8baca8882e3b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1ce130c95c0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD6CAYAAACxrrxPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAwOhQ4ARlDoAGAEhQ4ARlDoAGDE/wFSsvqZcViSgQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1ce130c9518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "valid_data['category_id'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f53b3rbpzpSg"
   },
   "source": [
    "### Test the DataLoader Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {},
      {}
     ]
    },
    "colab_type": "code",
    "id": "o6o2BlVMzpSh",
    "outputId": "4e1095e8-b70b-407f-ffd3-3425f6bfa919"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i=0: \n",
      "i=1: \n",
      "i=2: \n",
      "i=3: \n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZ4AAABtCAYAAACRDQcMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJzsvXmwpWlV7vl7p+/79nSGzJNZmTVX\nQRVwxWrFC1dvweUWFFEohaWhKJMaTI0RKCEBahFi0IYlERqG8oe0A2IYKoEhEli2dYlQRLqR27ca\nZCyggKKmnM/JM+3pG95h9R/vzqP0FegioPKYnicjIzL32cN33rX3u9611vM8W4mIcIADHOAABzjA\n4wR9sS/gAAc4wAEO8O8LB4nnAAc4wAEO8LjiIPEc4AAHOMABHlccJJ4DHOAABzjA44qDxHOAAxzg\nAAd4XHGQeA5wgAMc4ACPK/Zd4vnUpz7FT/zET/DCF76Q22+/nVe/+tV8+ctfflxe+0lPehJbW1uP\n+XGvetWrePDBB+m6jttuuw2AGCO/9mu/xvOf/3ye97zn8Z73vOdbfbmPOy6V2FzAmTNneNaznvVN\nPe9+xKUSn6ZpePOb38ztt9/OC17wAt785jfTNM23+pIfV1wqsZlMJrz+9a/n9ttv5wd+4Af4gz/4\ng2/uomQfoW1becYzniH33Xff3m1/9Vd/Jc9+9rMlhPBtf/0bb7xRNjc3H9NjvPfyvOc9T0RE7r33\nXnnTm94kIiJ/9md/Jq9+9avFey87Ozty2223yac//elv+TU/XriUYiMi8v73v19uueWWb+p59yMu\npfj81m/9lvz8z/+8xBglhCBveMMb5O1vf/u3/JofL1xKsfnVX/1Vueuuu0REZDabyS233CKf+MQn\nHvM12W8uXX17UNc1k8mE+Xy+d9sP/uAPMhwOiTGilOJtb3sbn/70p5nNZogId911F9/zPd/DnXfe\nSVVVfOlLX2Jzc5PnPOc5rKys8A//8A9sbGxw11138X3f933ceeedlGXJ/fffz+bmJjfffDNvectb\ncM591bW8973v5T3veQ8pJVZWVvjlX/5lnvCEJ3zVfV7zmtfw4IMPMp1OueOOOzh37hyDwYB3v/vd\nfPCDH+THfuzHsNayvLzMC17wAv76r/+am2666XFZy281LqXY3HrrrXzwgx/kXe96F89//vMfl/X7\nduNSis/Tn/50rrjiCrTODZmnPOUpPPDAA9/+Rfw24VKKzS/90i8RYwRgY2ODrusYjUaPfVEec6r6\nNuOP/uiP5KabbpLnPOc58qY3vUne+973ynw+FxGRT3ziE/KzP/uzEmMUEZHf//3fl9e+9rUiIvKL\nv/iL8qIXvUi6rpP19XW58cYb5U/+5E9EROSP//iP5RWveMXe/X7oh35IptOptG0rL3vZy+RP//RP\nReSfTwb33nuvvPSlL9173Y985CPy/Oc//1+93ne/+93ye7/3eyIi8rrXvU4+97nPiYjIbbfdJp/8\n5Cf37vcXf/EX8rrXve5bulaPNy6V2PxLXCoVj8ilGZ+TJ0/KzTffLB/60Ie+Vct0UXCpxeaNb3yj\nPPWpT5U3vOEN31TVtq8qHoBXvOIVvOhFL+JjH/sYH/vYx3jnO9/JO9/5Tv7yL/+S7/7u72Z5eZk/\n//M/58SJE9x7770MBoO9x95yyy045zhy5Aj9fp9nPetZAFx99dXs7Ozs3e+Hf/iH9x53xx138Pd/\n//e8/OUv3/v5hz/8YR555BFe/OIX7902Ho/Z2dlhZWXlq673/vvv59ZbbwXgy1/+Mk984hMBEBGU\nUnv3E5G9E9y/VVwqsblUcanF57777uNnfuZnePnLX84tt9zyLVqli4NLLTa/+Zu/ya/8yq/w+te/\nnne84x28/vWvf0zrsa92wn/6p3/iD//wDxkOh9xyyy38wi/8Avfccw9KKT760Y/y4Q9/mNe+9rUA\nPPe5z+UlL3nJVz2+KIqv+r+1/3peNcbs/ftfSwgpJe644w7uvvtu7r77bt7//vfzvve9j+Xl5a+6\n32te8xruvvtufuM3foPbb7+dc+fO8aIXvYh3v/vdHD9+nPX19b37rq+vc+zYsce+KPsEl1JsLkVc\navG55557eOUrX8kb3/hGfvqnf/qbW5R9gkspNh/5yEc4d+4cAIPBgBe84AV8/vOff8xrsq8Sz6FD\nh/jd3/1dPv7xj+/dtrGxwXQ65cYbb+SjH/0ot9xyCy996Ut56lOfygc/+MG9fuNjwQc+8AG6rqNt\nW97//vf/T6epZz7zmdxzzz17ieM973kPP/VTP/U/Pc/b3/52rrjiCv7mb/6Gn/u5n+NHf/RHufvu\nu3nZy17Gc5/7XN73vvcRQmA8HnPPPffsnSD+LeJSis2liEspPh/60Ie46667eNe73sULX/jCx3yN\n+w2XUmw+8IEP8I53vAMRoes6PvCBD/C93/u9j/la91Wr7brrruMd73gHv/3bv83Zs2cpy5LRaMTb\n3vY2rr/+el784hfzxje+kRe+8IWEELj55pv527/9W1JKj+l1qqripS99KePxmNtuu40f+ZEf+aqf\nP/OZz+Q1r3kNr3zlK1FKMRwO+Z3f+Z2vap1Bpkg+7WlPA+DjH/84T3/60/d+9pKXvIRHH32UO+64\nA+89P/7jP84znvGMb3JlLj4updhciriU4vPrv/7riAhvectb9m572tOexlvf+tbHuiz7ApdSbO68\n807e+ta37h0Ibr31Vn7yJ3/yMa+JEvn39bUId955JzfccAOvetWrLvalHOD/g4PY7G8cxGf/4t9a\nbPZVq+0ABzjAAQ5w6ePfXcVzgAMc4AAHuLg4qHgOcIADHOAAjysOEs8BDnCAAxzgccVFZbXddM0a\nIhCamqIqMbQsj3poW4KAMoqdnV26uqHQiaqsOH6kQpUlEYOJERUaCgtbs4JWl6QkFEZRFSWjlR5V\nf4n5dIsQa9bP7qKmW4x6JXOveHijYe34Ma697gm07ZRer4eKU44eKektr9LM5vSGBYNySNCakw+e\n4CufegA/n+DKCj0YsrV5nkOrqyijmDeGZDTWak6eOoOoimPXHEcSWGOot3foL/exVZ/gA07DA596\ngEfC/ut23va855OIKBTGOkIbUEqRJC5YMAqFIndqExf4N6KycLZrG+b1hNbXROnQGpRWhBBQThER\nQucprQMk/1UX1kFA66xDiBGlBZGIVhpBoZUmSYc2+RqUKI6uXsegHFK5gugjbVszn45JKFIApQGt\nkJRIMUDweD+nqgYobQGhKBbXkjwpCZKEv/0fj12j8O3Gf77xOmKICIL3kbbzhBhJRKp+Ra/fQyuF\nsoqq1wcFCjDGIiIkH4gxkGKgGvRQWqMEUkxond+/hTFoBc6UoBQxRlLKjwsxgKQcNcnrlEKOYUIT\nk4DR2LKP0gZlDAjE6HHWEaInSkIkkWIi+EwdbpoWUBitsaUDpVFG4VuP7zwhhPxYLyjRfPHEiYsY\nha+NH7/lu3AlOO24/4FTHJoFKusonDCvW7orlimKAe14ztplQ1ZXV/F1x2y2RYehrTUsDQhtS90k\nZtMZ9XSHwz1F6IR2INhrO3rasXJqwKFjl+GGS5x+5DRb586zdmxAf2mZMA1IaXC9VVyhCSJ86uP3\nsbvd8JQbDrPbRnbaCcPvAhUDoLDtkDQ19EYWp0ZoSRw5NGJJD4gp8o/3fIzVQvGU71xheycRl47R\nLxTbu3OUFIRmgnUVtgj81T9+bZuji5p4dDtDjMXpRFdPOLy6RDFYws/GoB0762fRts/q6ir9UYUr\nS8Y7OxxWLdY6ooo4Z+gioCMnHj5FfzTk8muuxs9aprtzvG8ROh76xEMoDSurJQ2Osij4D1eXSBFp\n5lOCBFTdQIx88TMPc/x6iyIxnQubrmX9zCZf+PRXKE3ECfRGlq2t85SmoKnn6HKALfuErsMqhetV\nxKDp2oC0nurQITyJs4+c4dDaIa645gqMqzhy69GLGYKvjZSIKWKsIYZAIqFVTh5GWaL3KGNBKZIk\nlAKVIEqibWu2d86jrBAlIEaofYd1Dm1BiaAFSufQSiGS2Bs1KkG0AhFSDOgF1TOJkCRhdH5NhUFQ\nJJUwCNvb5yiOlDjjCDESoyBoJCXQoLQmhYCxBiUG0RGiQBSUJAQhBA8iOTmJYKz7Ogt08dDWLUop\ntNGURUGKgtGGLnS08yn9foEre2ij8V2LVhpEiHRooxFJGGsoyh5a27zBKwWxw1qHsxalQCTShS4n\nqxTxvkMA3zYo9c9ixZSEtmmwrgItoMEVBWVR0HYtiZjPFkrhowdyIpQYiU2XNSvGYo0GUSitiN7j\nQyTGhHEGQdAKrDaYQuXn26eoz36F3nVPoes6nrRiUEnTtopZPaM6OmJnNiMlTVFpynqbxglnTm9R\nHD3OUA+plhTn188zrj3DwYjBKnSjHg/c/yhrT7DIFXN6coz+tM//+dmTHPnChGfc/j08cqZm3ERU\nXbA5nXDZ2oDJ9pwrD19OCFBYuPaJV2J1wVD1WElTeuc17YOWdj5ntV/hxVINVjhcWIJRNGHMI1sn\niWpOChXLNy0xnLRo5Th2dMB891EYPoXLr1jmH+/9MkoJyrdUUn/dNbqoiec5z7+Z6foJ0Ia69Tx6\ndk69u4XVICGw1B9Sra5gypLhYAnfTIlVRZRdVNKIMfjQsrHlacpDLK0GdBKqoiQYSwgdXQPNeBOl\n4fBIoxU0rafoG4yG7Y0tVoaXsTRaputqYggUS8tsnt+gCx2T9Tm704b+yHLs6BrDw0eJvkViB3VD\n77Jr0EETtAHfgFZsjce0VHTNjP5sjp91pDClXxY86XufRuMTrRcMCYnhYobgayKlfPrVaBKgTU4A\neYMOGKVJKSBAUnm/EaBr50znu2grJOVRRkhRKKz75xOyEozWi+QSURq0zlUQWpEERMindokggjVu\nb69JKYBe3AcDJCL51BxiIvpADPkEp40hkZOJdY4YIihIkrDGECXCIrlFHxa3a1BCTI9dxPd4IAbB\nOYsE8HnVcjJWCpKmC5HSKARZVDIeSSHrQpSiqvpopUgpkSQskr6idA5QhBgxOi+LNoYUAzuTCaFt\nEclrarQixkSMAcEQgqB8g3UW4ww6JLxtERIKTRJBLTr71jokJpKGqBN6UW0553L8U6KeN7R1s4iz\nJaWEJMG5AmMtKfiLGIGvj+Xjx/j4P93PcGmVy6++jNF8A5EZpnLMyx4jVZKkYW0oDG1CSkXZ7tJt\nQTx2PX4+J8xnHL3iKk49cpKnXLvKvG1ZvW6AunLMqFth+hXPNO1y+eUrtHXDf/vr/5vhqE/fOPqu\nYpYiuxvbtLHi0S99nv7SEc6e3uD4Ncfo95dJoilTxRVX9Vk/dYbLrr4ah/Doo2dZXz/NlcdvQEXL\nYalYTQajD9PGQOPHcNRw8vQOlx1JmGqA9JfQpmRIYKsTjFZc3//68bmoief8+fP0naPb3aU+f5bd\n84HlUR9VLtPsToldw+BogY6Guo1ILDFVZDarqOeC0ZH5JOBxaOMxVR/VdZDAGps3REANLmPlu67B\nj7eQ3TMMehoMNPWMcWsYxQQhEtoWyNk8UqBjx+hQj6RairLP6tE1MI6QGqwIh48eZbK7hXY9YtsS\nSGxsjil7PdJswuXHVjh6fETlSpAEHnbOnENpDUUfVy7j/f78AMUYF8klkQSU0bkCWez4SYRI2rPl\nCALJe8aTHRIdohOi/vlYKimB0ciFptxCs6a1yomBXNHopHOVc2H6KDmxIApjNCG0aK0RWfjh2dzG\nSckzb2eYvl0I72Rxas8vpVAQE0opQvSgNSElCA1Fb5Q3wqTQKFKKaKN5bPK9xw9RhNh2QE6grixA\nQdslkjL4EOl8i9EGiREWCbQo+zjnUDovvlYKZfSiXZYTjVIKrRQxJVAQfF7v3miZSdylntW5VZkX\nFbVoh6UkaKCdzFEGDpd9EINxlhA8koQQPd57itLhjMU4RwHEeQKV8CHiQ0AEdra3UQoGwwFlWdB1\nHtFCWRYoDeW/8DLbb+hZza23fifntzocA9STllmtLJ/5fz6Nmte4oqLnI84ugaphfIa11SlKd9z7\niTFLA0V/NKCbzbhiBSKC6mv6S2O09OntHON0fRKURhMZHephR+Ao6Jo5mzsbzNvEseUSrzzKa9Yf\nPMEV1x7nzOlzPOFqQ7IVSuX2ZzUawDzhRSh6BUeqyOzMIxw+fjUb9YzPffwRrr16GaU0T73xMJ22\nnNU7PPylbZ7w3U/FDXv46Rbr2y3loUE+qKiv71h9URPPJ+/9NGsDKAqIEQY9SMEz3zlPoSsoQUKL\nOIuTgCcRlaWd1ihrCEkzWDlE2R9y4uQJJCqsc2ATvvEYZ0iSmDcdgmDKIerYE6k3T9DujEmmx6af\nM//SF1k9NOLy40cR5ahsj6VjRzj3sKdr5wyHQwyepplQuIrkWzrlIMKgikw2zxONZmdck0yfrp2z\nOkykepOeOcT4/HlWLjuCSMdouWBnDlVPszQqiEv7yjxiDzmh6EVVoYgRFDZv4AoWexdxkTbqZs50\nsk2UFm0UFzpnQSLaakRy9WL0Xs7ZSzio/Hom73WkxT1ySiK3zARiDGhlFj5UFiSSUkRIOBSh69B9\nSzPbQRmF1oqQYv4dJM95JOQZlVIGtKOpZ+g0ZrSyjPdx0WIziyrrcV70/59IStBWk6IQotDNs5V+\nSIkgkW7sc4vKaJQkVpaXcUWJLQuMNqDAaktMiUUXLh8qTG67JRFCjFhjcvIiVyllf8Csbgk+oGye\nwSml0NrQW+5jjEEplQ99ITKfzbHWoLSmazu8jxRlSewiuoCkhaKqOHv6NCFCTAlRClc6qmEfSCir\nabsGrTRaG0AoC0dV7c82KIA7PGDUr9g+H6gGCtsrKauKpZVlGulYWimQ6SrnZwbfc2x+pebo0Wvo\nGYMxE1YGmlY80m5ilGU9nMT35wy7Kynmq2zMd1laGbAzmzHsV/R6lmtUQqxnfV7SL5eZPXKayWyO\nK/o8cKqh5zQ4y+pqxT998kEGg4pJiEhKGC2sFBbEMlxdwqmWSRuwkynTSc3VN1yF0opev2AaNL1i\nwKHRMqP/fCNVjBADrhrx/T/0XwiiCL7DfQPa2kXd9XqXw+xcyaBfYKyQmhbfBpQS5o1nOByCMQyX\nSjof0SRcWVG7ktHKEbQriSkgxlCVJePdmrqecfKLEVtohmtrOKVZO7zKeD7DRME5R3XVk5htbfCV\nh04iUSEONs7ssHbkMjSR8XSH8WyKVtDOOpaPHEZ0hUrCrK3xYhhYRywVJnbo46v4qBnPO3oqopUB\nU3DjTU9hd32d3tIqRhdEpdiZewb9ZZo45f77Pst0u72YIfiaMDZXDtZYlDIYAZEEKp9sE6CxQGIy\n22U83iTEFmMTgsqzGjRKaQT2ZjV6QUxIIaKtIaq01+/X1u5VKBBz0aOEpPRXPZdCCLHDqLzRJQwR\naNqGJAkfI1bnjUqLIaXcrksh7RksilKYpYq6i+yM52AahqMhMbR5w1Zg7P4kfdZd/t1R4H3gAjkj\nLFgUCkXXeJw1HFo7TNnro0yez2E0ZrGOudWYUFphdUFKCaMViMK6khTyTMgYQ4iZCBBjygcDAa00\nrizp9SqKqkAkLipkISH4EPZatkppXLHI5FohOlfBIQb6wxE727skyQeQ3BLM7zNZtOiSQK8qUCpR\nXiCB7FMU/WWiwMmHH+D4VdezttRn49QJ1pYGbM09n//Yo9z45GME39LrD1k6fIioHI+e32Z7KuxM\nWlQhHFkNyHWeMBB0LDn76V0kzYhOU2jHSn+NcugwPhFWeoQAw0MVWoQbvvOpWFNSGM01Nyja4OlV\nBbY6ytGrsoGoEwvSAgXJRmwqQXuaFFkueriq5HIRdFVAl1CVZWANMRnWBhUhJsQaRv0huAKlE33T\nQ/cKjPn6qeWiJh7f1/SGifH2hKIHhenj+w7nO5QEZrtT+scOE6cNxlWIVvjG46oBXScY5XFKEbtA\n0R9g5h2D5UPoZGh9Q3fuHL1+n7Lf5+ihZbquRZRCokfZAlGK4ahiaErMSDj14MMsr63iCodpO2yl\nWVod0O2sk5LB6x7WQqXywBPvQRSziccAR4+ucerUWdYuO4Y1hi996ousXbGC6hrmIsx2OqQqmdRT\nYtdyfmPK9tefwV003HjT/5KZS4sNJklkj72mIIRMCBjvbHHms48gKqGt2Wuvic6bhQK0ygP8jFzT\naJs3TpUEZx1RJUjZYVch+JhnL1EkJyKVIEWUsYhSJMnpyQqZMLCYN4vW9I+s0cwbmvmcdj7DOYMz\nFkQRY4crC6xzCInhaMT2vKZr5oxjzWi0gl0QGIxiX2LuA84sPrxGg87znYKCEFNuL4sCpWmaFhEw\nVmGcxZWQlMkJWGtIOV6ZtRZzi03yPEUrhVVmMTOL+KZBK4U2oLWhcAVVUaKNJnq/MLbUaKswRYEy\nhqLILZ0QAl3TYq1FFu1ahUIpzXBliab1dJ1Hu9w6bZsaaw1Yk2eNStF1Hf1eiWiF2qfVKMADD04Y\n9SuGR6/Hu4qdeUtyA4qh4/DKUb7vWihFYZTO+8jx3Im/Tq4iuB74mohhPZxlbB7gqH4Cq/o47r8W\nRCJlr09MGoh7cXRoCmdRg4qRdbhS5dEDltI6ip7F2AoBYtT0BiUqKeZNZNgvcrWpFb3CgbGIZJKU\nTxZlKmY7G4xGy5iqR/QNRTXAhEgoDLHx+G6GMgYn4Por39Bn7qImnjYkokuoBoaAM3NCB8PVActH\n1qhKS5RE7Bp8m4g6EMTxyMPnuO6Ga0BpWh+w1tCOJ/SLkq4JtLGhqAqMKZGkeOSBR1hecqwcWcsf\nGK1w1tArHFZrBksDfKwxoWQ68Ry7fBmaXfAGM3C4w4cR39C1gmpn6EITmxbE0rSRFKAY9KGrOXS4\nZLZzlg4LKHq7DYcvv5rt06cZNzPSec/qoUOsn9tkPku4XnUxQ/A1YYois818npdYV6DIRDDvO4xR\nhLZh4/RJop9jygLv0yIBJGLKJ2yFzuQBpfO8AUHpXIUobVDaEFJaVDcGjSGEBg2Zlqs0WuXnQCm0\ntvjQYbRZtMs0xjpS7CDmVplG5eG7s1CWQELpPMtAFP3RCCHhmzmjYUVpj2KtwVqFxECUhEbju/05\n5VE2/95K61ydLaoESYLVClImbdSzjhiFXZkgktDGYJ2h1ysYDYaUZQUieN/RzWt8CMToKaqSXq+P\ndQXhX1DcM9kEjM7MOJXpgrn6MZrQRbTLJwClwGhFSj636RazmXZa5wrIasKivec7T0iBzrdY5ZAo\naGVy8pSc5FKKmd2mM1V7Wo8vZgi+Lq6/6mom6yc4ft1VqNJSlRZipEvgRNFYQyGgSnCqQAqNaRWp\nyNW8LVZ4aPMk08mDPHn5O7l27SkEX7N8+BiVVVSrR3HG4YOnv3wIbQwqBEwxQHxN2T8ElhwPZUji\nwTqsaILytOMJZX+ApqQf5xjXQ0TT1ucxxRJKaerJNjMMTduh/Taoks1JzeYDD1PPG6wrCT5weHnE\n6NAR/tv/8Tfc9oM/zOEjV+IVBP31T20XNfE4LIWF/uVHiG1NPd5h7eqrKCoHviXGBM4hKTCfzNje\n2WE8aQg6n/JIgjYwm2whZN2BUUIQj0qZdhlThxuUoBPWlqASySXizpRBkeh8ZDye4AwMl4ZYo4ld\nSxJFCB1xpij7CmMtsa7pTIGJgkLo2kTTGbCalFokwVVXXs5ka5cUE00yaFdR13OC1vTLCtyA/uFD\nHHWR5Tbx8ImNixmCr43FyTkkwZg8pb8w0DfKEINn/fRpZrsbYDILzllDjALKYLhAFss6HyEz41TK\nrCVjHElS3lC0QZRCSVrMkgwiAaNM1oxYt9D4ZO2HMSbresiH9iCB5AMaQ4oeozRWQxsjiQVLDcE6\nCwrqRRvVmExY6K0sIQu2W1hUOkmEfUpqA63zellLTBEVYqaaK0PXdRSLWYu2BSmBMpYQA51P0AW6\n+S7ddIwr8pwkb/KZAeesYbS0RFEUKGVIEnHOIb6j6pWEGJnOa+BCwhPEy6KVZvdme0pBWfVIPhJ8\nRzQ6V6ZW49sOsxhu+6ZlNpsjgKsKJApF6Ug+Zi2X0WiT6fDKKMpBjzY21H7+NZfnYuM7broB3FMR\nPEYZyuEyRhusUWiV8ALz3V2W1i6n1+sRuo5Z0xBxGJV44NR9nH7kk1w5ejL/6VkvxomjV2qMWybE\nOYV1aIFuc4xTS8Tg2Z4EJM0RifSbGUvLyzzwhYeo+parrn8iGydPU4/HXH/T93Bqd8LH/+bvePYL\nf5B+7yhtElRUfOTv/i+2drf5gZe/hL/60z9jYz7JM1QfWCkL7viZn+UD73s3rbIUKZEGimuPXs5/\nuf0Ozm1ucn5cs7wGSgzqG3x2Lu5kOyoKtUYSh+mVUPbY3T7PkbVlkilBW0iCsn2Gqy2j0YjN3W2M\naOJCO3Pm9BlSaCmdIwSIJmLMYk4Qa0SXbJ2b4K5aYVrPMChGSxVFabj6iqV8UvOK9XMzUggEXRJD\nxOiCUd9hiViV2JlOCbszhsMlFNCIcNnxVZrtLaw17MzmbHvD+c2AswWojkorfNPgzApl6XC2x3Q2\nZmf9LMZElvvL/Men7s+ewc6Z07kVpiHETHNWkjfkKJHoO86efZg61pkNRWZGYXKfXhYtG7UQlF74\nYiohYoyliwGzmB+QEknU3kanJGZ2mSTEWroQMSqhyHRalcKihZdP3RroFKhkkChEQh5uT6dYqxcV\nVf7jCouxmagAJp/6EXzoUKg9nQsCRu3PGY9OiSSJNiWsVmitKZTGGEU16mOdxdpMrOk6T0iJmBTG\nGWIMFG6AVrJHMJBFW6TqVfSXlvbmYDleiqZrM/uHzCpLQF03JBIxBVzp6HzWXKmU9mZkscutNe8j\nSMriYQTtNBhFUVWExRyIlK8HKzTzBmstzuosfFUan7KAdDxPJPYnE/QCTm9pvuO7nkKvfwhtLYnA\nlz//BT73mc/iYyC1ETML3Pq//ic+8Kfvpmki3/+TL+XPf+9/J9mT9K8I2N3vIKbr+O9/+1nUoM81\nlx3jh150M+OTX8JEw2VPvgmrNVMfOHN+h//+l++nrltGqz26ScdNN9/MmY0xG+fPoJevZHtnyif/\nx6eorr2BrWng9Pomvm5Ry4cuiIhwAAAgAElEQVTAK7AdZlCy8ZUtmsmcWdeQuo7kNVYZZo2gE1ls\nnRJz1TCoe9TTXaRy2GSYbu4Sr1cYlfBqH1c8urYUVZ+UOqJvUUZBuYzvIhLHWXBY9bAEotLYgeHo\n4DgbpzYYTyeYxgMBax3KaZJKlNYQ2pKkLV2CZjxFUoOWgIktVgea3Tkky7SeUQ0rymC48liP0xu7\noCyF0ogLhKTY3trAFiXaGSonGANHr76Rcw9+htn6FlFDsbpKMZ0zrCpmzQxJhqKq6NoZGM1k5xTE\nAt2D0WBIRFHXc3xoczthH+LEiUdRCqwtMlkAQVJWy0cCTTOhC7PMSkPvaUFgQUJYzHSUNnv9/JQS\n2trFJvPPZAGAwhjQlnk9w+lMoVZKo5GcJLTKA8uU22UignJuT0yqxSBpQUsIoKMCH6nrGjfogRJU\nBBUCmOxUoBDatgHJVRcaekWPtuswiW/qy7geDxTWoC7Q0QBn9KK1bKmqCmNya6rtOnSKqC6TBnwK\nWE0mDbiCtCAm5DZdRC+Ncvu6aal6PWKMRBEkZpGWSEJrwTmDD5quqUnO0TQ1KQU0wqA/zHOcLNoi\n+C4nMAUsaO5FUeS5UMpuFKFrUXHRn5P83gje52pHZ2JDfjMqggSEhN3Hbl+j5RXM6DJ6S4cBofOB\nzo549OwGsQm0bUdfNCEKm5MWdKBTGru0QXEE/uuz/jfOfP4LnDy1zrytKWyBweAxTOcBEzqOKsOk\n9czqDu87tidz6HI818+e5ZrxLu285qEHH+XJ33mWne2Gza3zNLVHFwVd29Jpk51erCIETdkf0Yx3\naFJExSz61VYx155hMCQNlYGWiEk9xMFsHrDBIALb25toiWixONnHM56SEdnPJFNEOTondRO+fD9c\nf80xqAxaF3nwLELX1cyKbdIVHa6taM50PPE/PAllIEzmTKdzTjz4KMtrRymcItqC0WiJtpmig0Pa\nOYPDPVLwdF2HpiLUhhgipbYMhhVeBDfso8WgCaxddjk6JqTdxQ2HNG3D6S99glD2SUAKwvjUQ7S6\nh6n6jEyBc4YEzNoJRWUoC8fu5g7ODAl2TkxZrOhTIPjiGy3TRUEIITOMpKNpWqp+SfQBDEQJNG2D\njyETorUsWnGJlC6IQ/PgOpC1M0YEUeyxqEjZ6kZJnuNIisSU2WgZJktFUkKpTDgQSVkASsJYTZc8\nhc6zqOQjg+ESLNptMSaigjZ0SKepBj1MYTBWE3yH1QaJC3aeBhRITIv3RZ5Z7NcB9vKoR0pC9HlD\nNosWYkqRummQlMWzghB8ZpqhcxJXkihMsThK5N9TkmDLCm1ywtDG5uokK3szoSPl1qZSmsIklBoy\n3h1nFwNtCD6igLnuCHJBnBqpiuwSYqxBFFir0AhW5aq4axtKA4FMXel82mPqSVxsXob8HrNZm2VE\nsTJYuUir/43xqY9/mur4NRTFgARIUFhtSE2HjxGjFVYpYook3zJpxvzDh38Hr4X6i1ey/P2rfGZr\nzJlTpxitLZHGY7a21jl5ZpvPffah/FzHNyhsgahI3SRIHVtbGzSPdJheopvM6B09ijOG2fYutper\ny7qZsdLvEXygmU0IK6sYa1EpsbKyQogtOkT6vSW25i2lVYgYksp6PuMcTiJeKVrxVE2e00vd0p7b\nyJ9RhPgNugUX9diw7dfxzZzYNYS2wesx0SZsscTZ3Zapatjpn8PTslGcY314lnGxQ2gjaSMyGi2x\ncXqd9RNnwVmGy0OuueEJuEIQbRj0elhb0OuPUEXiyOEBNlqQhBGP6/d5+KFzbO/uMI8aUy7R1BN0\nkTdX6wxRKbrkKQ8d5+GT57NYkYT1LYPRErGeMg+KRI/ZfExAmMxafIRef0S/v4opj1CtHKeohlhT\nQOgwLivGp/X+PFXLwqImSVaUhy4nmZw4IIlHUma2ieTbUXox9FfZmw21sF/L7LQs9CSTCHT2XNM4\nFA7Iuii90OykFEkx5QQmGsEQUyJIIkIeTC/0J8RAoUy2egEgt3t829HrD1g9vMLSsMIYtce8Qmmi\nZKeDlBYSU+swpkApC4sW3n6EM9lqSCuVhZlth/i4qCp9Jm0AqYsE76m7Dp9Srjhh4bMmWciMRhuL\nK0qMKehan8kBWlOUZa5KY87QSRQpCiplPzWlFNEHQucXp2OL0o666Zg3DbPpnJ3xmLpumE1mtPMW\nrS0JmE+m+LYFEYajEUVZIjHtHXiysDUSQ0cg2y4pk6u8XtWnX+1fAen5rV2mWxN8EKwISSX6vYKc\nXrNOrRVInULRMrphi7XVGyknx2l8IlqFK/soFdnZ3GI8nrIzrjFKU6vIdDqnSTD3HU3d4LuOUw99\nhZnvSGVgNu/o5g2DwRIxJprpLsvLIygLQhMwzmGcYj6doi+wRrXGVvngEX1DtWwRIzQhoFINJs/z\nrHV0kD9CYmgRrLJUZUndNCBgk6L4Bt+2c1E/W3II5mqbedfQdJ7UCfUc5p0nDLfZZoMTD45ZV6eo\n7QxSi94IsJF1PW3T0NQt/UEF1FR9h5FEr6iIIdLN54TQ0cynNOM5nTiCSvT6hxYaBeHI0SUK26du\nYDaeoZVm68FHKJxhPPOcOXGeuU+cPrtDsgNMb4QtlvFdYOfsOie3WxpZYVZ3lKa3mFdEUupQ2tCl\nQNPM6C+t4YPj/LkNTGFQMdLMhF5vf1Y8XLCvWXi2AXtJpmlqwqLaSVlhitYqz3TIXZFEdi7QauEy\noLLWRkkWcUI2ukkqIj6hosYox0JwglaZRovKRiuxixDzHCgKJGWJ5NdVCrSyuRWnZbEZt6wdOcTh\ntdVMGPF584wiCIrOB0QpEJ3NJ70nhkiylsYHuhCo2/05wA6hWzgtJEgJrTTWOZRRue2ssq2QUplY\nkCuWhISQOwwkQOXEk/IsR+0JSjVlVVFVJaIEa02uhP5FBZJixHctIGjrFu4FBqXz/bz3dE1HSomi\nKIHsbBCj0DUdoQvEdKGyURhXUFYVRa+iKCzOGYZLQ3rDAabUiEkEPClmL73KVZTl/hWQYhR1O0cT\niOTPjC0cXVQ5mUpH62d4GuzV59l6oMcTn/B9DMsVKmexKFaXB4jTiLKosqQaFtTes/7l05x48BFm\n0126WUvdRgKJNrXUi/0wSWRjZ4Ne6Uhdx2QeUb0+qfGEaZ3n2rUnNE2mupNIJPpVH6UVdRDsYAUl\nmi42SDT5EOgjtl/hnM4Hw1RneYoWVOmYhzpXeHTEbzBBuLgC0ljSrbbgJzSnoT8zdETMkRmqDzop\nRocF2gH2Yc/IOsadIxWKUCcm85rhoKCdNexuTrnmhiOMLiuI3jNicaouLBKOcO7hhzi9PmZ1WLCz\nfY6e6xGDZ3d3TH+4hOumhJQQZVBlxc5kTkoJVZa0XhOV4sh113Pm7DkSmiPHrmVYDtn295NUQ/CR\n1UOBgR3l2Yeu2OpK5vMAUajrTQTN1mbD4eNXsnxoictHAyZb2xczBF8TiYifdbiiQC38u3zo0BZa\n35AQksr3UymzmmIKKO0Wnlx57hOixxibRYcqD50RFpucwi3ICEkgLtyjNZo8kFF7YlVrDUIkScjz\nGtij80oSCtvH2SJvsGRz0qJnKVyZT9FFnuvo5EghLFyT822SFF4U0naEpEkhYXoFhv25uaUke5Y2\nQrYzwkDhHD60SMz+bbaqaObzPE8TTRtrlDEY69DWUBQOJZk8oK3O/9caVxaZSZbigpILYXHo8N5n\n9l+MhCj4kAWjhMyuExFSzJXwYFBSlWX2YCM7YPiuWyS67GgggO8C2hh6vR4ikarqU/Qqps0sC4id\nyt6jIRHmLXOZslTu34oHH2h3NpGUDzkmBpStkAABAwSqJc+XP/N3mK0nY9QmoHBLFWbLk1Kgqkpm\n4x2sWWaWdrj/vjH/8ZYZKkZ2J1OSTyQrKCsYZbHGwaxhlhSjnqOZNVQ9B6VitrXJwBpoIs1sTHDX\nYCrLbGc7O4EohzYJtTRkMFyim9VcdnSNL3xB6JUliEV1Ht/UrPSXOHVmHe8iNjikr1FRUSjHZLyb\nW+4U37CiuaiJx2wPUIcStfHYK6EJEVdC1Iu++3iZo8tHSZ1H9DpaFG6wzLybU8cGTUE9T4SuZjAy\neNVgpEC5EpnNicYSlUcngyscSRSb40RKljppJESGa1eC6THdehRblmDAaUOsd1GqT6/qAQY/n/Hw\n5sNoNIcPrbK5MUWpMSlGqr5BNx0Dd4Rer2LZXcE0evx4TNs5giuRJhB9x9rxNVbW1pjNanw72xsQ\n7zdk767ch/c+UDiHcg6fGoiZnZStczRIIiaPdUXenKLPfl+SBZ1KKbRkskC8oP9Ao0URk6BUoms9\nurQL88q48BPLpAStF+LQlAkBTl1o0ykUFmKit/Du0oCkvNaUJb5rMDobhbJwxUbr3GpCISkCirZt\nqSczrKspi5LQ1exXPnWIMSebmNtPkhIxeJroiQvhp9I6e9LlviVt26JIizaiYEwWBbuiYmkwzBY4\n1mbWIBBCXAh3NUrFLLrtZ4uhtm0J0dOFjhBy9QTk6omFdkspXFXSXxqSQsAaR4oB43pYV9A1DRJT\nPhyanNBiCGglIJGmnZN0QkxCEuiUD6JadHZ7bvYvsy10idm0zksvimCF5AxtNwOVWBokmka49sZn\nc/7RD6LOQ5eEw6urfOXRB5AuUS4t0TNDXOXwMeKlI5GoJdLGadarWcizvEScJZLRLA0qko+kyS7G\nDkgSaJoWbRy6gvH2BKMVDsf4fLtov0ZIiQJN1wV2d3fol0McNtsnhUCwhrqrKYYVSQlOuazeRhCl\nGKwuUZ9vs9ZvYd379XBxE48YhvUafeeZ2PNIBWVTsqqO4ZlhLp+yy5ewI1BpmRNf2cWt9Ln++ifw\n8JceJISW1s9o60CIBVeIwnctPi7YUpIIOw3D1SXaILjCUBQ9IoJOCbGR1cuuIHYJPx8jOmFdlbUJ\nRvHIIydoPaysjDIZV2dzvVOndyj6QqkLoiqZT6DvHPiGWWpoiz6z6Q5Kikw/Dh3DpRHQwxbQzjtU\nTMy2J8ynzcUMwddETOAKt9fKChd0LikQJYDOX5MgQJKQN/dFUjELJhsS0NoQc8MBogeV33KFdbl6\nkYSyCrNoyQge7bLuJFc7WatFzF/RkFJmVxmdvyeIAKUd0iv7ixlHnl2kmJ0QJJvy519IyG4I+Unw\nKdN8uzaweWaTkITRodHCE07BN/z4XCQsTDmz6UBuLeI1GFm4Pi8ytQaroeqXOfFjFt+LpLFaU/QG\nuKqPUnrhKJATWIoeay1Kq5wIjMG3dSYYmIU4NwRKrSlcNhpV2mT7KtGLllxCqUQ9nWSSQpkPWMZo\nvG8XBqO5bZc1Rh0heJQkWt8gWpGMkERhk8IpRzUYYEY2M92+gTL+YsIE8NtbeBI9PCmCE0u/qOhd\nNmX3rKW3tEZUhkNrRzl3fgepO/rLh3FSEJzG9gbEQmWhOkIoDAGhGvTZfmBK09X0XAUodMzaxa5V\ndN0MUQ2T82X2rJxD5+ZQFUhMTDfPY6JA49mdbBAQyiiIaLTVtHjq8+dZufFJgBAXjiSuULQ7U/pX\nXsXgoQeIUTBoRr0hlTYsHT3CuG4RFIUOEL/+COGiJp4uesqkiPPEqDjGpjuLdy1DNaOfljHjVdzi\n/dW0M9ywhW7OFz97H2VvQDebYpzDG0UbhQfvewQRYeXwEr1RnxJFNRqweeJRxlu7rB1dJSnBisob\nmSuZT6b0R6vYXh9NwJQ9tILx7oTDq4eZjKdYW2XTO+eom5aqctmyxGRipyTYHU9plhQmKARHb7DC\nuKk5/5WzLB8/RpKUhZDCwlesZTauafz+/FqEwuaTMUqhjc1fgaCyFYuxlhDjohKRLFSUhJILFN/M\nYDP2Ansqkuf3NvvYoYi+zZb7SuOToBF0MPlLAMmqd0k+X0PMrbUUsusBkE++AawesLy8tpgtZTue\n+P8y9ya/mm1petdv9Xvvrz1NdLfJvFmZlWWrjGUkpELAhAEMPGJiLAYW/wQTEAJbDJjTyjNGMLGE\nLFkIgV1QVhkM2IXLqLrMtOvmvRFxbzSn+ZrdrZbB2hHlAXVTCYHivFLEIEIRX3e+1bzv8/yekkEq\nhtOZdreqM7eUausjL9hRpZBCEoIn+AlhZDViUrNhSi7IjzoB/Y4qy6+6k9bXljIGXRcQqbCNwzaO\n6GdSzJSYGIcjQjUIJTHtGtO0gEApU1V8VAI51A0/54SiHiKUqrBQKRVlDkihcI2uJu+llLEVazXP\nCBSkRAoB6xw5JbQxGN0srvq50s21JAwF72eCjwhZ54JSWbKEkhKiaIypROuSaihgEg+zUwAgTWKa\nJhSQ0GQCwiTUdc/xRYtuG8Iwkc8T63bFdDrT9/e41hFKRvhEtg45Snw6kVTGhA6dMt1qRbMYthX1\nIBckmFgIBnQRTLNjngNCa5wWhHlElkIpohIfZCaZgD+eq6F7IY2TBSYp+vs7TOuYY0Qoj04OMSrC\nMLPbOGIEOUVyqzlPJ4Y0YZLk7sU3DHFG6xVZfDeD8qNuPHk8k0qVys7T4jZfwU1+i9SGjbiksy3e\n1/nO5mJPyYVxGNFWc1uOxAKqrDBCkUvEtI67/hbxDrdzf4tu1myf2PpdTYVXb94ileLiek84vsHt\nr+hWe6bxjnkeKqT0eGKcIs7V4bjQljllIOFTpEjNGDIkSVIOsf2UP/jqS77/tMFJiYgTKUs++f7n\nCAkmTniRoRj62xekIjingFUPc44gdHX7V/4ZaGfIKSFLRaPU/aMsIW6VuSUWH0Yu8G/+xb/8wZ7L\nf/vf/Y33hs66cQikcDTdjv32us6IgieGuJCw68Z3//aWvu9Bq5r7kwuGyGpdF8go6mtsnEJfroix\n+lZYcD/vwKYPrSr3TpBDQEr1foZiG4sxhnazYr3boEwlGYzngUEpSgogYbXZo42tiaNKL+q2ekBQ\nWoKoaB2lFdPQL5L32qrMWTBPE1IbbON4F9gnRAXDKm0YRE2XzSGgbfOetcaCW5JCIET1A1WMUSJ5\nj5CytlsbQ5ZloWQIRCpY3aCErhlPlOWQ8TBLJslxmChJgIxE4Kv/9e8x3bYIVSiTR5pMmY6oVUvR\nnnTsUU8ugGpJaFXGi1Cp7WhMKYQkkasVWRSKDxRRvTUiFayTjGXGYpBNwpdQWXcUSogoCrJk0vnM\n4vNm6G/IeQLp6ndGFobpyHi4JysI/S1ZGjwT1jreHN/y/UffpwwHRgTNbPDFU2KmXVmy9siUltv1\nA4aEWi0oOkNb8K0nG/i1/Q+4Ob3gbf6GQ3rNo/A5caj+hKZp8CRefPmSz79/zf7RjjBGbk49+rFE\nX0S0O5K+6rh/c0+3MwjrSfZA2mg8nrW7pL0dQBj8+S1ufc2rn/0uUnqs2SFE5nR3IvgE1oGxqBAq\neyiWinRJiUzA94m2VZx9QQnYX/+AL7/9mv0jhRSK9X6PlnNNU0yeeRyYkRBnXLPHH46U9cOMRXhn\n9FCiOv+Vqu2bXARl2XDkPxPupaQmL6w0PvCaIKbqU0GoKj4oku7qisvrShPPvirW3m+ASi7CB00Y\nE1olhvFAu1rRrh1K5CVhtdKahZQoMspI4rv/A/kLQYcfq6RWaGOwjcGYBmMMtrE0rcNai9a6znAo\nmLahMZq2daw2DSUVhBaUTKV1u0p6rhiiiqHSeoGH5nfUidqyLFTC9zBOFQArNc5ZjFY4W1NCEYXG\nVhP4PAyUUMkJ2lZmnlQsseJpCZOLDMMJ21mEs8imJshKMs60qCIY+x6RMk1XpfdSVtTRQy3ZKGY/\nU0ogJsXNq5/zxW/8K5i/+9sUIUgmUJTlfDphLrcIYejPM7vvdRQs8zzg1isovsZRxcwsM4jA5X6N\nLILc98R9qu3KmLk/3HA/Rl4Gj1SZSyzpPPP8+c8xUjKPgZuXXzOsVsQ+MB5PTOeB2dcbrigFMSdu\np3tefvucf1lKpjmQSChVmOLA6y+f88WPf8RwPBN0IUiLFoWQTti1JefCNPVkXWB8wDee7rJj4IDf\nwwrNlCM6tzzTP+QmvuEmvOXb8iWfXXxBO684Hie+ffmGxmjIgpQ1IxF3mZEXA9PBUQ4tUWTUJ2dE\nNxMFNHqFSYY0KI5/dINp1zTKkpMnDWdOtyO7RxtC8Zzu+zoP0BqVBCVVPth06nGNoZEQYiaEgkJx\nPwmarUUby8uXr5C5sCoKTT35m6bFmI7j7RtyFGjd0K3XzPOZzun32TMPrUpK70/CNV+nzlWkACMl\nRcgqmV7acSl5ygLj/NALdg5Li0cJSJIwRcT1Qi2WCsJMkZocAirUE2BJNflULEmc24sdXeswqg7e\nS8qV6xdTbbNJlghvRVhUWfmBhvRttlukrIQBJSVSgm0M3aZ776+RQqERBB8QQtI07r3PyfuZeZxR\n1iwwz3c3ElXpIYvgJfkAiUWEUYkRwftKFs8wTSPejzTWoFVtUaslRVQphTaS4CMhxNrCKwVh65Ij\nltmUUpL99QXKOabk6ecBWaA1DU47Ss5snj6jazuMkaSUqxH2I77/v6iUKAzjyEl4/uh/+Fv8xr/2\nl5izx6GRUjJgKMykYWLz7FNaqWA6oRtH21DHADkjSyTETEoFjSFPE1IWhnnkfDxz8SwtUN6wBACe\nK4tyzJxt5Q4KIYg+kvOMKJDmmeBnjLUcOXM8vCbMnjKNDMOZVihO05H/5W/+N2iZaGX9zE6HkX/y\n+/+IP/7D3wES/TGSRWK/2vOf/vv/LrlIQPGf/NX/gMY2pNjzV/7yv/GnvkcfmU6dCI9BhqWnX6CU\nQCmCp91jTMq8Frd8NXzJr+x+xFYZwmRRrkMoU9MMO03YFcLzjkkE3NOEaTKSTBodm7JCeY0YNMeX\nLxGA3jWIZsV4PqK7lu5yQ4igpeV0/y3rpqEoKMkTvXwfCBZypmGkM7omdF7t2RbDi5evoe3QUiNL\n5Nvnr/ns80fMw0gII1Jb5jCz3j1hv90x92fevnrLeZopjf+YH8GfWjlkrHuHqFnkyxKMMEwJhFkW\nJKrZU1Z8NPnd4vMBS4oqp46LYVW5JV1WqyX4GiBhlCJTZ0+ilBpCh0FoaLtm+RkTtKtLpuFMSTW3\nCcoyGC/kGCqklFKD0R5gaSuRQmO0JvrAZrfFNU3dWKSkcQ1xQZ4UKhInxohUBVEKzjaAJPoaiR1J\naOUWivgyPsqLPqTk9zfY2k4DoVTl5AlJjh4fCoXufSSGELICYZVEaEU6J3IKVUqfK2G60sAV2mic\ngClOxJiQC11cizpbamzDbrer+VApAFWyLfLDnfFkrSn+yO/+zf+Kf+kv/lsUJtIwk8xMyAYjC1OG\n/vbA41+X4AO35yM/lpkcRk6HW4yVCJ/wPqDJzGLi9//Bb1JQTOHET37/d3jx4ifEfub+cIcKsNms\nSD4RVUER+Ov/4b+zHAZH/vpf+/fofSLMI//Ff/zXsEZxmgb+y7/6HxE0GDKX108oU8Bbxe/95Ev8\nFOohvljWriWLQkgeZ7as7UKQnz3Zdcgp4lMkkLChIMx3y90/6jdr85lhr3/IaTxw79/ybP0Jb+ef\ncm1+REiedrY8az/jtXjOz04/o5OKy4sdiI6YMsM4E3anqo66Bn2UjD91CLNmPA4YC+2Fxmxavnz+\nc7KE9UpxPx5RXUf3+HOMUEx+JMSqrnn06VMgoI8HspXkBN6D0ZIwebbf+wHDq59jiye8eU1cCX74\nxSXPXx4ZJ0UxhUZ1fP31G5yBpuvQZeDYDzz90V/g1c/+kJu3d/gsuLraI+zDnPH86M/9c1VwvBCk\ny7LJRO/56mvBqX9JLpEiJEqZd6tUhXSmDyuYaNs1GQizRwhBs12xvbyoDLAUa5icBNE4cq4mSaUE\nstTEy82+453QLiPph3MdwLumpnjGSMn1tQBVaSckQj7MxU0rQ86JpmloLy6qaVSKejsp4Kd58fmI\numfkgiiCEktdwFXBNc2CfKq+nFASjamfozUWIQXTMFJEwToHIRBDomSI04hUatGeSEIIzLPHOI2R\nssYhlCoSMEpC2y4ppxnvJ9quwbmK0UklMoaZYZ6JKdHYBqctWkhSiChX45mlqG1ARfWCdZvuI38K\nf3r99Hf/Ibt/fsvf/ltf8T//T/87eI1cWXL0DCFzsbsk+Ym//fK/R/zW/4hRiq9efsU/+j9+m5QF\n//V//p/htOM0HbFuhbErKIG/85u/TRomHJLf+s2/Q6sV5/FElpaiJZfthjlMxJBZdQ1h9vUUMRt6\nUYhO0CqL0XA4nWmFpbiCPx8wzZrbuzfInNDFMYw9SURCyOx3W8qUmPsJmQt37oxBMxVPIyxqFCRZ\nKY5GNGSlCOP5O9+jj7rxfHLx6/zs9d/nLCLawJf/8CWP/rzim8PPsK8a1rs1RgmeyKd8y7ecSmIw\nt6zjhEURnpwoCuybhvlgyCisVSilOc09ZGg//5So7nn8yLKyBikV3guIgXJj8KHgmpZGGfq7Zag2\neqac0Kbl5u7E9slT4jTz6Y+e4MeB9voT8vElj754AqJw8/aeT5+uOfWRw1SIIfDoskErw/ZizzT1\nzDHw9R/+Yw5HT7ff0YqML6nKYB9gtestWlWHcgVJVoSOn2d2+2uG8Y6SU71tLIbFd5jQDz34FVK+\npx0oJQh9z+t/+iXXTx/TbVdIAUmAcZYSQEuBEoKuc2w3FkUi5yXumtp+yDkSUoWNpuTfRdwRS67J\npQLegU4fWqWUsNrQrNasLvaIUkizZxqGpe0ZUcYi399I3wW7VeGFFMvNVC6m3Fx9HD5EGtcQYv2z\nkCMFSYgJKTUlBZSUdN2qmqvlguxJNSbDNQYpZW1fLk7h+ni1jSlloe0strFYZ8kCgp+Z/ExMEZEL\nrnE4baoPixrJUb09Eb2o3ZSSGNd+5E/hT6/dbxhe/f173GrFNEPMM6vZMKOQoTBPnrHvWW1WTGFG\nIerMrlP0UcLxzP3cY1yHTAl0xpmO/v41rWvozz3rtgXlMFnQOstqu2U6nojR46xFKE1nBUP0ROdp\nSyXq++SRI2zdmvN8xoQ4BggAACAASURBVAbNul2RRUbLBuNash8RFDrZEm0EL+n9GaVr1IaRkuIH\nCJnSKRCJFDLCC+yqI/iBqL770PZRN56f3P89oiq0HsavwN9DHBLSQWwEUxIwxKr+yA3dJ5FJZ0Ln\nmWNkPAAthM1E2U84A123J6fXfP5rVSJ6F3+Knix/7lf/VRrb0L98xcyRJAXyUvPm5gQI/DTRdBty\n9oTjiVW7ozQK3a9Rq4b+fKZ/+5bRB6xSbC8uSLHQ7To2+5HTzZHddsfu0Z50PrG5uq4LoBKsW8cn\nX3xOf38ml2/IaQS3qmqhBzrAdkbXxaIUYvQIrat7XCourq7p+3vu7zxFhPeE6BBmtJYffOPJVKd+\nXuTOqhRizrx6/hwtC41zNJttVWrlQEoBoUA3IGVGaVtP/RRkKdULJKpptESPVgpKjXSexkprMFYj\n1MP08WhV+WpCS7rtmhg843Cukv0FhVNyIqSy0J3je66bepcmK6qXx6dEShFRwBrHPHtCDDXfbUki\nLbkw+7EmxGqNyTVLSS7sO4OqHqpYIatK1xBEP88YU29nJSUyhXa9xViDT5FYEsM4MXsPCFZNy3a1\nQQJjSihbgwHFooJTWtfbkLUY5z7uh/Ad9ep/83gpkWfPTMRYx5Qnoog0zYp+mOgas5iaJXkMRF04\nT5Z8OrG62GNHT2k0VtYIcZkTrVwhRaB1K5pVi9OSafaEELgf7lm3HRdqg267+rOd6/x1pRy9EKyF\nJIpCLAI/9wgJ52lg03ZICuf7A806IVJGyERfJlZtR8kjrt1yOt6iU6BtN3gUu80O6xRv799gtCWn\nwLE/srFu+Uz/9PqoG08shTZoXL/n8WdbyueBP37+Nesn4LLDR5h8wLU78jghDxp9dUamjE8gzhrx\nas3masU89eSLA2O6Z34NjGAvDfbRGrMt/N5XfxeZPbGAiZpG72lCw3qlOJ1GkArZZlZNS9d8wt3b\nN0xTYP/okjAFWtcijWa6PyFWa063I91Ty3Q+Y4Tm8uqKHAJhHjkHz3C6QxnHyjm0hng6okrCnwbs\ndsembTHtww0b8/OZnCGHmZRSXegW4KfMsN3sOd2/opAJOVAnLRUUWj4wjWGaZyRiCaSTiFQ3IVQl\ni3s/0J9G7m5uaPct2kBWEdc5Cnnh8pmK0lk4ZTHXm5nShrLkAY3DzOHNiWbn2F7sub569EFfx4eq\nnGu2UfaJNy9eVj5gWDhqyy2DUttrefks6sxKgoSy8AViSgTvUYtKrizZPJUJUb1QpUCKkRSrObjk\nRAix3mKyIAaPazrk0pYchwFjLUrrJd68Cg1yWagTst7DhJZMpxMphmpmNZZV0yFzlWdLBDHFqpQM\nEdN1Fd8kFdo5lHuojEMIRWApRFXIoeB9QgiHjzNBTmhgKop0iggDkUIOoKcblG059meST5is8Mbh\nZGGIkVQSRAFpJvUFg0CmSFTQ6ZbD8Y6QChemYRzOSGHxs2dMEdO0eJmZc0EjEaoQ/YyTlmw04909\nSVlmBmSUWG1wK8UQPXkKSBlokLh2j1OFcwzI6YgwLVfNnj70YFtaDCENuIecQOpmhzpdQBG49Y7z\nN1+x03t+/x/c8/Rp5s3NLRlHZiaXyLPvB3YF3KsdYT+jPolwE5lOU1V1vGj55MdXjN97TUkC2Xe0\nwzX70jKLnrG84aATo5qZueFEQYXMo4vPyaGtJrak2Dza8+bFC45Dwa4iPqY6pCsabRTEgN06vvzp\nV3zxa5+QfMTn6jERNnLRNoRQ6Kwm5YCcI7gNWlt+9c/+gLu7A87Vub3ID1Of89XP/pjs5/rFX7qB\nOZX3C0ISCSVcXZDEuzZYvSGE/IFNsXkxoC5xCmVZVNNiMJVCgJVgMmPsIUckGXSsJGzMe8BllQZX\ncUKKtb2TC6SYiTGxvlpXubFID1Y5JZUixID0CllKVWFSFkxOHb6bhUMnlSLlpRVaco2iEJI5eMax\nJ+aEKDUbKQMhViWfWDasOtcpKK0I3tf/f7lV1awdXTe5ReqeY8SnjDYWZQxCi/fCE60rn811HXen\ne07jADnTujrXETnjw4SUctnsIsKJmuJpG6x1SK2QRtVb7AMtW8Bt9gxDzZaKwG614RwEwjW4LIm+\np1s7phCwVnE33PP4s2f0p8raCzqihWa9apmHge1+yzyNxDCD0JTsSTGTrMEpTQ4ZLRqEGDnc31WT\nvKt4iLZr8fPE+uqKNk5k2dA1kuNxxM+BGALNdoWPMzuxIu0Nbr1iHnpsSlidmBWsbMM8TyTXoYSk\n61pOx56NdjTdmmE4YwykYJl/gSL0o24897+X+OyHKwSZw81rCBEtPEbDi0NASVudzAqEDMhLmAAR\nBO1dx7/+l/7tX+rxfve3/gZXtmGWkbty5MQZrxNfh6+5yNfkQeKuJT//gz/AJ4EUATG+ZSXkMgzN\nPHr2iPPdG15+eeTq6Zbj7QzvQIh+ANkRkkTIEz70YAzZOggjUjckIbm6WhEyTJOkcgweXo1TzaWZ\nfawqJKUXDE0VUdf2mqVxhuR7cplQUlLIKPlhf6xGnxbajUQLsNqhtUDLQvQeZTQxz6QYqhFOVY9I\nwaOUQkVPK9aoLJZBemQOoWbGsIAAYkEog5aLAXXyqAc643n76g0pJbbbPRdX12hTeW05VVL1cjVF\nKoWQYklSFeSSiDEyjO/aZpaVdnUGJCoK5x3fLedCCNUcKJXCzxPez3WDyqnGfrQd7yRvZQGXSmUr\nhsh7VCroVc2tKkJUJ3yaOdyeOfuBLGvEg1G2elNCNaL6EEi5xixIY96bed9tYFJqpvN3D68/ZgUF\nOoV661OaIhK2bfnes0ecjwcmP7Fxe2JM2KGn3V2xXjWErJC+Ss9XVhFjIvsZ6RRTmnBFM4aRUhIh\nFy5Uw+hnNo2ibTWvzgekTrR2w3noMWnC2BYpAl3TME5jvUnJnqO3QEYUaCWsV2v62dJ2LdN5wpS6\n+WspSKph6zTTPNHtdoS+5+LiCilh77pq6j/eQowoYRFS0l1uv/M9+rg+ns0FIk7M0xklG9qrx6jz\nK37wqWFaFua7PrC6mFn/AKwCpOCPvzrzox9e/NKPd5Cv+Vz/EKU7dOpYjSdO/p4swRNpnGO477nY\nXZK3M0Ya+n7m9s0tK7dmjhNz7/HThGlBq4gQDdEHRMqUVPuxzsDKtNy+fsOj73/C6GeUkMg8VSim\nFZQUETjiA00gfefat87ho6/RCKViVIyzBB9wrqlqKqWZRknBk8rMhzaV7y4uF9NqwQ8eP3ts2/Do\n0yecTvecbu+Wk/qS3yMrEglRgaFCGObJI2JB6kosCCFQhCAuij0SiFhA6rpxKs3wQBe39WZXFWVS\n4MOEUi1yibCot48lokIqYowoKZnmvm7MLOy9nNGqkg5SSiBUBY7KQvKBNIeFbKBIIZBSopTE7CeU\nUljjKtFDgDTmPYqIXG9Ifh7JeUApgW0dRQtypkbIl4SPnsZYnKkKNrVw9ubol4ONrLgepZELxw/q\njCn4+YO3cz9kuVRv/p2yjEJwvTb050Odw5FZdYY4zoRw4OLJFRGBki1GVGuIOo0MKbDTtoawxYQu\nmagyjbHIbMHWmPi1kLhtx7mvLdOu2yKEwpmJ9WrF6eaI3qxBJpxz9HOPcI79dkt/f0DLQLfdU7TE\nacEkCq5rIAe0ahnTEdOuKUqzaSTTcaDZbXBa44n444TeGDabjtNxQBqBc01ts35HfdxYBHMiqQ0K\nRYwTp9vMaQRlwWxObC4la5UIEd78DpDh2b9QePbnI/r/hY7fo/hp+QPULBdvisayxuV17eLIjLGW\ncTjQNh1TmlntHP3JEEIkhDNTH/GpvnHOtPjSU/ElGuEMGy0Rww2taXiyhlevnnN4Aq3QPCuPmc4j\nWm8JPjOez9yfH2bmS00TzVhtwJiFHpzQUpGWiF2ZWSKsHaZT+DQwxlznAx+wvvfF94GC1pp5mJnP\nA+f+fll4B7KekZrFjLuAMkWdZVRkciGJRCZWIkGpsxByjWHwIaK0QVtFEQKta1jfMPQf9HV8qGq7\nllxyTY5EcO5PCAr7/QXaaFKMxFRIsc5wDqcjwU8Y65DGII1BG1OTS1m8PjEQA5RQON3eY8zCb5N6\nkWlHZCm0qoourGuW24hcbjuxtvJkxjjD+uJJlbtTlkwaQQow+gmlJK22NKZFKw25boR+mhmnGZSh\nEFFKYt2M1hYxTShjIS1TugdMLuhVZidlNboXydjPlKIX3uBIbzrWeLpHn9aW7kLdvj28YdU16E3D\np90FwxxI/UwIge31JT4mhPQ4qRnPI0YpTLdmPPc03Yqua5n7CWOrsbNtGtqnHVMcubj6DIg8urjk\n7njkcH+LxVBWK2zr8DHilCX5I94X8iAwm469uGaaz6QUSauO1dqihWAKM2iL2XREP2GN42JXqRnn\nfiLLBxx9/cn3PuXF198giuQ8ZHSXoRHoT4+0smM6zogtmDvBOhXcE3BtSywj/fT2l348sVVc+C0U\nQyIzakhKkmMhnRNKau7HI9YIQgwUqfEx058nUqM49RHdWNTk2V13TPMJ6xxW6/pvkufrnx/4/hMF\nocc5QYmgNMyy8GZ8zaPL6h1yqmF1KeCf/vz/h3f2/3u1q3Wdk6BorGL2HkGpZFsAJZmHCSWgs4aU\nCnPssKmj748f9LlcXlzSdg1+9rAHKHz7/GuyiEThwWXIlSMHgpQq7yojUALImaLq5gKF7Oc6eE+1\nB16H69UfIpUiRY8zldb8EEtKzZLWTSm5+nm6hv3FBTFMnA8Th5vb+n6xgKqXQDixBPOlGKHUGINS\n6jzreD4zDgNK6UUcUGMjhABjbFXIBY/WhhgCGoi5moulqPwv13VVyVbyEnVeYTs+BkY/U0r1IRlp\nUbI+H0SplOoM535GyPqYyIxShq5dE2UhhIjrWvw4MfwCn8jHLIti3+wYU4CSaZUFITl5z7pEZPRI\n02GExClHEp4xZj69uub27hahDY3UzCqTlOJqd8FKaoQsmKZls1qzbnf4MHAcjrjVlkYLzmOPNgIp\nFUIUfEp0doUwVdHolCQgSX3ASsl+d4XqJFerS07HA+fzuUqqLy2dbDjcH4lNROTMbr3mFCKeQru9\noj8cECKTfMKKd2DXXA/fQjP4B+zjiePE5W7D7tGe4As/+ek3dBcrhteFtE3EfUINjmba0T5K5Mcj\nEsPeX9G7m1/68WR/xqZPSQH6fkYUg5Sgr9YEfaLvA/f3J0oI7C8ukFZSUuHy8VO6bkt5/QJyYHXp\nuPjkC+b+xOn2BU2zIRVoTOLZ4zU6nsGA22x5lM+Miwt8WjVMYUSkHbY1dEZWafUDrC9+9ON/hrlW\nqMj8msMTY0QbSwz1iyVVVUTFlBj8zDh92Fvcs08/RZlKjE4pvE/TfPX6a6SW78dkpSSkNChtq4k1\neLIQJAFSJJSpN6DoPaWompppFEaZqpKjqrBimrFSvkcGPbTKVOVZThGpNF3XYZykbRR6u2d/cYE1\njtfPXzLOM6jqf1lvtoQYK8qpreDUssRdoBTNZkO33eKnAT8NiFQFA5VMrVBSo42rmzUVHMscCH4i\nl4IxGmsNMccqclzev3GeGEIgkzHaYHVLYx1aqkpOyIFcSk01FaqalYtEFsXp1KPUWy4vLwjec3t3\nU9N/7+4/5kfwndV1DVkEVuuGKAW2QJwH9qLQrS/pmitiGhBKMuTIulvR39+DdNjNBSUnYikopbG2\n0K02+PNIt3vEOLxFGU3XGL56/gYlMk2K2M5hvSOEhKKwvrhGIxiGga7bEHJkjgltG7QT7NfPCPNE\no7bcDffVhJwLTx8/JU4TJQqun11z++1rHj35HGSsGB8E/nRCoNAiIU3DWipOfiImkPOEdobd+uo7\n36OPuvEcDxOq1bx6cYNQipQyh/s73BcTSYG+d8j7bSXVNjN5VZsnxjyiOzW/9OPFecvL7i3JJlIT\n6lUkR068xncJ1VkSM9NLKHc90zzRdorN6pLj6YjIhaZRFOHozxPzENDdBuUaVs2a/nSHbCRDtHhW\n9IMgNxe4eM/Z3CNF5JV6y4/EiizgcHtgs3/y4d/YD1Bt66qTf4F+Csr79lvN4Clo6/6k154LOie0\nrbLYD1nWOpSqgB4hLdM4YoyhazuaoSWEHtAkMrnkKv9eWmZCsPh0PCkNlZor682mLsh1AC+lglg3\nKN3YGv/wQH080YcqBVcVTXN5fUXXWayRuLZFWcvm8pLN1QUvv3qJDwmjNDGU95QJuWywXbuiXXcg\nIYVAyYWua0hxt5Daq/FWCFEl2H5m7oeaUDst5lNRIaPjNJDuM6vdhiILIWWm6DnPNX9HC03nOhrb\nIGIikRGikEphmjzDHNDGsWTzoVWVXh9uj9y9vUOq+vxLLoT4MEU5AE67pV1osCIjdSHfjeiuxbo1\nQxzIJZCDZ73bk0tku2uJc+LRxY5Tf+Rwf+bik8fEfObcn2i1RpSRFDNv7+5YO43UhjTNCAN+Lvgp\nkPPE7vozDod7dpsd1SIMjTGMdydW7YaiFCc/sNvtaqjgovI0uxVFG9pOc3vzLfKsaZzjcHhDURqb\nJRMRIRSWjPeFGHviuiOjkVbTNS0xB/rT6Tvfo48bBNes8DHi5xHnFNvPEsPFVHNeji32dM2UJ2SO\niO8N2NWaMHnCEFF280s/XjtuKSMM6URaZbKcQQoCdeiKBHNpaDYdq+OKi201z2WhkVnz7XxEKQeu\n5erpZ9y8esHrbw913qQEUjXk1FOKJSvFanPB4XjDVm6JYqLPGVXg9fwN635LTArdPExxgZASufDz\nKs1MUFJNF8sCKJWJVgPWamSsEBX6WLSGD9imUmKR9+aKT8nvnp9SNKZjki1zHBaenKZp1gtwDHKO\nGKMIAZKP5JKxqxUZuTxFgUigkDWSuciFU5aWGdHDK6VNjQLPBaMNIJYoCIGQGuMaCKmaDFcN4Tgw\n+6mGtcVUZ0NC0rUtrrF1U1mUbJXFVs2lymxZgG81FFAp/OQRUjP2J0pJi09HE7yvGTDWETOklOn9\nyBx9jW6QlS1nlEbkjNaKvJAvYkiM44SQBgQoLVHGoBc1W1kOO8hSlZMZhH+YOVYAetMhEqTcU7Ih\n3hzorp5gjKBtHHkKzOeRTduhhMK0iuEucrV/TB8GvK+HihICu82O8+1LjFwRpCDpjA6SlC3bnaWs\ntpwPd6TpAMbQdivG2wNirWpSaGMpBW4Pt1xdPeJ8OLHfX1HmiJDQGovEcnj9ms31Y8b5TD/PrC8f\n4bTmm9dv2O1bMI7j7R0iZ/auIRSBc4YcAzkXOqGZUuD1N/fsrx7h0gOe8XSdQBwrxns2kfA408g1\n0+9pVFDMeqj8pj8zMgWJeq4xzwSTPtKJy1/68dadY5x61kkgbzKzuMQqjU+Cb796gY4z15/suXhy\nRXOR2FxcEoqg0R3TcM8XnSCkiZzg5U/+T47jyMXlBa7VEDNdq1m1a169PdAfA8o6jOv4+svn3PUT\nn/yLO4rw9G0iHc+s9YYpPszFrZ5w62YCC5RRVFJ1/eZLRCkEHzCNWVIxl79TAvhw8FNj1Z+AK0M9\nDKRSmIe5hgHm+oOcpSATmae7Gp8tLDknpqlGacsi0KahCIlTDXEMECvoR5eaDSOEqEo4o4nxYabD\nuqbhnQ00p8Krly8RSrC7vODyyjD6Kiq4e3tHmMMC1yxARBlF1zUopZAIKAJyrJvOYvqTUlXQa8nL\nQp9JORFjoKjC5mpPyJ4wTBhjGYcBHyJoQyiF8zRU82fJSCFojcEqi1EaLcEsogVtWs79wHCayKFg\nrEY5V6njaiFghIzUlaKhbL2BJ1+w9mF+bwDS6Uyzv6DMEFXk+un3uPdnXDLkImiahkZqUvaoAmGC\nEuH28KbO1YpHtwZlBF5kHj/5jGmc0eeeFs2Ucw3hmzOKzCdPn/Dz1y+wQpEErDdr2tWKkCLWSu7v\n37LRO5QU7HYbhhgIKbLJDVIKxmlE7zrO4z0OjW478hxIKJ4+ueQ4ZGwReO+R1vBmOrPZr8nngBCe\n1WbHOQ80RdJ+umEcJsIvsCJ81I3n1Vc/Z71eo6xFbDxt2hKf9ygMMwKnHT59g2zWDH905OqqJYcb\nJnVPF79bJ/7/VN/4L9mwols1GAuno2f0ms264fPvPeV8d0uaJ/LkOfqJq6srnFlzGibGOSPEipwL\nzkjuT6+5uL5iu+pqJjow9RONEjx+fEHfe5KCeTqjZeDHP3yKH8+EBqRpSJeJw9sTJq4//Bv7Aeod\n56u8Q9BLIMuqXBIVxZ9jwrYN7zywUtZo6g/PaqOqEKV4b4Qkw3gemc8j43ykGMg6VcyNAFAIoesA\nXS7+FF0jmrVqyVMkHQO5VCFCKAKtNMYuURUhYh8owFVpVSXQiGX+Ukhz4v7tgcPNoUY8LAKLECM5\nVSKBkorG1PC2UhbK9HJzTCmR5gAIgq+zo5LrDSMGD6IsbUtNKRljLLhKUTBNi+o6fAxEApMPFFK9\n6ejq0zFKIyU0roUCs/fc3x44ncYKGLUWYw2xZJwx9aBRCkLJGk5XBFJXabFUvGfrPcTaXl1zunmF\nu7rC5oYxTbgcmGKmKE/T7mk3jsOtp2sMtllxIw0MI6dhwGmJVI7peGJ7cY2VhdlnVOewEUZ/gjFB\nq4hz4Ns3B4QPpBbKFDH7R4RhwBcPUWLFGrOyKNtyuL9hGCdc8JyNwBVDzLDarelv7jH7FbZAvxwQ\nfAGRPXEO7NZ7+jhy4S7JfUA0hjgEhlNfE31lYegnRJ5/YYjiRz02fO8HnwESmRONb2huG7rUEVPN\nVgnnCbM2gOfuJXz9T15QgGAPfPP1//VLP57vInerM2/yPdkqtruIjjeczneM5yMISCFyGk/E4Hnz\n/DnTdCCNJ0r09KcDoRhOY6Fb7bk7H5l8IoaET6BEw+A139wFfPA0ZFpj+OGv/4j1umUvnlFGiQey\n1cS9IJaHKdkN/t0pWQDyHXyaUuS7pAQWZy8gkSyLg1CL0e/DVU71V4iJVGrmD6IqqKRuUbojJ0VO\niroeO4rQldAMkBVKGqxySGHZthdIr0geyAZtOihqMWAuPpci3odkPbQKISygTLtEE2R8CIzjRD8M\njFNgnDw+RKZxYhwmUkw0rkEpWRVri+8nvzeL1tyeGCIxROZhwk+BsR8JPhJDIqfadgtDTXtNuSrW\nhNYkCsIoEixSdoVRDiMNJcHpcOTu9RvevHrL3d2Rb1684sXzV/T9BFKibFXCGSmJs0dRDaPaaqTW\n2KatpiFRoxZc93AhoS9ePEe3GyxrOiNRTJRUMM4ye4mfe+6OR7KWPP/2G8a5J/T3pBBppEEXxTic\nefb9H1OK4vmLb6DJKGOqOZ3CTCadDpz7E5v9poIJhQMUMlNl52lG2o6mrenOrdX1IJAL7mJLt9lx\nf39HniMvv/6GEgPjcODYn7i5f8vdcCJMnjKPzK6Q8sx2syeEE5EMcaZbb7k93REmTz8MNE5gVEcR\nDziB1MdIKgWTAtx7vMz1Ki5mBiDGCZsiKrWsVwKVKtMI1WDWv3wbxI2KScNRzpxFQCtJryJuWGPb\nFY0znO/vOd0eefZow5QDP/ujLxEpcf3ZpzTNqmbQWMXmakfrN7x9e0t/PvLjH3/C1aYhsOL5yzvY\nXjFlUFZzur/lfIrM04Sxiuk8IS4N2ln8k4c5JDXOLttOzXNZsNM1LA2xYPjrwi7e/1beaRE+aMVU\nEzCr0VHUDUUK2k3HFU853jsO96+Zk0AqS0oBiqmBaFVLUFtLGUSI3B9e43SLa1qijzDVkDulFcbW\niO9KSvjAL+QDVQ4zsrFcPXtMSYVXz1+gi8bHGaGqKkwoTQqJt2/vcK1jfbFDG1PFIctgXiDxU0Wv\naG3wuQInXdMw+Lq57boNY38mxzqf1EIxz/XfIKrIJJXElOZF2BERQmKNw0qHokqylXaA4XA44edI\niIWYQaaZbruuvqH30eY1Xl1ZRSIvf15vbpXEoOp86YHWbrMhjpFzfEMwAu06rMsYZZjnidOYcRmK\njazXDYf+zJwLm33D+OotrFuabk88H7k73rLuLgjHAdUodiuBwGCcQrDFzhE1B4wUtNohth03d2/Y\nbx2tXJNTQQnF/atv6Kd7EC1aN4RhRkuH69agCo83e27fvsZKxbnv2XWO4XTGPbrG+5HWNGi15nzq\nWe2uKRRIkZgLXdMx4dFaY5sdPp5q7Pd31EfdeG4PHlMKbdcijePtzT3aGq43mmGOSCP5/JM/g0kZ\n+yue8OYFMUuSgbz/5dsgV2lDnxP3BIpIeCLdpmM8zvgws//sE84RPvviM5Rp8L4nhAPXT65J84Ba\n7VFUIq9QkW61YpgmXCwMk+PV3YCRie2jZ4Txjozg1Zdfo9uG/jwT5rp46n1LHBLt96kD1QdYhWqy\nlFD76qW8b3EVoMg/2WEq1LEKDGqcwAd2lUtBmOpCk0oixfT+MYyxWNth1apmy8SM0S0xRQoRrRVK\nLiKRkMleoBdgZaFUDFBISCMQRhBjxJg6fP/QLcMPV4LkI3dvb1FSoqRCGIHMNXq8LLO3qR9hSYQ1\nxoCtnjVJTROtsdMD1ra4dYc/96AScwhIKUEIpnmqhw0pMc4xDSPjWC0AsSQKBZ8DPnmErLddqw1G\nKGTh/QahlEbKwna/I4bM7d0RWQraqIrxp86ShKjA0lzq4UIg3qOQ6gaUq1z7IVeoXxLXbiFHSvBE\nJTjfvQEhsOstczywUXv6fqK14ELk7uaObrVj8BOujLwZj6z1iqALrWtoOss0B8iS2U9MGTa2JXjo\n2oYQfDV448nqktP5js+efsLL16/YPbqGKFi3lkGNwIb1yjKfR1KYiKahW1/QDwPGKvwcWZuWN69f\ns+scKWeOw2uc7PAlEs5HVptL8nBHiBFKwMqOmCOiaTDlAft43r45s+kEtlthW8vV934FIyvr5+S/\n4tEnT9DKkSKsdgq9/VVenH+KcR1e/fInnp/943vapzuE7NitN7x58w0+BZwVZJ9I0fNn/8KPgcx4\n9rjVnkZIctGM88v0GAAAIABJREFU80TrIMwT2llKhCEeyAUwkrvDHUobksyc374FmVBa0nQ7/DCy\nWa2Y7ZH0GEIZSbPE9xrbPszFrZDIifdxBMLIJfiLGiEQ62IkhEQvkcp5wbh8aJjJPM5L+uhCYC5A\nyu8FD1pJmmZFPp8oqbb8jFQgLWVBsEhZ5cSHtzesL/aU4GumjJLLSKi2DJXW1e9T8gffPz9cSfxc\n21055xrWt8gPY0qEOXA8nqogLWcihdevXnP15JrVqiOGGpSXUqZpasvqeLivRlFRlWSVxVcYx5EY\nI+O553w6MU8z2/0O838z92Y/lmVXet9v7emcc4cYcqiBrCKbzR7VjZYMQbL9p1uGH/xiAwJkwbIl\nu2U1m2SRrBwjI+50hj0sP6wT2e0HFUE5hYwN5EtlVMaNOPfuvdda3/f7hkRtzXBK2EXAq9Ct3DWr\ndBpUmw3pyn4LXWT37JrzMlFzY7/draIONd+PWp6Vf4zIFkGaGBQ2m49MhDV64WmuxxlcqwvDtqNr\nDh97ku9xzMyu0W2u2Wy3pG7DUibOZeH25rl9wO7ONHF88fwbDvOZXvk430rnwlxhzpmhObY75X68\nMJXGJgai70lxQwie/abj9P7Aj69fctLM7e0NuTbK6UDLE3XX0W8i6jqbU18mOhfAJYatAw/fyoZ3\nd3f0ux3b5NndbJldxfWedjzx4XIhxY4yFQ7TA6FcqOcZwg/vz5/16e2GSAiN22/+mDJPVJTzMtKm\nzNc/+QYXEi1Xuig0ovWOj0q5WUjlD8/j+Ot/+ce8enthWfufnQvUJmx2A3/087+gLJXYbRjPZ4bd\nwN3da6JrOKk44Hz/Bh96cML26ooPb76nCw7vBirgikI+s3t+hWDub399xW//w9+ytAW9BnWe5ivd\nFkKCWZ+mcuqxn99KQWs1zxO2gdBs0E9TcG2VH6ypk49kg0845hnPlzWp1QjMtTRaw0jhiyntur5D\naCyzceWWeSIEQRG6tGEpxSTSfmCcKnHX4fwade0F8etsQiEECz3DPU0fTy6mGLQkalMXNm3Ml5lc\nMrmoVeVioXe1VC6XEd6849BFa4OlRIoJHx2tVh7hOTbRM+LAsmTGceZ8PjOdTzzO+y7zhSCFJm0N\n1WsECXQSCVjYnhaMSKC6xqe3j0IGt1ZGOD6SxhEjXj/K5h2yvn5HjNEyodY7mni3Zg89zTXsEt71\nzGXGi5J2G87HI7vrPePrC6lTLlqR89l+d85zc32LE2fxKdfXcJkY5zND9OS8MM8Lqduyf9bz8O57\ni3cPgdNxIoRAH5Rut6GnZyqZze6au+/ekkNjeXsmbK55Xz/gvKeNji//5FuW+WRSdVlgErpNIoZE\n9UobrdsxRgguUKYzTuDhwwc2t88Zz5k0RLrSWQgciTZNHHTEA2X+4f35sx48275Dg3I+HaCAeKHN\nmf3NrZXZ3rwK3g/kfKJOM0P/BcfxA72//oO/X6uVH/34GTF2XE73fP3jH6FUXn33Hay4/8v5gX64\notWRTozIGmKji46uJfzQMx4PvPru12z6LWHXs5wr2jy5VZ7d7silMqQeD/TbDbWP5HEiXm/wvuFc\nBdeYpyMuPc2bW6kGiaRWtGSElUoN1FLN8+LEzhcnH1EsZZ0BDZ/wx8rzZOqCx+oE/eghsXA36FLE\nO4hd5Hg4mrlShNYqZZztH/JCv+2YHk74K4vTdpgqDO9W1IjQasMjTzakL68UZ1OvZZtJiTDnzLIs\niBgVmVZX5oTiCdy9f6CsbTQfHJvthqvra7phIIaAiBCcI7fK6Xjk4f5AU4N3ykqd9hE7mZwloTrn\nCSHQuYRv5ol6nPWVWtAVWApm2g2r/Losy8eIixCD5fU4wWM3bV0njH3frbMdi+N2fj1sn+ajAYzo\nXi4fSLuEK5G2zAxpx3JeOGTYBM++2xCS5/5yQaKlwYpUws2eD797TR899x8u7G6ek+eJNGyJtfH+\n/hXdbsvgIjIuVFXG0z37L77i7v09Xz8zqX2dzjgccXdD8xNtOXCzfc53717z9RcvWE5nnIOpZS6H\nM/vYM48j9ANpd0WWTCkXdN7QmPHuhqxHOr/l7s1rovM0F2jNkn4fHrLFojdPRena/IO/o89rIN0/\np4wXLu8f2N3sqUWJ0YMqS25IVbQVG3rOI+fjhdBveFk2KxDyD1v9zUvKMtFKY7O7od9cU1rhqz/6\nFpbRlCASqdOR3/3ud0gD5xMaoFweuNpfI+roY+RHX19zmIU8V6alstkMuGWiXCae9TP19D0t7vl/\nfv1b9i9fcrl7z+l3F9LPTCpaiqd3kfu/fZoVz9/9+/+DWhtSGq1ZNoqut9uqhsBXtY3erQgV7+32\nDMK/+O//6Sd7Lb/95W+45Jk02C2qjiOVhWfPb4xA7ZRWM6oF56HfdLQs5HFah9VCzoXmzcBXjhN5\nyTaP8o5cC22pEIUyF1IYKKgRD57gcs4Zf64oTas9j1yY5xkfk2FpXOByObHkjJbGZZwZ52IKss4T\n8JzmwvnNHV1K9gy9X2dbVk2pj2hp1LoA1YhCQSAJzRk+ZUiJPiSojVYrIp6cLZPHreq5PFdqLnhf\nmefCvEy0bIfO+XD6OEOqY6NLia7r1tfjiF5YakPrTHBWcXd9Wp/r01xd8PiryD4lCB0udcynA6fz\nhMqFUgdOpbFzA9vQk6cDl6JcDzs+nB/orq65zCO31wPH+zuG/S3teObQwfZqTz5PzMuJRRsaHDUk\nxtMR15RLmVjuPzCmyGZ7C3nCJWgtUVCudz3nrNRlpHUWEV+0oUPCu0LcbxmckKUQ444pT1YB5xNR\n4Dy9x8VEF3o0zwwuclkKYBeaqBVXKvp7rAif9eAJecL5zOA8h3dveP6Tr8g1IsOGtFhU7lwq4/nE\neBlBhDDP5Fbp/wvklKKK98lQKE0tUKoJqSZaCFAu3L+/J08TKpbQl2IjbvY46SAr0o648oCEiGRl\nvDRudhucLNBXbsPByL/DjuX8gRD3xDAQuiuDBU5n4r5jnGautt/w7JunWfFczheohVob6hx5yWvI\nWDO6c6umXsrZsDMi1FZw4pDwaeXUl/FCBcZxWiMPjO+1LHklFBhy3zkDe3rv0Gqy76qg3lOlQFOL\nTxBhPE8Mm842YmchZKrCkgsDQkydRSs8xeXM6NpKJcaATotVOk1xrdGWkak1vAhddGQs6dav0E6/\nyuBrNZHFtCx4H9bIY6sqRRVqZZnt5upSJXURn4K1xxDL0hG/Eso9GiK1VLpuICksS2GZLcZCxKEV\ntFScRJoUI4OXQrk/kGumFSUGR0qR6+s9XZc4TKeVtAAinloKY850m+3nfQY/sLI2cpk4IfS10nLG\nqTJPF+alkK4amxQoJXO5HJAgRG1c5g9sb645PNyxCYlynoh9x/ly4Krf4ufM24d3DN2AKGRduHVX\nnJbJXA21oHOhlMbmdk9ZJfVSCy0Y+Pf+fKRzmUqjZk+ZC8+fPWcjnreHE3GAd+d7nE9E10jJQuRC\nLSwKMW45OKVNCylV+t0Nx9dvCC5w0BOIY/YOecrR1zWfcGUiB0/1HdPF4YIwtsKQBvoYzbDWPMuY\nKW2hOfC+kOsfDqIUEWKyJMWYIjlPOBcIoYPWkJ0Qu443v/2eFpxh5J2ic6bViTZN5JRQPMklthtH\nTBaYdL4/8M2XhaKB3c3XjHevCf0zvtk4MpmH4z31piDbwk6+Yo6vaCFDepp+hFqVUtahda3m11kP\nHdMamZ+g1rL6ZR5FBYX4id9WlbpuXNYcK0vBOfP1eLdCPqVaZpCImR5FmOaREJOZH4OnlMblNIIq\nIdjB5NQqokfjadPIXAyFIJ9cGP5pVssN78VmUa3hUJJXordgQREsQgAbwteq5D6T5oV5KZynyUQj\ntRH7xyhcjFYA6OMQH0WdEJJJ13VF3QdxRB/oY2c35vExH8c8PQ4IIVIz5Gnmo9BRBBcDsLbUyHjn\nWPJMcMkG0iuIUtZIBS8Ov84Xa664lRsXn7C4QGelSx3bbsNUR652G8rlQho6hu1ARYmauD+8ZfPs\nhsu84B1I2iNqleu272k0puOBftiiJVPLyGa7ZxrPdOJ5efXCxB0eJgQXhLhJaHqO5JncMi6YOnCZ\nMt+/+o6bm+cc3t5x35SrJJznwvX1lc2Zbm84jDNd16HOsYwjxVWaC9RgAY9+2/PyAlNy9J2g48T1\ndsdDPhP6a2vXJgjDD7M0P+/Tu7phiHB4fc92v6PvPEhER6XGChWWy8jf/dv/nT/7m59zOM30mx2l\nnB/pHn/QWpaJnDP7YU/OC14XIJL6Hptv1tXpm6xV4D2tZUprFNfxn169ZUiRlz/5ijEvHI8nQrfn\neHggtowL16QQEQakv2KZT9TDmeF6w1ffvOB1feChHLmSyMY945x/R5KnefA8tjJErCVSqx06Vl3Y\njdvJShKozVD9qylRP/FsRFfhgjgheEFiYllGQgg4L5Ql/6Ov/IfX2KrjeHzAdT1VhWWqaKtc3eyJ\nQVYitSN1yb6+NWpTTueRJVd8fJoHD6uq7zG2Qetsw2bncd6vcFO7KOA8rZmsfJ+2pHmmlTNLw9KJ\nVml6CI6WF2uvYlLrUjP9zY6066hi6bNePF3XEZ2nT50JT6L/+AxcaZS6MNYL87yilcRUaW6tjAyH\nw0cOW8J8Wq05hIYEhzpnz73xj56vXQVKqSzzD0crf86lquRpQTaOTRpYTkdaExNJYNXN3AotBLw6\nSsmMPrPrt7S50Pc959N5fZYbggtsrna8uSv4lklxYKoz4XLgUJS+3zLOJ1xVlqVyPh4ZUmQuI1fD\nMw7TA81DjB0fXn/P2AobCWjdcL3bgfPkOnN/uON6uGXYDBymCzIEyrGwzBd2vceFLe1c0Q6YJjbb\nHb+dL5RSkRy4nI6U6LhxV3z57Ifhx5/14Lna9DgtXL28wQfHMp3x6pHdNYph7ae88Bf/3d+Qjyf2\nu1v+7j/9At8Ftvs/HBIqWtBl4cPplRFgRHEx2FAPYWmN+Tzz6rs7rr66hhoQhRY8zkWG/Z6vvn5J\nDIFX37/n6mbL5rojZEffbWkKAWE83ZE1E3fP2H9xg/eB8uGeUE5Ig4f6O0qpRA8Pcvfpf7GfYPkY\nP5rALGnS5idVrWXl1s1EEJpv66YCSuC/6FbwA0sIiCipi8iKE7GWmkdrWdMx9SMxQS0Ik3ksFCLl\nMgOC1kq/SQSnmNJXVwSMYXhUFXHRaL9akN8DOvxcK0RTfLVc19ddrUXmTXAgXkzuLkJKCfHeQJ6G\namC/i5RJ1hTWjA+ervfrJUMoDZbsab4n7BK+82YknhrihT4ODF1Pni8GJ61tTds2d1QpmXlpGPjB\n5O2CAzVKttZqVY33K1zWfq7ajJYhwdOahfeBIGoRFVoruTXmZVkTZ5/mcn1EW8J74TCOtDKySVuC\neIRMXRrSKUE85/HILvYQA6fLAyxK1spGhX67p6hVQ+f7EW0Tl0W5TQPn6QRXz3HLgcvpgZvdnod6\nJo8TbblwamYp8MHRxcTGJY7Hezpx7LdXSClc2sIudNzdvaPzA7fXXyBeWWhs0sBhuRCCJ8Yrllah\nFS7lzNZv6LZbpgJBIGpi6eFP/+Qv+fnP/5wlRcLvCer7rAdPDAWPpxYQvyEEpeQLr//2/2YR4Y/+\n6KfkeaKVyuF+ph+Uv/oX/5z/7V//O7769ps/+PudD2cqHpcGnHhiDCzje8olowFcHIgx8PU3e7ZX\niVZGhpg4XkaWZUC3N4xTpdsPfPmjl3ifGOeF/dU15JnzYULqBe8dlRPD/isWAvMp8+H0gAue1AuL\ns2quecfZPfxX+M3+/19/8c/+hgrUYrMCVZNztH9EJ9BWbfNvZkhsq+TjU+fY/PFf/ik+hlWCawbI\n090dMQp3799+pA7Uks2BXxYLInNQl0qIJrdOfaLvO8pU1+jniMOhKngXqZqpVByKC4qEp3nwDLvO\nqrMg5Hm26OkV6On82ppSk8P32x2dKA9375kvJ4IXXt5uCALBCf1mWD1bGRWP+MRxaZynmUUbBWul\nlvPEfJhI14G6ZGat1GkhL/NKsnBGm26wFKVWxYeI84FlKWgzKXwpyyqrDh8jK0oVgneEuGUcL9S8\ncDke16pISTHig1+jKgLeOVNcPtU1jqSrntM8GiOwGsHk8OHE9eAZg3B8uNBaJiTP5BXKxPjhQEqJ\nq03iUpQkhePDne1XpdAPW3KbePvhQIyF+4cTx2ki4Th5+wzOLRO6npKVXEce7u7wPrJwpBfPpTY2\nU0a7jjIdqDRUFPrAopmHuyORRrmcmLUhac+2Fy7zgeh6gsCynAhkLksFdVzqTL0ol6UwIiRRKE84\n+nq3eUFpC1UXQr/l4f4NvjWOpzNXX35NboVW1je/qxC3TOMFv3gODx/+4O939+49N1/+BB8Cl9OB\nTVuBia1SiqeNZzpf2PTBkLFOOE8LSZWUFi7HkdtnX5Pnke2mg9WV3aeBy1Q4vz2x6R2lNvCO129e\nsbQPfPXTn9DVLaUVAjuqZkJXyb4SnmjYWIwdUZXiKvOyMHS22Yk4arU+fHM2ZHbyD7Ydm/YAfLob\naQiBEJL5dhzUvBjNYFlWGKEp7wCcM9YaraJloesCV8+urBoTQZ1Anwg4q2bzOlMQj9ZqkyqpRmbw\nT7PVFkM0fJAqIr1JqpuZX1EhxY5ZM60q43ih7wdSTEjwpAD7IeEoeHEEqRYj3W0orTHlQq4LTaya\n8iporrhFcapE59FSyBWkCSH01l5VtTmgM2WqUq3NZ7Ajy9FRQ866EBHviN7aTF0XcN6T+kTsDVm0\nXCbm+UKthWWZYRG6rsP7YFSNJyp1BzhOI5InFGHOwiBQx5n7XDgcGnjPtgUkKOcpE3QkB0enmbII\nv5uszXu8zMiSCblRivBwnvG+UgmkEJnHI9IyxQ08nCZStajw99rYNM+iguoDEU9tYu22Bgc/4lol\nVMfxYQQnqP+ALJWQBFdhUcW3xrm95eIjqguDnDiLIg3uRFGXWGpBlsYcGjdVSRK4v2S+uL39wd/R\nZz14/tX/8L/y7Nbx07/8K45//0tCTPTbPZv9NW+/f8WLZ9dsBk9VT78fQC/kEXKZ+e1//P4P/n7i\nPcf3H/DBsdsnlIzzPddf3PD2+99Qq/Lm7syPfvxstR4o3guz94hLbPeV8XRHih3npcfnQqpnTueK\n67c8/9FzXIxMpxFodK6w73csSzaJqyovb3/CL979gtk7Y899YqDmp1o2pzEekzT9OLcx457NQkz/\nZI4LO4LdP9CsP+Vq2TCkq5lwLnlt660GRcB5x5LNPJpSIERhuB4IfaS6QgwR7+N6iw60YqFi0juG\nfsP93QMhRooILoJEJX/CaIdPuWotK7eIj4F3pRTmcTTR3wr8VIS5ZLRkgmukwTH0PV4aznm0VGoz\nA25rypgrh2lmLA1FidoY0pa5LiwJNl2PW0Pf6io8UZU1vlosNkMcoo0hJhTFhbC2XYQYokFNVyW0\niCN4z+5mT/COUgrOJXCO3fU1ZTYbRV5mfPAsoylanTzddFiAv/5v/ltchP12R66VpWSLoj7NxAji\nE8t8YdTGm3f/lv3mluYuzOcOUmIr8KOv/pzp8o5N+hLw5qdTpVXh/uE1Tir39yM7X8lF2Q8dpRYG\nifzk259ZFDwgKSClkfPCu3fvyXWxqPSh4/RwR9hYHEiMdrHbds9oLcF84VyOlHrCk4hEplb5JvZm\n7K+F6hOiSs0z81LRoPzul7/k9qsveLh/9YO/o8968Hzzk1t2uxuGuCH9aENeLuSl0O8HnvWR79+8\nJTnPzbNrYvCE4pl1Znd7w/3bP7ziqQ28tz71PE7cPr+l4fHR4bod82XCD1vuP8zsbzsEmKbCV3/6\nF9y9uqPOR2AGJpZZudle8eq33+P7DfXuhGfm6mYLstBvrvB943TINF1IIfKzP/qWkif+6Z/8S379\n+lfcje9W38vTW4d3bxBnSqKiyuRllVGbd0QUGyyzYnKaIU9Magu3P//qk72W6XIiL6N9ODpDKpV5\nwXubH6wWeLskrDn3BcXvOlxwSGA1VCqG/1xw0ejHrSnns7V1vPMGuVSH4J8suUBXIQTtH1qbghCC\nQUBrzRZHjgdtRC+kIKSut+E9FmFBCqhYJNGcC/fjxGlZiCGySYkhJqiCa44yzdTWyCUTY09tDe/D\nSkhwHwkGiL0ffPAf83hSDIa7aYaRCii1mSIydIGYElrLKvMWExqogWpjCsyTEbhjUvKycJkuFsvw\nRNf98R0hBC4PBzKVHjNGLRXENXITvDR8czzv/wpHQatjGBrgcSI8vD8TdcPd6cHk6ii5KV4bIXQ0\nWbh6cUNaHC0KXpzFljhlfHigeIjaiMfA7Ctddby42lE+Xgsru+svSQqh75CgSHPUJkSpLNIxRIf4\nHVUMobUVm8+JRGKIOLUY9SIecYV5qXz7k1vmeaJOTxgS6nBGKagz58tsw3kXuLq94XiayFNGnTCO\nC92mY5FIXYTrZ57nL/9wccH1bssyXwhhQ2gG+5zKwqIdrRYe/SB+syGPM+dc2O5v+MXf/gd6l6hL\nZrvrePPmgdsXkYfjPXNLyAzj6UxV5Xg+k/xCZsHHDVkWLnd3TB8mvnr5ElWHLgdu0hVf7r5geaJz\nhO9+/et1Sm/JJ9os9hpt1FJYSiV4owk7EUp7jCuwQ+hPP+HBcz5fSDFQfGbQSi6F4+HIZtOjVMSz\ntnqMZHAaTywU/CbSyDjvKNIsUbXpx7jrPOc1yiHiglANvUDNRquO8WlKdp349f1qVYMPgVoyqPH0\ncGLtXnTFzpjUWpphZwwiOiPOoz5yqZnzXDiOIyF4utC46juudtcc7o/MZVpneiYksJbrCstdE0FV\nHyM0BB8iirVl7VB01h4slZJngvd4JyudxN5D2kyootoQ5xEH3lm4oPcJKLjWcM2TWvrU+pVPukLX\n0wWPax5xGZGO0GZCc0y1MgRBG8QukLSxuEQoSvSB7AqxGqK3uY7euvYUhE4XqzIdBE1UVVznTbjh\nlVCEktZQQwe+wBKV6ypGHXFCwN4iodoYRsSeRRHwUqEFildip3hNVAdJrV3aaATxNHUEiTSUsub1\ndAzIOPPdd7+m1crvu7J9XnKBZlrL3B8u9kvpdsQojIu1B9JuC6VSnCCzQnVIjMQELjr+zf/8P1GW\nicPb9wxeGLaRHBpeepo2Og+VwHQ5st0Guig8//JbHu7fIpL4/tUb+s0GOb1je32N3hU2X3yJ95nx\n8Jqui0z371E8bivEWLj7cML7ARWP84EYJ07nh/XmHdhdbXnxzR+jWSl1ZNEtIW358ZeeVie2V7c8\nHI+EIfKrw99xauPnfAT/2WXVjc0+WqvU1hCxiqdis5xcV4q1VhO6rn4e+cTtw2VZjK4MqxJLcc5/\nRMRoNY521cp4OTGVMy2CBI+TZJ4UfUT4N1yp6+YN4MAVfExIcHYjDA6k4OVpVjx1jRNxziMhkFzC\n+cCbV9+TQm8KQwSa3bDLPFMQkl/jIXyktsZcK/eXA5dcmXJh328ZkudmGOhCJKga8TpP5s/wAW1w\nuZzput5IFlpQdXgXcGvF68TRVJnmCZ9XzFFT27h8WFtqjtoaMfUmzY8Rv2KrQliNwMHTpsWk42tU\nxcdcofA0nw3AJiY7qAehly2hGYW+1MqmAupwUZEiEIXoCikHqle8720Opg0VhzjFVSHgaPT4NZK9\niaJFPya1iggZz0ZtvwxA7gtbTWa8FyjSCOpYtIALbGlkpyQNuCYU73A0RJVFIBT7HMxO6bJSRZDg\nSCg0o557YfVkweb6C662PXQd0p6wqm1ZLpzevsb1PZ3ryNMRJVIKvHn7ni9+tLMsFWcmOO+D3baC\nx4lnPh+4/9V3fPXVj5G64BfbLOaQyUvmYRxR8SznC2n3gthH5klJYYcPgRe3kTevvydtEzIKYWf/\n/Xw6MsRAbcrVbotEJQ09sbtmj9DvtiyANDi8/x0vrjeUeSL2if2Ll5bsuBhodDpeeP3+SB4c+9sN\nH44f8ATqtPCjzZfkyw8zjT7bUrspq1YEG2g3HpMsHRL9Kkm2dps2pRZTucknT4c0MGhcUzHXzpoJ\nCTAicwNqUaZppvlGU4dr9vcijlqWj4oo4+zYXEjdehvUYga5oEhyVDVZ8lNcVl16Quxw3pHzzOV0\nIYaEaqOU8qiBR5oyTsUsm0NA1Db3rHDKE5dSkRDYes+ui+z7ns4JXhXPo0crIprxLpK1rKQCQZyn\n1WrImzWSwYmYkmutlhWrhlpTfHAr8cI8Pa1ByZnWlO22Z5knU685wYmpGJ3zzMv8EecTug4XHlNm\nn+ZKvXEa1YGXQBY1YncIBk5FiK2gydnhognnQV0m4I0h2ITmBcmKRKNFeI3WUnZqEN9kkfTiPdlb\nlSES2DWh+EbUAVcbTUy67pvDe2XnO+P7acH5iAO0OaIWmzlHR2pGDC8S6Z3ZKQKB5hqymOTdO6F4\nGEoyCXboCGtMefo9DMrPi8yJEYmesszseqHOC7/8ThnHzNQCD7/4Ff/kz39izDYtZmJTRx8CrSzE\nXHj5xTe0ZWY5HUl9JE+eExOv3t2zu9qS+kS3Gbh7M3KTCpvnHVA5ny3m99kXL5kOZxqOWBun0zva\nMlK7QFHh+puXxLCh7xL3pwdct2VZKun6isubt7z84mtcAFCIPTEqdTwjwVFrYLPt4NUdy9Tx/u17\nrm5fEnvL6wjpmuifJnNKnan9gMd92gbJ3ltLrSkq4Jqu2Bo1D4mTT57HU2sj52JqqeagCVUrQxpY\nLgafzNPCZRzJ2mi4j9EJJpv2OAJabZBe61qZrS26UjJD2PDo+s91BrHo6Ke4wspj06aM5xPTyqQL\nsUMQSp4ouZDXdtx4KZxOma+++oKshSrKuNiho86RRNn3PVch0AVT+6k2psuJZbGYhdYE5x5NvLYB\nxpQo80wXAvM0I2KC+tbqag5VlrzQpccD0ZRyfeooxVqmqg0thWm6rNQJm4e4YJJw8Z5uGCglm5w6\nrH6jz/x0wk9IAAAYk0lEQVQMfmi5GImWLU5xHkehUwFpSHVMncO3gG8ODWIiJ0240uFjRavQBHwU\nNCqpQl0LiFYE4oKQ8NXIG5VCJz1ERbKn9YpTT9TKkiDhEBXDgInYJct7CgEzJzSkGZEiN09AqK7R\narG9tlbU9bTQjFWZFKpnjtjPGZXeeXys1Aq975l/j+rwsx48w/4Fc3VUbfyf//E7di9+SrpKVI4w\nzQw9/O7vf4EuE8+vnxF2W5z3PLx9w3w+k46BcbKMj+GqR5rH9R1+qbx8dkMRy5lvtZJz4vvjTD/+\nlhfP94ZZ8RYEVrUx39/T7/bUtuD7gfP5xLNnVwzDFeM4EaKjG7bUaUZj5N0v/p6aZ65vNpT1e+hU\nWZq1HcalEdpM7Pc8ezny9vsP/OY3I8/uj/z8n/1z5unIeP+APFH0h6p5XWLwFo9QwYvjY7BgK3i3\nDuSbkCmEaBXJJ8+B83Zg4Mz9Pc8LYDLbDCylcjzeMy8rEHFlxwmGdn8Mp3ukMBhhoZJzMbqyd5Q6\n05ayVnp2s3uqc4ToPZfTkcvpvKoIZZ1bWXS1ikfFmHXjZV5/TuE37z6w2W1Rr1Y1IeyT56rfsOt6\n8y+JA5qliTblcjmTi/luQkqoCDkvqBMyphQtrdhsT5Vas0mnnbV/fAzkVo2ioEKKcZVDV+bLCdls\nqMsFJCEuULGvaVgGTUyBUjojV0iD9TDliV4KADpxaHJIFmISXEvgG2jENbhyFmbpqqKuUbUDhBgb\ntGhveC1UxGJHvFvD+wJRKk03aGr40Kh4Ej2VsjIoqzELV8L3UJP5tBAkQJcr1XkcnugcSaDUQC9C\ndhUfi82MWqCTtHIBI+KUKh7f7BBsXcMVT4zm3cJBQlDnqFqQ9sP72mfVJJZSiKKEmnnx1c9YTiMx\nOIa9AQCvd5GrTWC365hFONzfs0xHyvmC0uif7fFdoO8SSkSDcL4cEQ99F+lwtOmAo6FlZPdswPdX\nVAzd3Yrw8P6BqXnS9TXTNBEkUUple7Vne3tLyQvDbiDXC3U6UcqItMz9q+/ZXl1ZO6pUfHeFC5F+\nc8N5zuiUqVpo3pNLpRsiu+DZ3zzj/PCAztD3He6J5oo8BrzZW0TWzdvMpDRdSQW2gStqLaw1P+VT\nJ3fmuqqlRKzFJmKJp5iia14mljLRQjX/Cqawa2qG13lZmMtEqYt5REpdb8xrumWtq/Q3AW4d3Ns8\n6Cmu4+ED8zRazECIhBTwK5i1aVuzbQx747wN8AuN4oTFOTKm8kseNiHRAeQMtdDWPya0aZSsLKUx\nzQun84lpWcitseTKOE7kXFlyMf/WSvNWNVJ1a41lntfD3hODAxS3PsvY9bRWeLh/oMwLtSzUnBkv\nZ1rO0BplKcboa5aA+zi/yvPTlLoDSGcmXtc5Ouzz0GVPVFDrXyIFims49SQR27TVWxeBCt4TBByB\nIGWd01TENxwVRwbviCo4CrFiasbgbb5XwFdP8TNZjCruVHA+4NbgRmkNmww1crDaJ+CRCr1mnMuI\nVpq3Z6k1s9BWD5DSuZXjuOYoWUVrasVWn3AsQpcCtZxR30jdhrSLnN5/oCLsUuR2CNzND2jast29\nYL5MqMv4TgnaaG4hbTsWhS0Nnys1eFzweDw+gcvgvfDNn/yM/csX/Lt/868pmy3b1FEX5esvv+bd\nh3vyZaTfDUDmeBzhtELz5gtDFS4PFx7evcb5BC6xu+3ReqDmRgyBOs7E4cfcH+7JI4zzhGiF00TQ\nQN8N7H/yEtdOlHkm7jY0cU/XCFcaGgwFageNrEICg0cCK4fLEUVQYU30tBbLv/of/xc+8vXbitmH\n1V9iqijWoahj5Xg5Z3ObBmD9faMNGEvNOWfJmUUptSHFUmPH6cDMGbAPnVOl5kxRG177YMNaal6Z\nbJXHMUiMAReTmRvVNuQgjZwvHzfzp7bmcUZ8WM2ziuAIqUOqsehKzmuMhaJBCV2iSz2+D1QqSTyb\n6Ni4RFLbpDTY89M16KZqZp4rS20czwtNhG47sLm+wsfAfJmZzhOX44T3FletoXH94hm1FKbTSF0W\nnHfrrIaVPmHqtRDj6h8JpL4z4cBim6kTx+n0gLtYJwGVjwBYXd97T/VSALDrthRM/acIrmXwEXEQ\neTwEsJam99RWCSkSi6X9ZoHYGvhqz3mNUClB8XNGNwmvPQTLkaootVU6HAFHcQVPRLTS+YG2mBE/\ndIGlVXwNhAQFpaNDorBgkelbPDlajIIRSprN2aPSXE/IjbwG+KlWpPaILogPoDaDL6J0v+ej81kP\nHl1GzucLm/1A10F7ONB1ARokV5jPjdAEHzK0iZQcSwbfb8nzws0+8u2fvzQFx7zw21++ZrvZsEyK\nePDaiDfXKIGH05HZFX7205/y4f4V87lxfvcW2T1jfz1Ql8axGNqj3+wIi7K/uuZwuDAtmW64orQ3\n+DrSxcbN11dozQzdntYqS504Hd5SlswyZUIXbHDYHNTGVz/9lkbFtSu8j+T5HkLHMj/N/HgTpdgR\nI87MgY+SWecsd0dRUxdVM5iaqklwjlXlZzPgJuDC6vFRO3za+iUi8Bjv1taa3SFos3nLo1fIfDo2\nYE4xkYKnZfMT1VZsJsAqOlhfo1sVeeL8qrhbh9LiaDWbbFcctWS88yt3zIMLoE/4UoCYki8IIUW8\ni+aBUSG32VIlV3WZeCGmgOs8BCVKoHMm4/VqMdK1FVo2U6p3lgzacExL5jzNFIGQImm7od/tLOpc\nHK0oWs1bk5cFETXj7nYg9ZHmhKrWGvQh4Ly18cBoFC6IceXMTYcZlg0San5Uq3JEzN/TqhlbfQwf\nq6unuOb26JYRfBZqNK6hYl4ZcYZzAotlceqok7Xzm/MEheYqaCLMSvOepSq+LdQQYGqUUJHicFrJ\nkokakVqZmCEEvM9UEVyeKBKw4kQJTShuQRZH9h5horZAQwlUzlmQYId7dhCboFVZUJxrZECzp0S7\ngDptuBioKiRpVFFSE+rvaaZ91oPn7b3JYIfcWO7eMfSOTZu4/vJbal548/o1u9sblqIcjx8QdTQB\nqqfzjv2za0syDAM4x4sf3fCbX70C11HOI85lWi5cPX/B7vmtpZnWBT1ekJsbnv/8r7l79RsCI5tg\nqI93D8rLl9/y5rs3/F///u+5ebbjZr8H5zhOk8EzJdOroN0OWaudvAQEZXe9p9806jwzjjOtTbgu\n4HzH+eEDiONqHzncHcGf0elptgzEPdY1BmarzfDqxtuyzbyVjI+mYhF11ibwnrrkjyFqTXWVW1rV\nZFLbhqB4Z3MYVkiCNrswtHX+UJuJA2qtIJCryXAReST5/6OcIJt1CBYDrbUhMdqwvVREC2CHkW3K\n3g7BVSZea7HKbG0xmSruaZp7bY6S8OIYNgNVHXlcYAWdhhAppVjFFyMuebuIiaOPHZs44GqBPBpe\naG2NivOGeGtQVBmXyrQsiB9Yj3NaKTTsOXrvrYqJgTzP5GViukwWqR2CKSFrWxWIRilYky3s//Vi\nogHv7b3mHq8gGPZnmUwpGQBVxnGkFktbdU90NgogOZN9oquCOsUVNR+ZFpDA1BqheUStfltcJUg0\nUcWa6qs1IGGm+mBimQq+BVoQQlIkOyN0FkcIDidKCR6XPbiGVEGc0iRCEVyydOCAEDTSfMHXigZn\nxAmFKh6XKop9RoIKRRbcKg9vgM+eGipOAQmQzMdjSh2HVEE9hN/D0vu8qrbB8/Bu4psff0PsE8t4\n5OrqFi0TbrPl5vmeWDKxZTbP4M0HSLE3ikGI1HnCxcRSLiZCFPj6x1/y5tVrrq87NlfPiKHn/ev3\nHPI7Si50XUJ2W7QGHl79mm+fR5Y6UzNsh4D6D7z77siHo6cthfN45MN+REpl+/xHVKwUnvwOrxPR\necaiDMMNWhzESN973B7Kq++R2LO//ZL79x+IKTH0HdPlgFaY5pnwmZMp/nPL0PjVhvqP3sCVWlBz\nXW+w9trtdip2o33sI/sVn9MaiLmxDdMPov7jbKssmZAioARnWTsmp/U4lNoKy5zxKdKVYv4Rrfjg\nSaHjcD7YhUTX3gXY3VlA13mFj+Z30SbkWteaqtkcpDV8iuayx2Yjvjla9R+l4k9tWY+/ok2MthET\nYBWnc46cFyRZlSHBrwbSSBc6htjTxUSVhYYwzQYONbBoXZ+7kivkpRBiDz7RDQPjZWZ/c8Pti2dM\nl5GSLXahZIOzeu+Zx8z75Z7NpmcYemvDeUu6hGabpA92cWkFJ7rqDnSNubdDyAWPb4GcM8u8UGrh\ncHdn9Oxc6Xa7z/wU/vNL1hjwRQrOK7RkIgEE1NGJt4sRHvHrwaGmPyDICjxUigyGN2oNU1K7f/jr\nBKIOOlObqvMEFbR/DDuPeK00EYJTqkBsEaJCMzGKhsdWN9SmbFWYnalGJUArjkhC3YwvAt6hgzNf\nkprKMStE3+NWMv+iSvCN5p+ynFocf/ZP/tx8H1VxoaPqgu973v32O1L0jNoxZuU2FL58ueP9QyZt\nzUgFDdFKzUquEzjlw5u37LY3bPqIB7rouB4E3/XMzDT1DMGzv31OOzRC56lTw2+E5XJCfWQTwY8j\n9xfY39zQxYDve5ZSuLl5QZ7PvPnVW15+89KAn94z5wXcQHAOj6flws3NDW/v3lLrkZvnO75/feb+\n/VtuX3SoH7i+fs58epqxCMradlmXIFapeEg+oFVtnmMTG1PUqKIVa79Zdw4D2ytCXb0X1kZpalwv\nlzpEoGi1m/yKTfmoRMN8KzUXNFeW8UI3DMxztu8ZnIkNxIbp6jzaFhxGMw7eU0uFtcJJLoBYFaTN\nXlPN9n2dWsVkP5E82Xhl56xqDCHS9RvmeTZDZim26biGBpDg8N58cF3q6H2PU0deisE2XUPilmk8\nkpKz5FYbdFGXgg+JfhPJzcCeQ2fKua7rGM8XtDX6vkO2G3zwTJcLx4cjeZl5+/YtV/s9u6s9wxpZ\nLiJrMJ/FJLS1Emqt/kNrdr0pT9O4khHENuFS2GwHUCUvhfh7fCKfc7VS8L3imyn4pDXUm+MfBU9j\nxdeZL0YrHqU5QaqnVaH6SlJZq0sBFRYRfFUzlWKtMF8heMMM1eZpUgjOI2qWASfWCfCCzYQesVHN\nEZq1PtUpQQKTAC4TRAjiycki7VtLtE4slVZAgyeuqKroIKoJH1Q9W6BpJvOEo6/3m62V41oN4dEn\nWotMhxMqHb4X7j4s0BKHHBlcoyMwn89srp4zLRM+z3jfWNpMUo+ESBwi3llKZV1OTNORL774Kcv7\nA33X05qS73/BZtiTl8W8HgIhKPOsyFT5kz/7km/zxHlsjHUh6kKfeqIXcm0cJbP89rd89eKKiuN0\nOuA3jRuBzfXAhYK4wNV2Q377mrMLSFaub/e0POFcIzrFDU+TORWQjy2YR/xJSN6isBVi8DRdDxOx\nKkdQuykpFHnsAXvKovgUVmXSiunwirW+Httxirq64l/q/8cPFEz8SZ2V6iD7gveObujwR1MQSbFI\n54b9+04wkGHzdt7VhhNPbRlhlYGvQocuJeZ5MmMsDhcC0Qfa/DQ3t1qVpSzgO2SZAf2oHitacJ0n\nBKs4Y+gY+p5NGvDV5iR2QVCkQow9IXTkPFNKYTqfqLlQq5kUO9/jnZi8vlSOH+7J80xdKq3AVBa2\n11t211ek3mTP08XjxCim0+VEXRaGfjAPTlDbDH3DuxVjpDZrQxVRA7+WXK0qrRbvnVIihHUzU8j5\nabaoAVxvBG382jbrAqJqcQEq1LBarNdOgmuR5lirjwwukIgUV3EaLa5CK514HI3sGw5H15TmHE6a\nVTSScRKpGKXgEfRaxcMa3tgjzOt9UqVa5bJmJTkRk+I3R3YgTSnePH2hGNldVy9S/X/bu5ceN44j\ngOP/6sc8yH3LciwgcQLbNyc+xMgXyPe/B4GBOICMxNJKu9JySQ6nXznU7Do+yCeDWhj1u460K5Ai\nq7u6qtplYvP45vVKczxOMnMTAh24Xz67/qifrDS/4+XLO5yrnD17zvP1FftpB3EFTEy7Ayde+2ZC\ncKxPz7j4JOA6z831jjl7khS++8dL/vTikttZL1fzDqQ08rzj9m7DOHT8eP2aLnSwvUH8SDi5oNbE\nPN0Tl7zqvJ0YxlMOMjNeXNDNmdUpbO4SJ6sVN+9umYYV99OeSMeBmameIL7RryOVwiEl0u01rkKt\nCZfe0uKB8YCWXEuihhPeX/9AmfdcfPL8Y74FH/SHL77SVJnTycUP5dLwcB+Pptbqw+iWpSCgiaaA\nALx3pIOurgme1pZ+DrQkWip6frP03bSfnano1IG2rNxCCIyrnhAjXiDPB6hJm1YRWPpPNMgULWgQ\npwEMXWnWpv0pIktWbll5T/MBnDbtSdO5dPr8ae54cF4ncW93pKINsnOa9C6e3uOiJ6VE13Wcn14y\nxKhTBEpFcPqaNh1fI+JwMTCcnBBjZN7uefXDS3I64LwHiq7YWwbxtBDIc2a/n2gNuqHHOU8/9nq2\nJpro8X2kHiadTpBntrtlqnXJBC8Mq8hqHEF0BE8QTwgBHyMuOObDxG6701RU1+kV9TGyWq/YbXU3\n9FRJ0124b1BF8E7TZKUJ4nW3wsNZTtPnxUHfHPg1tWXtqULTWRXBuYFaZ1oUTpun4IkiHGKh0ugI\nGqBEcM0jUuioTC0wSqRKWub4ebqm0yNS0GaJCsQaEFe1Ks5rSt2J9vA1rTqhkZHWIVLIEtGBpjo7\nrjoQgi5YXdPg8ws+bgNpS9wXTxhH3r35kfPLK7rYMWVhPL+kH3tKmph27zldBeIwUvMeJkepnm5w\nbLaZy/NTWug5P1shFKZUeXv7lovLZ0jM+HHN+ckVNR24/PQFdze3zHc3zFKQONIxEzp9Y7/795av\nvv0rOe1JKSEeSpvpzj7j+ThSW2aXJ72PxHn2KfHs7IJ52pJSZU6VrlZi7Jjub1lHGB0USWzeXnP1\n4isSjourC6bDgdqeZpfi6dWlpgJK1S/whwcCJek8LR7yzctzTaFVKsvV2LXRhqrVa97rX5b2s+/z\nnMvyTO97ebQcvLZlKoLznn7oCF4HZHaxZz9N+gEPAeZlVE9DD22Xcu3lp1CaVk555/SD7T2t6dTf\n+tD06rWPglaptfy0wn5icincb7aErjFNiRB1Jbo6P0W6QKOwGnq60LHqe238rVoUgNSlbN1rAF7O\nuWrOzLURho6zZ8949/aGWjIO/QIV0cVH10e280xula4bQITpsOf1j6/IaWa/3S+z87R8Wt8QoVad\ny1jzxHo10vdrnNfXfejiUiVZcC4So2cYz+mHnu1mR15SnrkU7u425JwI3dPMFAD85Zu/4Vx9vIm3\nLSOIWtVqNSk61HN5iDituBRZ2oGb7i6k/d8VI0vrhfcOj6M43dk3Gm6pz9FblTUAPDROF4oGpMfa\n0YIjIL5SioCbaaJ/XpIs6b5KZtaCg9qACgfRwbsBTQW6QpRAwNG814DqOs1mRJYzvQ/7qIFnd9gQ\n4hmnwwnrT1/Q+8D93YYSG+vYM+dMmScuVxHvEy7d4xE2h4lG4V///J7x/ILP//i5bu1SYk6wGlaw\nvtCKmPGceU6U+xu6fsX19Rvev5/wYeA8bPD1noOMvNlk9umMr//+NSU1XGrcvnkNVJ59+jn7/T19\n6HDB87vfv+Awzey3M3NKvHn1mk+uzvAyQIWrF5/xn+9/4PV/X/Hll88JZ5/BNHEV9syHt0zllCCB\nvhd297uP+RZ8kGcpfG2NaZ5YDyMA4hoSl3WSaDPf0jaoJc84PNoZr6NP9Mt82WAsO4mHgCKPwx4f\nS6qXyQJlGflfS6UWDTzURpVKCF5Td3vBEZYZbEJFV/biNYVWm16xrEUC7uFfiRNoWavhYui1IEKc\n9g+JLBV87lcf/fNrud9MpCqUOTHGTncYY6QbB7wXgusYuhXBedKUyGhFmzjBuQA1ax9VK1CXFuFl\n11pqIwwj64sLDvsdJWVwjjklqJn95g6JPcF7pv0OEehrx2o9aon7nNluNjq1wIdlYoG+jnp3kOP0\n4pzY6bXMOWW9ORW9qqFkbRwNa8/JyZphGHh38545ZWg69t97ITzV3Sjw52+/oUlDmn6KqoBvnio6\nEaRQteNsyQzQflogPTS8aSmG/r/VWbVLOTaC18T04zDeKkDLS0bCQau46mhe8FRya9TlbDU2LTTw\nTfMD5WHclWiDaRUdQuqpjxMX9dxPllFKS/Wq/uZlooLu7GBJlT7OwP4wae2JfrqMMcb8Jj3N1mxj\njDG/WRZ4jDHGHJUFHmOMMUdlgccYY8xRWeAxxhhzVBZ4jDHGHJUFHmOMMUdlgccYY8xRWeAxxhhz\nVBZ4jDHGHJUFHmOMMUdlgccYY8xRWeAxxhhzVBZ4jDHGHJUFHmOMMUdlgccYY8xRWeAxxhhzVBZ4\njDHGHJUFHmOMMUdlgccYY8xRWeAxxhhzVBZ4jDHGHNX/AJu6EX6N3GDiAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1ce05205198>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "imagesToShow=4\n",
    "\n",
    "def flaotTensorToImage(img, mean=0, std=1):\n",
    "        \"\"\"convert a tensor to an image\"\"\"\n",
    "        img = np.transpose(img.numpy(), (1, 2, 0))\n",
    "        img = (img*std+ mean)*255\n",
    "        img = img.astype(np.uint8)    \n",
    "        return img    \n",
    "\n",
    "if __name__ == '__main__':  \n",
    "    for i, data in enumerate(t_loader, 0):\n",
    "        print('i=%d: '%(i))            \n",
    "        images, labels = data            \n",
    "        num = len(images)\n",
    "\n",
    "        ax = plt.subplot(1, imagesToShow, i + 1)\n",
    "        plt.tight_layout()\n",
    "        ax.set_title('Sample #{}'.format(i))\n",
    "        ax.axis('off')\n",
    "\n",
    "        for n in range(num):\n",
    "            image=images[n]\n",
    "            label=labels[n]\n",
    "            plt.imshow (flaotTensorToImage(image))\n",
    "\n",
    "        if i==imagesToShow-1:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OqiMkF2nzpSk"
   },
   "source": [
    "## Define the model\n",
    "- A simple CNN with great performance (95% accuracy) \n",
    "- In PyTorch, a model is defined by a subclass of nn.Module. It has two methods:\n",
    "\n",
    "`__init__:` constructor. Create layers here. Note that we don't define the connections between layers in this function.\n",
    "\n",
    "`forward(x):` forward function. Receives an input variable x. Returns a output variable. Note that we actually connect the layers here dynamically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {}
     ]
    },
    "colab_type": "code",
    "id": "wrb3DsUazpSl",
    "outputId": "aa46ae96-dea2-4531-a919-223526ae5a2c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DPN(\n",
      "  (features): Sequential(\n",
      "    (conv1): Sequential(\n",
      "      (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
      "      (2): ReLU(inplace)\n",
      "      (3): MaxPool2d(kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), dilation=(1, 1), ceil_mode=False)\n",
      "    )\n",
      "    (conv2_1): DualPathBlock(\n",
      "      (c1x1_w): Sequential(\n",
      "        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu): ReLU(inplace)\n",
      "        (conv): Conv2d(64, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "      (layers): Sequential(\n",
      "        (c1x1_a): Sequential(\n",
      "          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu): ReLU(inplace)\n",
      "          (conv): Conv2d(64, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (c3x3_b): Sequential(\n",
      "          (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu): ReLU(inplace)\n",
      "          (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        )\n",
      "        (c1x1_c): Sequential(\n",
      "          (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu): ReLU(inplace)\n",
      "          (conv): Conv2d(96, 272, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (conv2_2): DualPathBlock(\n",
      "      (layers): Sequential(\n",
      "        (c1x1_a): Sequential(\n",
      "          (norm): BatchNorm2d(304, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu): ReLU(inplace)\n",
      "          (conv): Conv2d(304, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (c3x3_b): Sequential(\n",
      "          (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu): ReLU(inplace)\n",
      "          (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        )\n",
      "        (c1x1_c): Sequential(\n",
      "          (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu): ReLU(inplace)\n",
      "          (conv): Conv2d(96, 272, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (conv2_3): DualPathBlock(\n",
      "      (layers): Sequential(\n",
      "        (c1x1_a): Sequential(\n",
      "          (norm): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu): ReLU(inplace)\n",
      "          (conv): Conv2d(320, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (c3x3_b): Sequential(\n",
      "          (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu): ReLU(inplace)\n",
      "          (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        )\n",
      "        (c1x1_c): Sequential(\n",
      "          (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu): ReLU(inplace)\n",
      "          (conv): Conv2d(96, 272, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (conv3_1): DualPathBlock(\n",
      "      (c1x1_w): Sequential(\n",
      "        (norm): BatchNorm2d(336, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu): ReLU(inplace)\n",
      "        (conv): Conv2d(336, 576, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      )\n",
      "      (layers): Sequential(\n",
      "        (c1x1_a): Sequential(\n",
      "          (norm): BatchNorm2d(336, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu): ReLU(inplace)\n",
      "          (conv): Conv2d(336, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (c3x3_b): Sequential(\n",
      "          (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu): ReLU(inplace)\n",
      "          (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
      "        )\n",
      "        (c1x1_c): Sequential(\n",
      "          (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu): ReLU(inplace)\n",
      "          (conv): Conv2d(192, 544, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (conv3_2): DualPathBlock(\n",
      "      (layers): Sequential(\n",
      "        (c1x1_a): Sequential(\n",
      "          (norm): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu): ReLU(inplace)\n",
      "          (conv): Conv2d(608, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (c3x3_b): Sequential(\n",
      "          (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu): ReLU(inplace)\n",
      "          (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        )\n",
      "        (c1x1_c): Sequential(\n",
      "          (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu): ReLU(inplace)\n",
      "          (conv): Conv2d(192, 544, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (conv3_3): DualPathBlock(\n",
      "      (layers): Sequential(\n",
      "        (c1x1_a): Sequential(\n",
      "          (norm): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu): ReLU(inplace)\n",
      "          (conv): Conv2d(640, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (c3x3_b): Sequential(\n",
      "          (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu): ReLU(inplace)\n",
      "          (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        )\n",
      "        (c1x1_c): Sequential(\n",
      "          (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu): ReLU(inplace)\n",
      "          (conv): Conv2d(192, 544, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (conv3_4): DualPathBlock(\n",
      "      (layers): Sequential(\n",
      "        (c1x1_a): Sequential(\n",
      "          (norm): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu): ReLU(inplace)\n",
      "          (conv): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (c3x3_b): Sequential(\n",
      "          (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu): ReLU(inplace)\n",
      "          (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        )\n",
      "        (c1x1_c): Sequential(\n",
      "          (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu): ReLU(inplace)\n",
      "          (conv): Conv2d(192, 544, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (conv4_1): DualPathBlock(\n",
      "      (c1x1_w): Sequential(\n",
      "        (norm): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu): ReLU(inplace)\n",
      "        (conv): Conv2d(704, 1072, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      )\n",
      "      (layers): Sequential(\n",
      "        (c1x1_a): Sequential(\n",
      "          (norm): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu): ReLU(inplace)\n",
      "          (conv): Conv2d(704, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (c3x3_b): Sequential(\n",
      "          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu): ReLU(inplace)\n",
      "          (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
      "        )\n",
      "        (c1x1_c): Sequential(\n",
      "          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu): ReLU(inplace)\n",
      "          (conv): Conv2d(384, 1048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (conv4_2): DualPathBlock(\n",
      "      (layers): Sequential(\n",
      "        (c1x1_a): Sequential(\n",
      "          (norm): BatchNorm2d(1096, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu): ReLU(inplace)\n",
      "          (conv): Conv2d(1096, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (c3x3_b): Sequential(\n",
      "          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu): ReLU(inplace)\n",
      "          (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        )\n",
      "        (c1x1_c): Sequential(\n",
      "          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu): ReLU(inplace)\n",
      "          (conv): Conv2d(384, 1048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (conv4_3): DualPathBlock(\n",
      "      (layers): Sequential(\n",
      "        (c1x1_a): Sequential(\n",
      "          (norm): BatchNorm2d(1120, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu): ReLU(inplace)\n",
      "          (conv): Conv2d(1120, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (c3x3_b): Sequential(\n",
      "          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu): ReLU(inplace)\n",
      "          (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        )\n",
      "        (c1x1_c): Sequential(\n",
      "          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu): ReLU(inplace)\n",
      "          (conv): Conv2d(384, 1048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (conv4_4): DualPathBlock(\n",
      "      (layers): Sequential(\n",
      "        (c1x1_a): Sequential(\n",
      "          (norm): BatchNorm2d(1144, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu): ReLU(inplace)\n",
      "          (conv): Conv2d(1144, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (c3x3_b): Sequential(\n",
      "          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu): ReLU(inplace)\n",
      "          (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        )\n",
      "        (c1x1_c): Sequential(\n",
      "          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu): ReLU(inplace)\n",
      "          (conv): Conv2d(384, 1048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (conv4_5): DualPathBlock(\n",
      "      (layers): Sequential(\n",
      "        (c1x1_a): Sequential(\n",
      "          (norm): BatchNorm2d(1168, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu): ReLU(inplace)\n",
      "          (conv): Conv2d(1168, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (c3x3_b): Sequential(\n",
      "          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu): ReLU(inplace)\n",
      "          (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        )\n",
      "        (c1x1_c): Sequential(\n",
      "          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu): ReLU(inplace)\n",
      "          (conv): Conv2d(384, 1048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (conv4_6): DualPathBlock(\n",
      "      (layers): Sequential(\n",
      "        (c1x1_a): Sequential(\n",
      "          (norm): BatchNorm2d(1192, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu): ReLU(inplace)\n",
      "          (conv): Conv2d(1192, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (c3x3_b): Sequential(\n",
      "          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu): ReLU(inplace)\n",
      "          (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        )\n",
      "        (c1x1_c): Sequential(\n",
      "          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu): ReLU(inplace)\n",
      "          (conv): Conv2d(384, 1048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (conv4_7): DualPathBlock(\n",
      "      (layers): Sequential(\n",
      "        (c1x1_a): Sequential(\n",
      "          (norm): BatchNorm2d(1216, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu): ReLU(inplace)\n",
      "          (conv): Conv2d(1216, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (c3x3_b): Sequential(\n",
      "          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu): ReLU(inplace)\n",
      "          (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        )\n",
      "        (c1x1_c): Sequential(\n",
      "          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu): ReLU(inplace)\n",
      "          (conv): Conv2d(384, 1048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (conv4_8): DualPathBlock(\n",
      "      (layers): Sequential(\n",
      "        (c1x1_a): Sequential(\n",
      "          (norm): BatchNorm2d(1240, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu): ReLU(inplace)\n",
      "          (conv): Conv2d(1240, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (c3x3_b): Sequential(\n",
      "          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu): ReLU(inplace)\n",
      "          (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        )\n",
      "        (c1x1_c): Sequential(\n",
      "          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu): ReLU(inplace)\n",
      "          (conv): Conv2d(384, 1048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (conv4_9): DualPathBlock(\n",
      "      (layers): Sequential(\n",
      "        (c1x1_a): Sequential(\n",
      "          (norm): BatchNorm2d(1264, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu): ReLU(inplace)\n",
      "          (conv): Conv2d(1264, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (c3x3_b): Sequential(\n",
      "          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu): ReLU(inplace)\n",
      "          (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        )\n",
      "        (c1x1_c): Sequential(\n",
      "          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu): ReLU(inplace)\n",
      "          (conv): Conv2d(384, 1048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (conv4_10): DualPathBlock(\n",
      "      (layers): Sequential(\n",
      "        (c1x1_a): Sequential(\n",
      "          (norm): BatchNorm2d(1288, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu): ReLU(inplace)\n",
      "          (conv): Conv2d(1288, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (c3x3_b): Sequential(\n",
      "          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu): ReLU(inplace)\n",
      "          (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        )\n",
      "        (c1x1_c): Sequential(\n",
      "          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu): ReLU(inplace)\n",
      "          (conv): Conv2d(384, 1048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (conv4_11): DualPathBlock(\n",
      "      (layers): Sequential(\n",
      "        (c1x1_a): Sequential(\n",
      "          (norm): BatchNorm2d(1312, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu): ReLU(inplace)\n",
      "          (conv): Conv2d(1312, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (c3x3_b): Sequential(\n",
      "          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu): ReLU(inplace)\n",
      "          (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        )\n",
      "        (c1x1_c): Sequential(\n",
      "          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu): ReLU(inplace)\n",
      "          (conv): Conv2d(384, 1048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (conv4_12): DualPathBlock(\n",
      "      (layers): Sequential(\n",
      "        (c1x1_a): Sequential(\n",
      "          (norm): BatchNorm2d(1336, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu): ReLU(inplace)\n",
      "          (conv): Conv2d(1336, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (c3x3_b): Sequential(\n",
      "          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu): ReLU(inplace)\n",
      "          (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        )\n",
      "        (c1x1_c): Sequential(\n",
      "          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu): ReLU(inplace)\n",
      "          (conv): Conv2d(384, 1048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (conv4_13): DualPathBlock(\n",
      "      (layers): Sequential(\n",
      "        (c1x1_a): Sequential(\n",
      "          (norm): BatchNorm2d(1360, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu): ReLU(inplace)\n",
      "          (conv): Conv2d(1360, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (c3x3_b): Sequential(\n",
      "          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu): ReLU(inplace)\n",
      "          (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        )\n",
      "        (c1x1_c): Sequential(\n",
      "          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu): ReLU(inplace)\n",
      "          (conv): Conv2d(384, 1048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (conv4_14): DualPathBlock(\n",
      "      (layers): Sequential(\n",
      "        (c1x1_a): Sequential(\n",
      "          (norm): BatchNorm2d(1384, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu): ReLU(inplace)\n",
      "          (conv): Conv2d(1384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (c3x3_b): Sequential(\n",
      "          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu): ReLU(inplace)\n",
      "          (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        )\n",
      "        (c1x1_c): Sequential(\n",
      "          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu): ReLU(inplace)\n",
      "          (conv): Conv2d(384, 1048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (conv4_15): DualPathBlock(\n",
      "      (layers): Sequential(\n",
      "        (c1x1_a): Sequential(\n",
      "          (norm): BatchNorm2d(1408, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu): ReLU(inplace)\n",
      "          (conv): Conv2d(1408, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (c3x3_b): Sequential(\n",
      "          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu): ReLU(inplace)\n",
      "          (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        )\n",
      "        (c1x1_c): Sequential(\n",
      "          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu): ReLU(inplace)\n",
      "          (conv): Conv2d(384, 1048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (conv4_16): DualPathBlock(\n",
      "      (layers): Sequential(\n",
      "        (c1x1_a): Sequential(\n",
      "          (norm): BatchNorm2d(1432, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu): ReLU(inplace)\n",
      "          (conv): Conv2d(1432, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (c3x3_b): Sequential(\n",
      "          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu): ReLU(inplace)\n",
      "          (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        )\n",
      "        (c1x1_c): Sequential(\n",
      "          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu): ReLU(inplace)\n",
      "          (conv): Conv2d(384, 1048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (conv4_17): DualPathBlock(\n",
      "      (layers): Sequential(\n",
      "        (c1x1_a): Sequential(\n",
      "          (norm): BatchNorm2d(1456, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu): ReLU(inplace)\n",
      "          (conv): Conv2d(1456, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (c3x3_b): Sequential(\n",
      "          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu): ReLU(inplace)\n",
      "          (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        )\n",
      "        (c1x1_c): Sequential(\n",
      "          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu): ReLU(inplace)\n",
      "          (conv): Conv2d(384, 1048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (conv4_18): DualPathBlock(\n",
      "      (layers): Sequential(\n",
      "        (c1x1_a): Sequential(\n",
      "          (norm): BatchNorm2d(1480, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu): ReLU(inplace)\n",
      "          (conv): Conv2d(1480, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (c3x3_b): Sequential(\n",
      "          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu): ReLU(inplace)\n",
      "          (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        )\n",
      "        (c1x1_c): Sequential(\n",
      "          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu): ReLU(inplace)\n",
      "          (conv): Conv2d(384, 1048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (conv4_19): DualPathBlock(\n",
      "      (layers): Sequential(\n",
      "        (c1x1_a): Sequential(\n",
      "          (norm): BatchNorm2d(1504, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu): ReLU(inplace)\n",
      "          (conv): Conv2d(1504, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (c3x3_b): Sequential(\n",
      "          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu): ReLU(inplace)\n",
      "          (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        )\n",
      "        (c1x1_c): Sequential(\n",
      "          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu): ReLU(inplace)\n",
      "          (conv): Conv2d(384, 1048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (conv4_20): DualPathBlock(\n",
      "      (layers): Sequential(\n",
      "        (c1x1_a): Sequential(\n",
      "          (norm): BatchNorm2d(1528, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu): ReLU(inplace)\n",
      "          (conv): Conv2d(1528, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (c3x3_b): Sequential(\n",
      "          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu): ReLU(inplace)\n",
      "          (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        )\n",
      "        (c1x1_c): Sequential(\n",
      "          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu): ReLU(inplace)\n",
      "          (conv): Conv2d(384, 1048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (conv5_1): DualPathBlock(\n",
      "      (c1x1_w): Sequential(\n",
      "        (norm): BatchNorm2d(1552, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu): ReLU(inplace)\n",
      "        (conv): Conv2d(1552, 2304, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      )\n",
      "      (layers): Sequential(\n",
      "        (c1x1_a): Sequential(\n",
      "          (norm): BatchNorm2d(1552, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu): ReLU(inplace)\n",
      "          (conv): Conv2d(1552, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (c3x3_b): Sequential(\n",
      "          (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu): ReLU(inplace)\n",
      "          (conv): Conv2d(768, 768, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
      "        )\n",
      "        (c1x1_c): Sequential(\n",
      "          (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu): ReLU(inplace)\n",
      "          (conv): Conv2d(768, 2176, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (conv5_2): DualPathBlock(\n",
      "      (layers): Sequential(\n",
      "        (c1x1_a): Sequential(\n",
      "          (norm): BatchNorm2d(2432, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu): ReLU(inplace)\n",
      "          (conv): Conv2d(2432, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (c3x3_b): Sequential(\n",
      "          (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu): ReLU(inplace)\n",
      "          (conv): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        )\n",
      "        (c1x1_c): Sequential(\n",
      "          (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu): ReLU(inplace)\n",
      "          (conv): Conv2d(768, 2176, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (conv5_3): DualPathBlock(\n",
      "      (layers): Sequential(\n",
      "        (c1x1_a): Sequential(\n",
      "          (norm): BatchNorm2d(2560, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu): ReLU(inplace)\n",
      "          (conv): Conv2d(2560, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (c3x3_b): Sequential(\n",
      "          (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu): ReLU(inplace)\n",
      "          (conv): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        )\n",
      "        (c1x1_c): Sequential(\n",
      "          (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu): ReLU(inplace)\n",
      "          (conv): Conv2d(768, 2176, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (classifier): Linear(in_features=2688, out_features=12, bias=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "import math \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from collections import OrderedDict\n",
    "from torch.nn import init\n",
    "import numpy as np\n",
    "\n",
    "# model = SimpleNet(len(classes), 3)\n",
    "# model =vggnetXX_generic(len(classes), 3)\n",
    "# model =lenetXX_generic(len(classes), 3)\n",
    "# model =resnetxtXX_generic(len(classes), 3)\n",
    "# model =wrnXX_generic(len(classes), 3)\n",
    "model =dpn92(len(classes))\n",
    "# model = senetXX_generic(len(classes), 3, 32)\n",
    "\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "lr= 0.00005 * 2 * 2\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=lr)\n",
    "\n",
    "if use_cuda:\n",
    "    model = model.cuda()\n",
    "# model = senetXX_generic(len(classes), 3, 32)\n",
    "model_name = (type(model).__name__) # remember the real name\n",
    "# model = torch.nn.DataParallel(model, device_ids=list(range(4)))\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v4YEou5EzpSq"
   },
   "source": [
    "# Metrics and Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {}
     ]
    },
    "colab_type": "code",
    "id": "KZiIF6zYzpSs",
    "outputId": "25793eed-e107-433b-e174-39e8ce5308c3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0:16:40.00'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime \n",
    "\n",
    "from utils import *\n",
    "\n",
    "NOW_TIME = datetime.datetime.now()\n",
    "NOW_TIME =NOW_TIME.strftime(\"%Y-%m-%d %H:%M\")\n",
    "\n",
    "use_tensorboard=False\n",
    "\n",
    "hms_string(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tZ3OlGCxzpSw"
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {}
     ]
    },
    "colab_type": "code",
    "id": "HDwDNmfUzpSz",
    "outputId": "2921aeb9-53a5-4fbe-ff89-9ac0d19923e3"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm \n",
    "from sklearn import metrics\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn import cross_validation\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_auc_score, log_loss, roc_auc_score, roc_curve, auc\n",
    "\n",
    "def train(train_loader, model, epoch, optimizer):\n",
    "    if use_cuda:\n",
    "        model.cuda()\n",
    "        criterion.cuda()\n",
    "\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    acc = AverageMeter()\n",
    "   \n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "\n",
    "    end = time.time()\n",
    "    for batch_idx, (images, target) in enumerate(train_loader): \n",
    "        correct = 0\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        if use_cuda:\n",
    "            images, target = images.cuda(), target.cuda()\n",
    "            images, target = Variable(images), Variable(target)\n",
    "        # compute y_pred\n",
    "        y_pred = model(images)\n",
    "        loss = criterion(y_pred, target)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        prec1, prec1 = accuracy2(y_pred.data, target.data, topk=(1, 1))\n",
    "        losses.update(loss.data[0], images.size(0))\n",
    "        acc.update(prec1[0], images.size(0))\n",
    "        \n",
    "        pred = y_pred.data.max(1)[1] # get the index of the max log-probability\n",
    "        correct += pred.eq(target.data).cpu().sum()\n",
    "        accuracy = 100. * correct / len(images)\n",
    "        \n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if batch_idx % 200  == 0:\n",
    "            print('TRAIN: LOSS-->{loss.val:.4f} ({loss.avg:.4f})\\t' 'ACC-->{acc.val:.3f}% ({acc.avg:.3f}%)'.format(loss=losses, acc=acc))\n",
    "            if use_tensorboard:\n",
    "                exp.add_scalar_value('tr_epoch_loss', losses.avg, step=epoch)\n",
    "                exp.add_scalar_value('tr_epoch_acc', acc.avg, step=epoch)\n",
    "                \n",
    "            print('TRAIN: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}, Accuracy: {}/{} ({:.3f}%)'.format(\n",
    "                epoch, batch_idx * len(images), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.data[0],\n",
    "                correct, len(images),\n",
    "                accuracy))            \n",
    "    \n",
    "\n",
    "    return float('{loss.avg:.4f}'.format(loss=losses)), float('{acc.avg:.4f}'.format(acc=acc))\n",
    "\n",
    "def validate(val_loader, model, epoch):\n",
    "    if use_cuda:\n",
    "        model.cuda()\n",
    "        criterion.cuda()\n",
    "\n",
    "    batch_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    acc = AverageMeter()\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (images, labels) in enumerate(val_loader):\n",
    "\n",
    "        if use_cuda:\n",
    "            images, labels = images.cuda(), labels.cuda()\n",
    "            images, labels = Variable(images, volatile=True), Variable(labels)\n",
    "\n",
    "        # compute y_pred\n",
    "        y_pred = model(images)\n",
    "        loss = criterion(y_pred, labels)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        prec1, temp_var = accuracy2(y_pred.data, labels.data, topk=(1, 1))\n",
    "        losses.update(loss.data[0], images.size(0))\n",
    "        acc.update(prec1[0], images.size(0))\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if i % 200== 0:\n",
    "            print('VAL:   LOSS--> {loss.val:.4f} ({loss.avg:.4f})\\t''ACC-->{acc.val:.3f} ({acc.avg:.3f})'.format(loss=losses, acc=acc))\n",
    "\n",
    "        if i % 50 == 0:\n",
    "            if use_tensorboard:\n",
    "                exp.add_scalar_value('val_epoch_loss', losses.avg, step=epoch)\n",
    "                exp.add_scalar_value('val_epoch_acc', acc.avg, step=epoch)\n",
    "\n",
    "    print(' * Accuracy {acc.avg:.4f}'.format(acc=acc))\n",
    "    return float('{loss.avg:.6f}'.format(loss=losses)), float('{acc.avg:.6f}'.format(acc=acc))\n",
    "\n",
    "\n",
    "def testImageLoader(image_name):\n",
    "    \"\"\"load image, returns cuda tensor\"\"\"\n",
    "#     image = Image.open(image_name)\n",
    "    image = Image.open(image_name).convert('RGB')\n",
    "    image = test_trans(image)\n",
    "#     image = Variable(image, requires_grad=True)\n",
    "    image = image.unsqueeze(0)  \n",
    "    if use_cuda:\n",
    "#         print (\"cuda\")\n",
    "        image.cuda()         \n",
    "    return image  \n",
    "\n",
    "def testModel(test_dir, local_model):    \n",
    "    if use_cuda:\n",
    "        local_model.cuda()\n",
    "    \n",
    "    local_model.eval()\n",
    "    \n",
    "    columns = ['file', 'species']\n",
    "    df_pred = pd.DataFrame(data=np.zeros((0, len(columns))), columns=columns)\n",
    "#     df_pred.species.astype(int)\n",
    "    for index, row in (sample_submission.iterrows()):\n",
    "#         for file in os.listdir(test_dir):            \n",
    "        currImage=os.path.join(test_dir, row['file'])\n",
    "        if os.path.isfile(currImage):\n",
    "            X_tensor_test=testImageLoader (currImage)            \n",
    "#             print (type(X_tensor_test))\n",
    "            if use_cuda:\n",
    "                X_tensor_test = Variable(X_tensor_test.cuda()) \n",
    "            else:\n",
    "                X_tensor_test = Variable(X_tensor_test)        \n",
    "            \n",
    "            # get the index of the max log-probability\n",
    "            predicted_val = (local_model(X_tensor_test)).data.max(1)[1] # get the index of the max log-probability\n",
    "#             predicted_val = predicted_val.data.max(1, keepdim=True)[1]\n",
    "            p_test = (predicted_val.cpu().numpy().item())\n",
    "            df_pred = df_pred.append({'file': row['file'], 'species': num_to_class[int(p_test)]}, ignore_index=True)             \n",
    "    \n",
    "    return df_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rTtKoAUczpS6"
   },
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {}
     ]
    },
    "colab_type": "code",
    "id": "tYY0L_BkzpS7",
    "outputId": "be6367a0-8bb0-485f-94c8-4ac8136bebe2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Seed: 2222\n",
      "python version : 3.6.2 |Anaconda custom (64-bit)| (default, Sep 19 2017, 08:03:39) [MSC v.1900 64 bit (AMD64)]\n",
      "torch  version : 0.3.1.post2\n",
      "cudnn  version : 7003\n",
      "=> Final model name 'DPN'\n",
      "MODEL: DPN\n",
      "dataset: seedlings\n",
      "    Total params: 35.01M\n",
      "MODEL: DPN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                                                                                           | 0/220 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->2.4876 (2.4876)\tACC-->0.000% (0.000%)\n",
      "TRAIN: 0 [0/4038 (0%)]\tLoss: 2.487592, Accuracy: 0/8 (0.000%)\n",
      "TRAIN: LOSS-->2.1794 (2.4797)\tACC-->25.000% (16.915%)\n",
      "TRAIN: 0 [1600/4038 (40%)]\tLoss: 2.179369, Accuracy: 2/8 (25.000%)\n",
      "TRAIN: LOSS-->1.8762 (2.3380)\tACC-->25.000% (20.667%)\n",
      "TRAIN: 0 [3200/4038 (79%)]\tLoss: 1.876172, Accuracy: 2/8 (25.000%)\n",
      "VAL:   LOSS--> 1.8210 (1.8210)\tACC-->37.500 (37.500)\n",
      " * Accuracy 31.4607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|▋                                                                                                                                               | 1/220 [02:40<9:44:47, 160.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->2.8310 (2.8310)\tACC-->12.500% (12.500%)\n",
      "TRAIN: 1 [0/4038 (0%)]\tLoss: 2.830983, Accuracy: 1/8 (12.500%)\n",
      "TRAIN: LOSS-->1.8975 (2.0213)\tACC-->37.500% (31.032%)\n",
      "TRAIN: 1 [1600/4038 (40%)]\tLoss: 1.897545, Accuracy: 3/8 (37.500%)\n",
      "TRAIN: LOSS-->1.6882 (1.9702)\tACC-->50.000% (33.292%)\n",
      "TRAIN: 1 [3200/4038 (79%)]\tLoss: 1.688155, Accuracy: 4/8 (50.000%)\n",
      "VAL:   LOSS--> 1.0810 (1.0810)\tACC-->62.500 (62.500)\n",
      " * Accuracy 41.7135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|█▎                                                                                                                                              | 2/220 [05:18<9:39:19, 159.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->2.7716 (2.7716)\tACC-->12.500% (12.500%)\n",
      "TRAIN: 2 [0/4038 (0%)]\tLoss: 2.771613, Accuracy: 1/8 (12.500%)\n",
      "TRAIN: LOSS-->2.1086 (1.8379)\tACC-->37.500% (36.505%)\n",
      "TRAIN: 2 [1600/4038 (40%)]\tLoss: 2.108582, Accuracy: 3/8 (37.500%)\n",
      "TRAIN: LOSS-->2.0125 (1.8215)\tACC-->25.000% (37.531%)\n",
      "TRAIN: 2 [3200/4038 (79%)]\tLoss: 2.012476, Accuracy: 2/8 (25.000%)\n",
      "VAL:   LOSS--> 1.2555 (1.2555)\tACC-->62.500 (62.500)\n",
      " * Accuracy 53.7921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|█▉                                                                                                                                              | 3/220 [07:57<9:35:51, 159.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->1.5207 (1.5207)\tACC-->25.000% (25.000%)\n",
      "TRAIN: 3 [0/4038 (0%)]\tLoss: 1.520744, Accuracy: 2/8 (25.000%)\n",
      "TRAIN: LOSS-->1.4634 (1.6676)\tACC-->50.000% (42.724%)\n",
      "TRAIN: 3 [1600/4038 (40%)]\tLoss: 1.463439, Accuracy: 4/8 (50.000%)\n",
      "TRAIN: LOSS-->0.9793 (1.6502)\tACC-->75.000% (43.890%)\n",
      "TRAIN: 3 [3200/4038 (79%)]\tLoss: 0.979265, Accuracy: 6/8 (75.000%)\n",
      "VAL:   LOSS--> 1.0562 (1.0562)\tACC-->50.000 (50.000)\n",
      " * Accuracy 57.0225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|██▌                                                                                                                                             | 4/220 [10:36<9:32:49, 159.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->1.2748 (1.2748)\tACC-->62.500% (62.500%)\n",
      "TRAIN: 4 [0/4038 (0%)]\tLoss: 1.274846, Accuracy: 5/8 (62.500%)\n",
      "TRAIN: LOSS-->2.0716 (1.5953)\tACC-->37.500% (44.341%)\n",
      "TRAIN: 4 [1600/4038 (40%)]\tLoss: 2.071552, Accuracy: 3/8 (37.500%)\n",
      "TRAIN: LOSS-->1.4450 (1.5777)\tACC-->62.500% (45.480%)\n",
      "TRAIN: 4 [3200/4038 (79%)]\tLoss: 1.445018, Accuracy: 5/8 (62.500%)\n",
      "VAL:   LOSS--> 1.3914 (1.3914)\tACC-->62.500 (62.500)\n",
      " * Accuracy 59.8315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|███▎                                                                                                                                            | 5/220 [13:14<9:29:44, 159.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->1.3404 (1.3404)\tACC-->50.000% (50.000%)\n",
      "TRAIN: 5 [0/4038 (0%)]\tLoss: 1.340355, Accuracy: 4/8 (50.000%)\n",
      "TRAIN: LOSS-->1.8233 (1.4606)\tACC-->25.000% (48.694%)\n",
      "TRAIN: 5 [1600/4038 (40%)]\tLoss: 1.823300, Accuracy: 2/8 (25.000%)\n",
      "TRAIN: LOSS-->1.1691 (1.4411)\tACC-->50.000% (49.751%)\n",
      "TRAIN: 5 [3200/4038 (79%)]\tLoss: 1.169054, Accuracy: 4/8 (50.000%)\n",
      "VAL:   LOSS--> 0.6989 (0.6989)\tACC-->87.500 (87.500)\n",
      " * Accuracy 64.1854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|███▉                                                                                                                                            | 6/220 [15:53<9:26:41, 158.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.9702 (0.9702)\tACC-->62.500% (62.500%)\n",
      "TRAIN: 6 [0/4038 (0%)]\tLoss: 0.970168, Accuracy: 5/8 (62.500%)\n",
      "TRAIN: LOSS-->1.1699 (1.3441)\tACC-->50.000% (54.104%)\n",
      "TRAIN: 6 [1600/4038 (40%)]\tLoss: 1.169942, Accuracy: 4/8 (50.000%)\n",
      "TRAIN: LOSS-->0.9112 (1.3153)\tACC-->75.000% (54.738%)\n",
      "TRAIN: 6 [3200/4038 (79%)]\tLoss: 0.911197, Accuracy: 6/8 (75.000%)\n",
      "VAL:   LOSS--> 1.2636 (1.2636)\tACC-->62.500 (62.500)\n",
      " * Accuracy 65.0281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|████▌                                                                                                                                           | 7/220 [18:31<9:23:51, 158.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->1.7077 (1.7077)\tACC-->50.000% (50.000%)\n",
      "TRAIN: 7 [0/4038 (0%)]\tLoss: 1.707706, Accuracy: 4/8 (50.000%)\n",
      "TRAIN: LOSS-->2.2554 (1.2211)\tACC-->25.000% (59.017%)\n",
      "TRAIN: 7 [1600/4038 (40%)]\tLoss: 2.255445, Accuracy: 2/8 (25.000%)\n",
      "TRAIN: LOSS-->1.9064 (1.2368)\tACC-->37.500% (58.074%)\n",
      "TRAIN: 7 [3200/4038 (79%)]\tLoss: 1.906396, Accuracy: 3/8 (37.500%)\n",
      "VAL:   LOSS--> 0.1512 (0.1512)\tACC-->100.000 (100.000)\n",
      " * Accuracy 74.7191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|█████▏                                                                                                                                          | 8/220 [21:09<9:20:51, 158.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.5032 (0.5032)\tACC-->87.500% (87.500%)\n",
      "TRAIN: 8 [0/4038 (0%)]\tLoss: 0.503199, Accuracy: 7/8 (87.500%)\n",
      "TRAIN: LOSS-->0.3627 (1.1634)\tACC-->100.000% (61.381%)\n",
      "TRAIN: 8 [1600/4038 (40%)]\tLoss: 0.362664, Accuracy: 8/8 (100.000%)\n",
      "TRAIN: LOSS-->1.0700 (1.1451)\tACC-->50.000% (61.908%)\n",
      "TRAIN: 8 [3200/4038 (79%)]\tLoss: 1.069963, Accuracy: 4/8 (50.000%)\n",
      "VAL:   LOSS--> 1.1663 (1.1663)\tACC-->75.000 (75.000)\n",
      " * Accuracy 76.1236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|█████▉                                                                                                                                          | 9/220 [23:48<9:18:11, 158.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->1.1870 (1.1870)\tACC-->62.500% (62.500%)\n",
      "TRAIN: 9 [0/4038 (0%)]\tLoss: 1.187040, Accuracy: 5/8 (62.500%)\n",
      "TRAIN: LOSS-->2.2966 (1.1651)\tACC-->25.000% (60.945%)\n",
      "TRAIN: 9 [1600/4038 (40%)]\tLoss: 2.296613, Accuracy: 2/8 (25.000%)\n",
      "TRAIN: LOSS-->0.7222 (1.1183)\tACC-->75.000% (61.596%)\n",
      "TRAIN: 9 [3200/4038 (79%)]\tLoss: 0.722152, Accuracy: 6/8 (75.000%)\n",
      "VAL:   LOSS--> 0.3919 (0.3919)\tACC-->87.500 (87.500)\n",
      " * Accuracy 77.2472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|██████▌                                                                                                                                        | 10/220 [26:27<9:15:33, 158.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->1.4551 (1.4551)\tACC-->25.000% (25.000%)\n",
      "TRAIN: 10 [0/4038 (0%)]\tLoss: 1.455114, Accuracy: 2/8 (25.000%)\n",
      "TRAIN: LOSS-->0.7128 (1.0018)\tACC-->75.000% (66.107%)\n",
      "TRAIN: 10 [1600/4038 (40%)]\tLoss: 0.712834, Accuracy: 6/8 (75.000%)\n",
      "TRAIN: LOSS-->0.4101 (1.0028)\tACC-->87.500% (66.739%)\n",
      "TRAIN: 10 [3200/4038 (79%)]\tLoss: 0.410130, Accuracy: 7/8 (87.500%)\n",
      "VAL:   LOSS--> 2.1863 (2.1863)\tACC-->62.500 (62.500)\n",
      " * Accuracy 71.2079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|███████▏                                                                                                                                       | 11/220 [29:06<9:12:55, 158.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->1.5684 (1.5684)\tACC-->62.500% (62.500%)\n",
      "TRAIN: 11 [0/4038 (0%)]\tLoss: 1.568399, Accuracy: 5/8 (62.500%)\n",
      "TRAIN: LOSS-->0.9281 (1.0045)\tACC-->62.500% (65.050%)\n",
      "TRAIN: 11 [1600/4038 (40%)]\tLoss: 0.928113, Accuracy: 5/8 (62.500%)\n",
      "TRAIN: LOSS-->1.0517 (0.9974)\tACC-->50.000% (65.680%)\n",
      "TRAIN: 11 [3200/4038 (79%)]\tLoss: 1.051731, Accuracy: 4/8 (50.000%)\n",
      "VAL:   LOSS--> 0.7237 (0.7237)\tACC-->75.000 (75.000)\n",
      " * Accuracy 81.1798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|███████▊                                                                                                                                       | 12/220 [31:44<9:10:10, 158.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.9507 (0.9507)\tACC-->75.000% (75.000%)\n",
      "TRAIN: 12 [0/4038 (0%)]\tLoss: 0.950652, Accuracy: 6/8 (75.000%)\n",
      "TRAIN: LOSS-->0.4818 (0.9331)\tACC-->75.000% (67.973%)\n",
      "TRAIN: 12 [1600/4038 (40%)]\tLoss: 0.481806, Accuracy: 6/8 (75.000%)\n",
      "TRAIN: LOSS-->1.1790 (0.9234)\tACC-->62.500% (68.547%)\n",
      "TRAIN: 12 [3200/4038 (79%)]\tLoss: 1.178977, Accuracy: 5/8 (62.500%)\n",
      "VAL:   LOSS--> 0.3664 (0.3664)\tACC-->87.500 (87.500)\n",
      " * Accuracy 71.9101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|████████▍                                                                                                                                      | 13/220 [34:23<9:07:30, 158.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->1.0658 (1.0658)\tACC-->62.500% (62.500%)\n",
      "TRAIN: 13 [0/4038 (0%)]\tLoss: 1.065802, Accuracy: 5/8 (62.500%)\n",
      "TRAIN: LOSS-->0.8818 (0.9136)\tACC-->50.000% (68.532%)\n",
      "TRAIN: 13 [1600/4038 (40%)]\tLoss: 0.881802, Accuracy: 4/8 (50.000%)\n",
      "TRAIN: LOSS-->0.8210 (0.9162)\tACC-->62.500% (68.392%)\n",
      "TRAIN: 13 [3200/4038 (79%)]\tLoss: 0.821032, Accuracy: 5/8 (62.500%)\n",
      "VAL:   LOSS--> 0.4501 (0.4501)\tACC-->87.500 (87.500)\n",
      " * Accuracy 82.7247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|█████████                                                                                                                                      | 14/220 [37:01<9:04:53, 158.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->1.2219 (1.2219)\tACC-->75.000% (75.000%)\n",
      "TRAIN: 14 [0/4038 (0%)]\tLoss: 1.221859, Accuracy: 6/8 (75.000%)\n",
      "TRAIN: LOSS-->1.4146 (0.8367)\tACC-->50.000% (72.388%)\n",
      "TRAIN: 14 [1600/4038 (40%)]\tLoss: 1.414559, Accuracy: 4/8 (50.000%)\n",
      "TRAIN: LOSS-->1.0058 (0.8549)\tACC-->87.500% (71.072%)\n",
      "TRAIN: 14 [3200/4038 (79%)]\tLoss: 1.005817, Accuracy: 7/8 (87.500%)\n",
      "VAL:   LOSS--> 0.1154 (0.1154)\tACC-->100.000 (100.000)\n",
      " * Accuracy 86.0955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|█████████▊                                                                                                                                     | 15/220 [39:40<9:02:10, 158.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->1.0150 (1.0150)\tACC-->62.500% (62.500%)\n",
      "TRAIN: 15 [0/4038 (0%)]\tLoss: 1.015031, Accuracy: 5/8 (62.500%)\n",
      "TRAIN: LOSS-->1.2241 (0.8620)\tACC-->50.000% (70.087%)\n",
      "TRAIN: 15 [1600/4038 (40%)]\tLoss: 1.224064, Accuracy: 4/8 (50.000%)\n",
      "TRAIN: LOSS-->0.6226 (0.8478)\tACC-->75.000% (70.948%)\n",
      "TRAIN: 15 [3200/4038 (79%)]\tLoss: 0.622630, Accuracy: 6/8 (75.000%)\n",
      "VAL:   LOSS--> 0.4759 (0.4759)\tACC-->87.500 (87.500)\n",
      " * Accuracy 83.5674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|██████████▍                                                                                                                                    | 16/220 [42:18<8:59:30, 158.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.2623 (0.2623)\tACC-->100.000% (100.000%)\n",
      "TRAIN: 16 [0/4038 (0%)]\tLoss: 0.262262, Accuracy: 8/8 (100.000%)\n",
      "TRAIN: LOSS-->0.3827 (0.8036)\tACC-->100.000% (72.201%)\n",
      "TRAIN: 16 [1600/4038 (40%)]\tLoss: 0.382695, Accuracy: 8/8 (100.000%)\n",
      "TRAIN: LOSS-->0.4776 (0.8006)\tACC-->75.000% (72.319%)\n",
      "TRAIN: 16 [3200/4038 (79%)]\tLoss: 0.477594, Accuracy: 6/8 (75.000%)\n",
      "VAL:   LOSS--> 1.4568 (1.4568)\tACC-->62.500 (62.500)\n",
      " * Accuracy 83.2865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|███████████                                                                                                                                    | 17/220 [44:56<8:56:35, 158.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->1.0967 (1.0967)\tACC-->75.000% (75.000%)\n",
      "TRAIN: 17 [0/4038 (0%)]\tLoss: 1.096667, Accuracy: 6/8 (75.000%)\n",
      "TRAIN: LOSS-->0.2692 (0.7729)\tACC-->87.500% (73.383%)\n",
      "TRAIN: 17 [1600/4038 (40%)]\tLoss: 0.269154, Accuracy: 7/8 (87.500%)\n",
      "TRAIN: LOSS-->0.5624 (0.7767)\tACC-->62.500% (73.473%)\n",
      "TRAIN: 17 [3200/4038 (79%)]\tLoss: 0.562419, Accuracy: 5/8 (62.500%)\n",
      "VAL:   LOSS--> 0.1509 (0.1509)\tACC-->87.500 (87.500)\n",
      " * Accuracy 86.7978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|███████████▋                                                                                                                                   | 18/220 [47:34<8:53:54, 158.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.2461 (0.2461)\tACC-->100.000% (100.000%)\n",
      "TRAIN: 18 [0/4038 (0%)]\tLoss: 0.246105, Accuracy: 8/8 (100.000%)\n",
      "TRAIN: LOSS-->0.8146 (0.7841)\tACC-->62.500% (73.756%)\n",
      "TRAIN: 18 [1600/4038 (40%)]\tLoss: 0.814622, Accuracy: 5/8 (62.500%)\n",
      "TRAIN: LOSS-->1.6855 (0.7727)\tACC-->50.000% (74.002%)\n",
      "TRAIN: 18 [3200/4038 (79%)]\tLoss: 1.685504, Accuracy: 4/8 (50.000%)\n",
      "VAL:   LOSS--> 2.2272 (2.2272)\tACC-->75.000 (75.000)\n",
      " * Accuracy 86.3764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|████████████▎                                                                                                                                  | 19/220 [50:13<8:51:15, 158.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.4714 (0.4714)\tACC-->75.000% (75.000%)\n",
      "TRAIN: 19 [0/4038 (0%)]\tLoss: 0.471412, Accuracy: 6/8 (75.000%)\n",
      "TRAIN: LOSS-->0.0972 (0.7326)\tACC-->100.000% (74.751%)\n",
      "TRAIN: 19 [1600/4038 (40%)]\tLoss: 0.097229, Accuracy: 8/8 (100.000%)\n",
      "TRAIN: LOSS-->0.6978 (0.7398)\tACC-->87.500% (74.688%)\n",
      "TRAIN: 19 [3200/4038 (79%)]\tLoss: 0.697793, Accuracy: 7/8 (87.500%)\n",
      "VAL:   LOSS--> 0.1831 (0.1831)\tACC-->100.000 (100.000)\n",
      " * Accuracy 87.9213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|█████████████                                                                                                                                  | 20/220 [52:51<8:48:36, 158.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.7707 (0.7707)\tACC-->87.500% (87.500%)\n",
      "TRAIN: 20 [0/4038 (0%)]\tLoss: 0.770720, Accuracy: 7/8 (87.500%)\n",
      "TRAIN: LOSS-->0.3477 (0.7528)\tACC-->100.000% (73.756%)\n",
      "TRAIN: 20 [1600/4038 (40%)]\tLoss: 0.347696, Accuracy: 8/8 (100.000%)\n",
      "TRAIN: LOSS-->0.5601 (0.7514)\tACC-->75.000% (73.847%)\n",
      "TRAIN: 20 [3200/4038 (79%)]\tLoss: 0.560067, Accuracy: 6/8 (75.000%)\n",
      "VAL:   LOSS--> 0.1043 (0.1043)\tACC-->100.000 (100.000)\n",
      " * Accuracy 85.1124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|█████████████▋                                                                                                                                 | 21/220 [55:30<8:45:57, 158.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->1.5033 (1.5033)\tACC-->62.500% (62.500%)\n",
      "TRAIN: 21 [0/4038 (0%)]\tLoss: 1.503293, Accuracy: 5/8 (62.500%)\n",
      "TRAIN: LOSS-->0.4670 (0.7370)\tACC-->87.500% (75.560%)\n",
      "TRAIN: 21 [1600/4038 (40%)]\tLoss: 0.466959, Accuracy: 7/8 (87.500%)\n",
      "TRAIN: LOSS-->2.0581 (0.7498)\tACC-->50.000% (74.532%)\n",
      "TRAIN: 21 [3200/4038 (79%)]\tLoss: 2.058067, Accuracy: 4/8 (50.000%)\n",
      "VAL:   LOSS--> 0.7338 (0.7338)\tACC-->87.500 (87.500)\n",
      " * Accuracy 83.5674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|██████████████▎                                                                                                                                | 22/220 [58:08<8:43:16, 158.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.7509 (0.7509)\tACC-->75.000% (75.000%)\n",
      "TRAIN: 22 [0/4038 (0%)]\tLoss: 0.750878, Accuracy: 6/8 (75.000%)\n",
      "TRAIN: LOSS-->1.0479 (0.7723)\tACC-->75.000% (73.259%)\n",
      "TRAIN: 22 [1600/4038 (40%)]\tLoss: 1.047857, Accuracy: 6/8 (75.000%)\n",
      "TRAIN: LOSS-->0.8517 (0.7184)\tACC-->62.500% (75.125%)\n",
      "TRAIN: 22 [3200/4038 (79%)]\tLoss: 0.851660, Accuracy: 5/8 (62.500%)\n",
      "VAL:   LOSS--> 0.4150 (0.4150)\tACC-->75.000 (75.000)\n",
      " * Accuracy 88.4831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|██████████████▋                                                                                                                              | 23/220 [1:00:45<8:40:28, 158.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.7339 (0.7339)\tACC-->87.500% (87.500%)\n",
      "TRAIN: 23 [0/4038 (0%)]\tLoss: 0.733872, Accuracy: 7/8 (87.500%)\n",
      "TRAIN: LOSS-->0.8662 (0.6669)\tACC-->50.000% (76.368%)\n",
      "TRAIN: 23 [1600/4038 (40%)]\tLoss: 0.866202, Accuracy: 4/8 (50.000%)\n",
      "TRAIN: LOSS-->0.7679 (0.6691)\tACC-->62.500% (76.808%)\n",
      "TRAIN: 23 [3200/4038 (79%)]\tLoss: 0.767851, Accuracy: 5/8 (62.500%)\n",
      "VAL:   LOSS--> 0.5422 (0.5422)\tACC-->75.000 (75.000)\n",
      " * Accuracy 87.2191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|███████████████▍                                                                                                                             | 24/220 [1:03:24<8:37:49, 158.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.3651 (0.3651)\tACC-->87.500% (87.500%)\n",
      "TRAIN: 24 [0/4038 (0%)]\tLoss: 0.365087, Accuracy: 7/8 (87.500%)\n",
      "TRAIN: LOSS-->0.8618 (0.6649)\tACC-->75.000% (77.612%)\n",
      "TRAIN: 24 [1600/4038 (40%)]\tLoss: 0.861804, Accuracy: 6/8 (75.000%)\n",
      "TRAIN: LOSS-->0.4945 (0.6519)\tACC-->87.500% (77.837%)\n",
      "TRAIN: 24 [3200/4038 (79%)]\tLoss: 0.494465, Accuracy: 7/8 (87.500%)\n",
      "VAL:   LOSS--> 0.0369 (0.0369)\tACC-->100.000 (100.000)\n",
      " * Accuracy 88.4831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|████████████████                                                                                                                             | 25/220 [1:06:02<8:35:10, 158.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.7208 (0.7208)\tACC-->75.000% (75.000%)\n",
      "TRAIN: 25 [0/4038 (0%)]\tLoss: 0.720845, Accuracy: 6/8 (75.000%)\n",
      "TRAIN: LOSS-->0.7865 (0.5862)\tACC-->62.500% (79.726%)\n",
      "TRAIN: 25 [1600/4038 (40%)]\tLoss: 0.786525, Accuracy: 5/8 (62.500%)\n",
      "TRAIN: LOSS-->1.2589 (0.6480)\tACC-->62.500% (77.868%)\n",
      "TRAIN: 25 [3200/4038 (79%)]\tLoss: 1.258940, Accuracy: 5/8 (62.500%)\n",
      "VAL:   LOSS--> 0.6194 (0.6194)\tACC-->87.500 (87.500)\n",
      " * Accuracy 83.4270\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|████████████████▋                                                                                                                            | 26/220 [1:08:41<8:32:31, 158.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.3341 (0.3341)\tACC-->100.000% (100.000%)\n",
      "TRAIN: 26 [0/4038 (0%)]\tLoss: 0.334062, Accuracy: 8/8 (100.000%)\n",
      "TRAIN: LOSS-->0.1332 (0.6668)\tACC-->100.000% (77.550%)\n",
      "TRAIN: 26 [1600/4038 (40%)]\tLoss: 0.133206, Accuracy: 8/8 (100.000%)\n",
      "TRAIN: LOSS-->1.4049 (0.6474)\tACC-->50.000% (78.180%)\n",
      "TRAIN: 26 [3200/4038 (79%)]\tLoss: 1.404896, Accuracy: 4/8 (50.000%)\n",
      "VAL:   LOSS--> 0.1563 (0.1563)\tACC-->100.000 (100.000)\n",
      " * Accuracy 89.3258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█████████████████▎                                                                                                                           | 27/220 [1:11:19<8:29:53, 158.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->1.3684 (1.3684)\tACC-->75.000% (75.000%)\n",
      "TRAIN: 27 [0/4038 (0%)]\tLoss: 1.368351, Accuracy: 6/8 (75.000%)\n",
      "TRAIN: LOSS-->0.4802 (0.6064)\tACC-->87.500% (79.291%)\n",
      "TRAIN: 27 [1600/4038 (40%)]\tLoss: 0.480216, Accuracy: 7/8 (87.500%)\n",
      "TRAIN: LOSS-->0.5553 (0.6132)\tACC-->87.500% (79.676%)\n",
      "TRAIN: 27 [3200/4038 (79%)]\tLoss: 0.555335, Accuracy: 7/8 (87.500%)\n",
      "VAL:   LOSS--> 0.0119 (0.0119)\tACC-->100.000 (100.000)\n",
      " * Accuracy 90.1685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|█████████████████▉                                                                                                                           | 28/220 [1:13:58<8:27:13, 158.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.7362 (0.7362)\tACC-->87.500% (87.500%)\n",
      "TRAIN: 28 [0/4038 (0%)]\tLoss: 0.736203, Accuracy: 7/8 (87.500%)\n",
      "TRAIN: LOSS-->0.5797 (0.6161)\tACC-->75.000% (78.545%)\n",
      "TRAIN: 28 [1600/4038 (40%)]\tLoss: 0.579736, Accuracy: 6/8 (75.000%)\n",
      "TRAIN: LOSS-->0.4981 (0.6077)\tACC-->75.000% (78.897%)\n",
      "TRAIN: 28 [3200/4038 (79%)]\tLoss: 0.498088, Accuracy: 6/8 (75.000%)\n",
      "VAL:   LOSS--> 0.0686 (0.0686)\tACC-->100.000 (100.000)\n",
      " * Accuracy 88.4831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|██████████████████▌                                                                                                                          | 29/220 [1:16:36<8:24:30, 158.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->1.0864 (1.0864)\tACC-->62.500% (62.500%)\n",
      "TRAIN: 29 [0/4038 (0%)]\tLoss: 1.086436, Accuracy: 5/8 (62.500%)\n",
      "TRAIN: LOSS-->0.5384 (0.6192)\tACC-->75.000% (77.923%)\n",
      "TRAIN: 29 [1600/4038 (40%)]\tLoss: 0.538437, Accuracy: 6/8 (75.000%)\n",
      "TRAIN: LOSS-->0.3111 (0.6110)\tACC-->87.500% (78.772%)\n",
      "TRAIN: 29 [3200/4038 (79%)]\tLoss: 0.311078, Accuracy: 7/8 (87.500%)\n",
      "VAL:   LOSS--> 0.0313 (0.0313)\tACC-->100.000 (100.000)\n",
      " * Accuracy 90.4494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|███████████████████▏                                                                                                                         | 30/220 [1:19:14<8:21:51, 158.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.3601 (0.3601)\tACC-->87.500% (87.500%)\n",
      "TRAIN: 30 [0/4038 (0%)]\tLoss: 0.360064, Accuracy: 7/8 (87.500%)\n",
      "TRAIN: LOSS-->0.0580 (0.5852)\tACC-->100.000% (80.037%)\n",
      "TRAIN: 30 [1600/4038 (40%)]\tLoss: 0.058009, Accuracy: 8/8 (100.000%)\n",
      "TRAIN: LOSS-->0.3554 (0.5974)\tACC-->87.500% (79.769%)\n",
      "TRAIN: 30 [3200/4038 (79%)]\tLoss: 0.355421, Accuracy: 7/8 (87.500%)\n",
      "VAL:   LOSS--> 0.1567 (0.1567)\tACC-->87.500 (87.500)\n",
      " * Accuracy 91.4326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|███████████████████▊                                                                                                                         | 31/220 [1:21:52<8:19:13, 158.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.7845 (0.7845)\tACC-->75.000% (75.000%)\n",
      "TRAIN: 31 [0/4038 (0%)]\tLoss: 0.784500, Accuracy: 6/8 (75.000%)\n",
      "TRAIN: LOSS-->0.1038 (0.5976)\tACC-->100.000% (79.913%)\n",
      "TRAIN: 31 [1600/4038 (40%)]\tLoss: 0.103761, Accuracy: 8/8 (100.000%)\n",
      "TRAIN: LOSS-->0.3827 (0.5729)\tACC-->87.500% (80.330%)\n",
      "TRAIN: 31 [3200/4038 (79%)]\tLoss: 0.382701, Accuracy: 7/8 (87.500%)\n",
      "VAL:   LOSS--> 0.2447 (0.2447)\tACC-->87.500 (87.500)\n",
      " * Accuracy 89.4663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|████████████████████▌                                                                                                                        | 32/220 [1:24:31<8:16:34, 158.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.2890 (0.2890)\tACC-->100.000% (100.000%)\n",
      "TRAIN: 32 [0/4038 (0%)]\tLoss: 0.288984, Accuracy: 8/8 (100.000%)\n",
      "TRAIN: LOSS-->0.6913 (0.5502)\tACC-->75.000% (80.908%)\n",
      "TRAIN: 32 [1600/4038 (40%)]\tLoss: 0.691340, Accuracy: 6/8 (75.000%)\n",
      "TRAIN: LOSS-->1.6745 (0.5750)\tACC-->62.500% (80.143%)\n",
      "TRAIN: 32 [3200/4038 (79%)]\tLoss: 1.674517, Accuracy: 5/8 (62.500%)\n",
      "VAL:   LOSS--> 0.4731 (0.4731)\tACC-->87.500 (87.500)\n",
      " * Accuracy 88.7640\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|█████████████████████▏                                                                                                                       | 33/220 [1:27:09<8:13:51, 158.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.3376 (0.3376)\tACC-->100.000% (100.000%)\n",
      "TRAIN: 33 [0/4038 (0%)]\tLoss: 0.337613, Accuracy: 8/8 (100.000%)\n",
      "TRAIN: LOSS-->0.6249 (0.5353)\tACC-->75.000% (80.970%)\n",
      "TRAIN: 33 [1600/4038 (40%)]\tLoss: 0.624945, Accuracy: 6/8 (75.000%)\n",
      "TRAIN: LOSS-->0.5492 (0.5574)\tACC-->75.000% (80.299%)\n",
      "TRAIN: 33 [3200/4038 (79%)]\tLoss: 0.549189, Accuracy: 6/8 (75.000%)\n",
      "VAL:   LOSS--> 0.6393 (0.6393)\tACC-->75.000 (75.000)\n",
      " * Accuracy 87.0787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|█████████████████████▊                                                                                                                       | 34/220 [1:29:46<8:11:09, 158.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->1.1823 (1.1823)\tACC-->75.000% (75.000%)\n",
      "TRAIN: 34 [0/4038 (0%)]\tLoss: 1.182288, Accuracy: 6/8 (75.000%)\n",
      "TRAIN: LOSS-->1.0723 (0.5423)\tACC-->62.500% (81.032%)\n",
      "TRAIN: 34 [1600/4038 (40%)]\tLoss: 1.072342, Accuracy: 5/8 (62.500%)\n",
      "TRAIN: LOSS-->0.3356 (0.5869)\tACC-->87.500% (80.081%)\n",
      "TRAIN: 34 [3200/4038 (79%)]\tLoss: 0.335611, Accuracy: 7/8 (87.500%)\n",
      "VAL:   LOSS--> 1.0279 (1.0279)\tACC-->62.500 (62.500)\n",
      " * Accuracy 87.9213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|██████████████████████▍                                                                                                                      | 35/220 [1:32:25<8:08:32, 158.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.1428 (0.1428)\tACC-->100.000% (100.000%)\n",
      "TRAIN: 35 [0/4038 (0%)]\tLoss: 0.142822, Accuracy: 8/8 (100.000%)\n",
      "TRAIN: LOSS-->0.6747 (0.5413)\tACC-->62.500% (80.659%)\n",
      "TRAIN: 35 [1600/4038 (40%)]\tLoss: 0.674741, Accuracy: 5/8 (62.500%)\n",
      "TRAIN: LOSS-->1.1746 (0.5480)\tACC-->62.500% (80.330%)\n",
      "TRAIN: 35 [3200/4038 (79%)]\tLoss: 1.174597, Accuracy: 5/8 (62.500%)\n",
      "VAL:   LOSS--> 0.4509 (0.4509)\tACC-->75.000 (75.000)\n",
      " * Accuracy 85.6742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|███████████████████████                                                                                                                      | 36/220 [1:35:04<8:05:56, 158.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.3133 (0.3133)\tACC-->87.500% (87.500%)\n",
      "TRAIN: 36 [0/4038 (0%)]\tLoss: 0.313309, Accuracy: 7/8 (87.500%)\n",
      "TRAIN: LOSS-->0.2356 (0.5284)\tACC-->87.500% (80.970%)\n",
      "TRAIN: 36 [1600/4038 (40%)]\tLoss: 0.235556, Accuracy: 7/8 (87.500%)\n",
      "TRAIN: LOSS-->0.2421 (0.5227)\tACC-->87.500% (81.203%)\n",
      "TRAIN: 36 [3200/4038 (79%)]\tLoss: 0.242138, Accuracy: 7/8 (87.500%)\n",
      "VAL:   LOSS--> 0.2892 (0.2892)\tACC-->87.500 (87.500)\n",
      " * Accuracy 89.4663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|███████████████████████▋                                                                                                                     | 37/220 [1:37:42<8:03:14, 158.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.6429 (0.6429)\tACC-->62.500% (62.500%)\n",
      "TRAIN: 37 [0/4038 (0%)]\tLoss: 0.642876, Accuracy: 5/8 (62.500%)\n",
      "TRAIN: LOSS-->0.2260 (0.5198)\tACC-->87.500% (82.400%)\n",
      "TRAIN: 37 [1600/4038 (40%)]\tLoss: 0.225956, Accuracy: 7/8 (87.500%)\n",
      "TRAIN: LOSS-->0.7678 (0.5377)\tACC-->75.000% (80.673%)\n",
      "TRAIN: 37 [3200/4038 (79%)]\tLoss: 0.767797, Accuracy: 6/8 (75.000%)\n",
      "VAL:   LOSS--> 0.0160 (0.0160)\tACC-->100.000 (100.000)\n",
      " * Accuracy 92.5562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|████████████████████████▎                                                                                                                    | 38/220 [1:40:19<8:00:32, 158.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.3975 (0.3975)\tACC-->87.500% (87.500%)\n",
      "TRAIN: 38 [0/4038 (0%)]\tLoss: 0.397479, Accuracy: 7/8 (87.500%)\n",
      "TRAIN: LOSS-->1.1974 (0.4884)\tACC-->62.500% (82.400%)\n",
      "TRAIN: 38 [1600/4038 (40%)]\tLoss: 1.197354, Accuracy: 5/8 (62.500%)\n",
      "TRAIN: LOSS-->0.2060 (0.4993)\tACC-->100.000% (82.170%)\n",
      "TRAIN: 38 [3200/4038 (79%)]\tLoss: 0.206001, Accuracy: 8/8 (100.000%)\n",
      "VAL:   LOSS--> 0.0015 (0.0015)\tACC-->100.000 (100.000)\n",
      " * Accuracy 92.5562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|████████████████████████▉                                                                                                                    | 39/220 [1:42:58<7:57:54, 158.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.5254 (0.5254)\tACC-->87.500% (87.500%)\n",
      "TRAIN: 39 [0/4038 (0%)]\tLoss: 0.525439, Accuracy: 7/8 (87.500%)\n",
      "TRAIN: LOSS-->0.5597 (0.4937)\tACC-->75.000% (82.960%)\n",
      "TRAIN: 39 [1600/4038 (40%)]\tLoss: 0.559654, Accuracy: 6/8 (75.000%)\n",
      "TRAIN: LOSS-->0.8585 (0.4948)\tACC-->62.500% (83.074%)\n",
      "TRAIN: 39 [3200/4038 (79%)]\tLoss: 0.858452, Accuracy: 5/8 (62.500%)\n",
      "VAL:   LOSS--> 0.2856 (0.2856)\tACC-->87.500 (87.500)\n",
      " * Accuracy 92.2753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|█████████████████████████▋                                                                                                                   | 40/220 [1:45:37<7:55:17, 158.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.2105 (0.2105)\tACC-->87.500% (87.500%)\n",
      "TRAIN: 40 [0/4038 (0%)]\tLoss: 0.210520, Accuracy: 7/8 (87.500%)\n",
      "TRAIN: LOSS-->0.4163 (0.5578)\tACC-->75.000% (80.100%)\n",
      "TRAIN: 40 [1600/4038 (40%)]\tLoss: 0.416310, Accuracy: 6/8 (75.000%)\n",
      "TRAIN: LOSS-->0.5381 (0.5059)\tACC-->62.500% (82.232%)\n",
      "TRAIN: 40 [3200/4038 (79%)]\tLoss: 0.538080, Accuracy: 5/8 (62.500%)\n",
      "VAL:   LOSS--> 0.0106 (0.0106)\tACC-->100.000 (100.000)\n",
      " * Accuracy 89.7472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 19%|██████████████████████████▎                                                                                                                  | 41/220 [1:48:15<7:52:39, 158.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.1443 (0.1443)\tACC-->100.000% (100.000%)\n",
      "TRAIN: 41 [0/4038 (0%)]\tLoss: 0.144347, Accuracy: 8/8 (100.000%)\n",
      "TRAIN: LOSS-->0.5279 (0.4844)\tACC-->75.000% (82.587%)\n",
      "TRAIN: 41 [1600/4038 (40%)]\tLoss: 0.527927, Accuracy: 6/8 (75.000%)\n",
      "TRAIN: LOSS-->0.3508 (0.4861)\tACC-->100.000% (82.762%)\n",
      "TRAIN: 41 [3200/4038 (79%)]\tLoss: 0.350775, Accuracy: 8/8 (100.000%)\n",
      "VAL:   LOSS--> 0.0152 (0.0152)\tACC-->100.000 (100.000)\n",
      " * Accuracy 90.8708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 19%|██████████████████████████▉                                                                                                                  | 42/220 [1:50:54<7:50:00, 158.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.2151 (0.2151)\tACC-->100.000% (100.000%)\n",
      "TRAIN: 42 [0/4038 (0%)]\tLoss: 0.215067, Accuracy: 8/8 (100.000%)\n",
      "TRAIN: LOSS-->0.7430 (0.4951)\tACC-->62.500% (83.209%)\n",
      "TRAIN: 42 [1600/4038 (40%)]\tLoss: 0.743021, Accuracy: 5/8 (62.500%)\n",
      "TRAIN: LOSS-->0.1555 (0.4835)\tACC-->100.000% (82.918%)\n",
      "TRAIN: 42 [3200/4038 (79%)]\tLoss: 0.155462, Accuracy: 8/8 (100.000%)\n",
      "VAL:   LOSS--> 0.1207 (0.1207)\tACC-->100.000 (100.000)\n",
      " * Accuracy 90.7303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|███████████████████████████▌                                                                                                                 | 43/220 [1:53:32<7:47:21, 158.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.5927 (0.5927)\tACC-->87.500% (87.500%)\n",
      "TRAIN: 43 [0/4038 (0%)]\tLoss: 0.592668, Accuracy: 7/8 (87.500%)\n",
      "TRAIN: LOSS-->0.6211 (0.4651)\tACC-->50.000% (83.955%)\n",
      "TRAIN: 43 [1600/4038 (40%)]\tLoss: 0.621132, Accuracy: 4/8 (50.000%)\n",
      "TRAIN: LOSS-->0.0564 (0.4814)\tACC-->100.000% (82.980%)\n",
      "TRAIN: 43 [3200/4038 (79%)]\tLoss: 0.056433, Accuracy: 8/8 (100.000%)\n",
      "VAL:   LOSS--> 0.0052 (0.0052)\tACC-->100.000 (100.000)\n",
      " * Accuracy 93.2584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████████████████████████▏                                                                                                                | 44/220 [1:56:11<7:44:44, 158.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.2587 (0.2587)\tACC-->100.000% (100.000%)\n",
      "TRAIN: 44 [0/4038 (0%)]\tLoss: 0.258656, Accuracy: 8/8 (100.000%)\n",
      "TRAIN: LOSS-->0.4752 (0.4583)\tACC-->75.000% (84.266%)\n",
      "TRAIN: 44 [1600/4038 (40%)]\tLoss: 0.475240, Accuracy: 6/8 (75.000%)\n",
      "TRAIN: LOSS-->0.6494 (0.4746)\tACC-->75.000% (83.385%)\n",
      "TRAIN: 44 [3200/4038 (79%)]\tLoss: 0.649438, Accuracy: 6/8 (75.000%)\n",
      "VAL:   LOSS--> 0.1908 (0.1908)\tACC-->100.000 (100.000)\n",
      " * Accuracy 90.3090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████████████████████████▊                                                                                                                | 45/220 [1:58:51<7:42:12, 158.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.2578 (0.2578)\tACC-->87.500% (87.500%)\n",
      "TRAIN: 45 [0/4038 (0%)]\tLoss: 0.257789, Accuracy: 7/8 (87.500%)\n",
      "TRAIN: LOSS-->0.2833 (0.4579)\tACC-->87.500% (83.520%)\n",
      "TRAIN: 45 [1600/4038 (40%)]\tLoss: 0.283258, Accuracy: 7/8 (87.500%)\n",
      "TRAIN: LOSS-->0.4447 (0.4812)\tACC-->87.500% (82.731%)\n",
      "TRAIN: 45 [3200/4038 (79%)]\tLoss: 0.444725, Accuracy: 7/8 (87.500%)\n",
      "VAL:   LOSS--> 0.0425 (0.0425)\tACC-->100.000 (100.000)\n",
      " * Accuracy 92.5562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 21%|█████████████████████████████▍                                                                                                               | 46/220 [2:01:29<7:39:33, 158.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.1827 (0.1827)\tACC-->100.000% (100.000%)\n",
      "TRAIN: 46 [0/4038 (0%)]\tLoss: 0.182749, Accuracy: 8/8 (100.000%)\n",
      "TRAIN: LOSS-->0.2761 (0.4634)\tACC-->100.000% (84.826%)\n",
      "TRAIN: 46 [1600/4038 (40%)]\tLoss: 0.276132, Accuracy: 8/8 (100.000%)\n",
      "TRAIN: LOSS-->0.3680 (0.4338)\tACC-->87.500% (85.817%)\n",
      "TRAIN: 46 [3200/4038 (79%)]\tLoss: 0.368005, Accuracy: 7/8 (87.500%)\n",
      "VAL:   LOSS--> 0.0421 (0.0421)\tACC-->100.000 (100.000)\n",
      " * Accuracy 91.8539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 21%|██████████████████████████████                                                                                                               | 47/220 [2:04:08<7:36:56, 158.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.9026 (0.9026)\tACC-->75.000% (75.000%)\n",
      "TRAIN: 47 [0/4038 (0%)]\tLoss: 0.902650, Accuracy: 6/8 (75.000%)\n",
      "TRAIN: LOSS-->0.1670 (0.4656)\tACC-->100.000% (84.515%)\n",
      "TRAIN: 47 [1600/4038 (40%)]\tLoss: 0.167040, Accuracy: 8/8 (100.000%)\n",
      "TRAIN: LOSS-->0.4949 (0.4486)\tACC-->75.000% (84.601%)\n",
      "TRAIN: 47 [3200/4038 (79%)]\tLoss: 0.494929, Accuracy: 6/8 (75.000%)\n",
      "VAL:   LOSS--> 0.0401 (0.0401)\tACC-->100.000 (100.000)\n",
      " * Accuracy 93.9607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██████████████████████████████▊                                                                                                              | 48/220 [2:06:46<7:34:16, 158.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.2444 (0.2444)\tACC-->100.000% (100.000%)\n",
      "TRAIN: 48 [0/4038 (0%)]\tLoss: 0.244359, Accuracy: 8/8 (100.000%)\n",
      "TRAIN: LOSS-->1.5015 (0.5019)\tACC-->37.500% (82.587%)\n",
      "TRAIN: 48 [1600/4038 (40%)]\tLoss: 1.501501, Accuracy: 3/8 (37.500%)\n",
      "TRAIN: LOSS-->0.1709 (0.4674)\tACC-->100.000% (84.009%)\n",
      "TRAIN: 48 [3200/4038 (79%)]\tLoss: 0.170915, Accuracy: 8/8 (100.000%)\n",
      "VAL:   LOSS--> 0.7843 (0.7843)\tACC-->87.500 (87.500)\n",
      " * Accuracy 91.2921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|███████████████████████████████▍                                                                                                             | 49/220 [2:09:24<7:31:38, 158.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.6168 (0.6168)\tACC-->75.000% (75.000%)\n",
      "TRAIN: 49 [0/4038 (0%)]\tLoss: 0.616786, Accuracy: 6/8 (75.000%)\n",
      "TRAIN: LOSS-->1.3449 (0.4927)\tACC-->62.500% (82.649%)\n",
      "TRAIN: 49 [1600/4038 (40%)]\tLoss: 1.344899, Accuracy: 5/8 (62.500%)\n",
      "TRAIN: LOSS-->0.0827 (0.4666)\tACC-->100.000% (83.541%)\n",
      "TRAIN: 49 [3200/4038 (79%)]\tLoss: 0.082693, Accuracy: 8/8 (100.000%)\n",
      "VAL:   LOSS--> 0.0654 (0.0654)\tACC-->100.000 (100.000)\n",
      " * Accuracy 91.4326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|████████████████████████████████                                                                                                             | 50/220 [2:12:03<7:28:58, 158.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.3640 (0.3640)\tACC-->87.500% (87.500%)\n",
      "TRAIN: 50 [0/4038 (0%)]\tLoss: 0.363986, Accuracy: 7/8 (87.500%)\n",
      "TRAIN: LOSS-->0.7408 (0.4423)\tACC-->75.000% (84.701%)\n",
      "TRAIN: 50 [1600/4038 (40%)]\tLoss: 0.740779, Accuracy: 6/8 (75.000%)\n",
      "TRAIN: LOSS-->0.1972 (0.4490)\tACC-->87.500% (84.258%)\n",
      "TRAIN: 50 [3200/4038 (79%)]\tLoss: 0.197152, Accuracy: 7/8 (87.500%)\n",
      "VAL:   LOSS--> 0.1480 (0.1480)\tACC-->87.500 (87.500)\n",
      " * Accuracy 93.1180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|████████████████████████████████▋                                                                                                            | 51/220 [2:14:41<7:26:19, 158.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.4274 (0.4274)\tACC-->87.500% (87.500%)\n",
      "TRAIN: 51 [0/4038 (0%)]\tLoss: 0.427439, Accuracy: 7/8 (87.500%)\n",
      "TRAIN: LOSS-->0.5444 (0.4159)\tACC-->62.500% (85.821%)\n",
      "TRAIN: 51 [1600/4038 (40%)]\tLoss: 0.544401, Accuracy: 5/8 (62.500%)\n",
      "TRAIN: LOSS-->0.2639 (0.4263)\tACC-->87.500% (85.100%)\n",
      "TRAIN: 51 [3200/4038 (79%)]\tLoss: 0.263948, Accuracy: 7/8 (87.500%)\n",
      "VAL:   LOSS--> 0.0171 (0.0171)\tACC-->100.000 (100.000)\n",
      " * Accuracy 91.4326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|█████████████████████████████████▎                                                                                                           | 52/220 [2:17:19<7:23:39, 158.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.2330 (0.2330)\tACC-->87.500% (87.500%)\n",
      "TRAIN: 52 [0/4038 (0%)]\tLoss: 0.232966, Accuracy: 7/8 (87.500%)\n",
      "TRAIN: LOSS-->0.0609 (0.4380)\tACC-->100.000% (85.697%)\n",
      "TRAIN: 52 [1600/4038 (40%)]\tLoss: 0.060897, Accuracy: 8/8 (100.000%)\n",
      "TRAIN: LOSS-->0.2236 (0.4428)\tACC-->87.500% (85.069%)\n",
      "TRAIN: 52 [3200/4038 (79%)]\tLoss: 0.223577, Accuracy: 7/8 (87.500%)\n",
      "VAL:   LOSS--> 0.1197 (0.1197)\tACC-->100.000 (100.000)\n",
      " * Accuracy 91.8539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|█████████████████████████████████▉                                                                                                           | 53/220 [2:19:57<7:21:00, 158.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.4381 (0.4381)\tACC-->87.500% (87.500%)\n",
      "TRAIN: 53 [0/4038 (0%)]\tLoss: 0.438095, Accuracy: 7/8 (87.500%)\n",
      "TRAIN: LOSS-->0.7802 (0.4782)\tACC-->75.000% (83.458%)\n",
      "TRAIN: 53 [1600/4038 (40%)]\tLoss: 0.780156, Accuracy: 6/8 (75.000%)\n",
      "TRAIN: LOSS-->0.7847 (0.4544)\tACC-->75.000% (84.663%)\n",
      "TRAIN: 53 [3200/4038 (79%)]\tLoss: 0.784693, Accuracy: 6/8 (75.000%)\n",
      "VAL:   LOSS--> 0.0109 (0.0109)\tACC-->100.000 (100.000)\n",
      " * Accuracy 91.5730\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██████████████████████████████████▌                                                                                                          | 54/220 [2:22:36<7:18:22, 158.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.0233 (0.0233)\tACC-->100.000% (100.000%)\n",
      "TRAIN: 54 [0/4038 (0%)]\tLoss: 0.023334, Accuracy: 8/8 (100.000%)\n",
      "TRAIN: LOSS-->0.0233 (0.4173)\tACC-->100.000% (85.697%)\n",
      "TRAIN: 54 [1600/4038 (40%)]\tLoss: 0.023257, Accuracy: 8/8 (100.000%)\n",
      "TRAIN: LOSS-->0.7239 (0.4243)\tACC-->87.500% (85.630%)\n",
      "TRAIN: 54 [3200/4038 (79%)]\tLoss: 0.723890, Accuracy: 7/8 (87.500%)\n",
      "VAL:   LOSS--> 0.0527 (0.0527)\tACC-->100.000 (100.000)\n",
      " * Accuracy 91.7135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|███████████████████████████████████▎                                                                                                         | 55/220 [2:25:14<7:15:43, 158.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.7655 (0.7655)\tACC-->87.500% (87.500%)\n",
      "TRAIN: 55 [0/4038 (0%)]\tLoss: 0.765481, Accuracy: 7/8 (87.500%)\n",
      "TRAIN: LOSS-->0.2387 (0.4332)\tACC-->87.500% (84.142%)\n",
      "TRAIN: 55 [1600/4038 (40%)]\tLoss: 0.238727, Accuracy: 7/8 (87.500%)\n",
      "TRAIN: LOSS-->0.3457 (0.4334)\tACC-->87.500% (84.944%)\n",
      "TRAIN: 55 [3200/4038 (79%)]\tLoss: 0.345722, Accuracy: 7/8 (87.500%)\n",
      "VAL:   LOSS--> 0.0393 (0.0393)\tACC-->100.000 (100.000)\n",
      " * Accuracy 92.2753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|███████████████████████████████████▉                                                                                                         | 56/220 [2:27:52<7:13:04, 158.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.5818 (0.5818)\tACC-->75.000% (75.000%)\n",
      "TRAIN: 56 [0/4038 (0%)]\tLoss: 0.581786, Accuracy: 6/8 (75.000%)\n",
      "TRAIN: LOSS-->0.7097 (0.4228)\tACC-->87.500% (83.893%)\n",
      "TRAIN: 56 [1600/4038 (40%)]\tLoss: 0.709657, Accuracy: 7/8 (87.500%)\n",
      "TRAIN: LOSS-->0.6933 (0.4083)\tACC-->75.000% (85.193%)\n",
      "TRAIN: 56 [3200/4038 (79%)]\tLoss: 0.693256, Accuracy: 6/8 (75.000%)\n",
      "VAL:   LOSS--> 0.0626 (0.0626)\tACC-->100.000 (100.000)\n",
      " * Accuracy 91.7135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|████████████████████████████████████▌                                                                                                        | 57/220 [2:30:31<7:10:25, 158.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.2752 (0.2752)\tACC-->87.500% (87.500%)\n",
      "TRAIN: 57 [0/4038 (0%)]\tLoss: 0.275196, Accuracy: 7/8 (87.500%)\n",
      "TRAIN: LOSS-->0.0220 (0.3908)\tACC-->100.000% (86.194%)\n",
      "TRAIN: 57 [1600/4038 (40%)]\tLoss: 0.022049, Accuracy: 8/8 (100.000%)\n",
      "TRAIN: LOSS-->0.2100 (0.3852)\tACC-->87.500% (86.004%)\n",
      "TRAIN: 57 [3200/4038 (79%)]\tLoss: 0.209983, Accuracy: 7/8 (87.500%)\n",
      "VAL:   LOSS--> 0.4031 (0.4031)\tACC-->87.500 (87.500)\n",
      " * Accuracy 91.4326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|█████████████████████████████████████▏                                                                                                       | 58/220 [2:33:09<7:07:47, 158.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.0998 (0.0998)\tACC-->100.000% (100.000%)\n",
      "TRAIN: 58 [0/4038 (0%)]\tLoss: 0.099778, Accuracy: 8/8 (100.000%)\n",
      "TRAIN: LOSS-->0.3669 (0.3946)\tACC-->87.500% (86.070%)\n",
      "TRAIN: 58 [1600/4038 (40%)]\tLoss: 0.366870, Accuracy: 7/8 (87.500%)\n",
      "TRAIN: LOSS-->0.1812 (0.3830)\tACC-->87.500% (86.409%)\n",
      "TRAIN: 58 [3200/4038 (79%)]\tLoss: 0.181239, Accuracy: 7/8 (87.500%)\n",
      "VAL:   LOSS--> 0.3222 (0.3222)\tACC-->75.000 (75.000)\n",
      " * Accuracy 95.3652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|█████████████████████████████████████▊                                                                                                       | 59/220 [2:35:48<7:05:09, 158.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->1.2461 (1.2461)\tACC-->50.000% (50.000%)\n",
      "TRAIN: 59 [0/4038 (0%)]\tLoss: 1.246063, Accuracy: 4/8 (50.000%)\n",
      "TRAIN: LOSS-->0.3287 (0.4730)\tACC-->75.000% (84.080%)\n",
      "TRAIN: 59 [1600/4038 (40%)]\tLoss: 0.328674, Accuracy: 6/8 (75.000%)\n",
      "TRAIN: LOSS-->0.2426 (0.4526)\tACC-->100.000% (84.975%)\n",
      "TRAIN: 59 [3200/4038 (79%)]\tLoss: 0.242630, Accuracy: 8/8 (100.000%)\n",
      "VAL:   LOSS--> 0.0721 (0.0721)\tACC-->100.000 (100.000)\n",
      " * Accuracy 93.1180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|██████████████████████████████████████▍                                                                                                      | 60/220 [2:38:26<7:02:31, 158.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.5175 (0.5175)\tACC-->75.000% (75.000%)\n",
      "TRAIN: 60 [0/4038 (0%)]\tLoss: 0.517535, Accuracy: 6/8 (75.000%)\n",
      "TRAIN: LOSS-->0.0198 (0.3891)\tACC-->100.000% (86.816%)\n",
      "TRAIN: 60 [1600/4038 (40%)]\tLoss: 0.019815, Accuracy: 8/8 (100.000%)\n",
      "TRAIN: LOSS-->0.5290 (0.4014)\tACC-->62.500% (86.222%)\n",
      "TRAIN: 60 [3200/4038 (79%)]\tLoss: 0.529005, Accuracy: 5/8 (62.500%)\n",
      "VAL:   LOSS--> 0.0643 (0.0643)\tACC-->100.000 (100.000)\n",
      " * Accuracy 93.5393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|███████████████████████████████████████                                                                                                      | 61/220 [2:41:05<6:59:52, 158.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.3523 (0.3523)\tACC-->87.500% (87.500%)\n",
      "TRAIN: 61 [0/4038 (0%)]\tLoss: 0.352316, Accuracy: 7/8 (87.500%)\n",
      "TRAIN: LOSS-->0.0094 (0.3915)\tACC-->100.000% (86.505%)\n",
      "TRAIN: 61 [1600/4038 (40%)]\tLoss: 0.009423, Accuracy: 8/8 (100.000%)\n",
      "TRAIN: LOSS-->0.3414 (0.3892)\tACC-->87.500% (86.814%)\n",
      "TRAIN: 61 [3200/4038 (79%)]\tLoss: 0.341356, Accuracy: 7/8 (87.500%)\n",
      "VAL:   LOSS--> 0.0130 (0.0130)\tACC-->100.000 (100.000)\n",
      " * Accuracy 93.2584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|███████████████████████████████████████▋                                                                                                     | 62/220 [2:43:44<6:57:15, 158.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.2974 (0.2974)\tACC-->87.500% (87.500%)\n",
      "TRAIN: 62 [0/4038 (0%)]\tLoss: 0.297434, Accuracy: 7/8 (87.500%)\n",
      "TRAIN: LOSS-->0.2922 (0.3855)\tACC-->87.500% (86.256%)\n",
      "TRAIN: 62 [1600/4038 (40%)]\tLoss: 0.292191, Accuracy: 7/8 (87.500%)\n",
      "TRAIN: LOSS-->0.8102 (0.3853)\tACC-->62.500% (86.409%)\n",
      "TRAIN: 62 [3200/4038 (79%)]\tLoss: 0.810238, Accuracy: 5/8 (62.500%)\n",
      "VAL:   LOSS--> 0.0016 (0.0016)\tACC-->100.000 (100.000)\n",
      " * Accuracy 91.8539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|████████████████████████████████████████▍                                                                                                    | 63/220 [2:46:27<6:54:49, 158.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.1131 (0.1131)\tACC-->100.000% (100.000%)\n",
      "TRAIN: 63 [0/4038 (0%)]\tLoss: 0.113072, Accuracy: 8/8 (100.000%)\n",
      "TRAIN: LOSS-->1.2951 (0.3946)\tACC-->62.500% (85.759%)\n",
      "TRAIN: 63 [1600/4038 (40%)]\tLoss: 1.295128, Accuracy: 5/8 (62.500%)\n",
      "TRAIN: LOSS-->0.2096 (0.3910)\tACC-->100.000% (86.222%)\n",
      "TRAIN: 63 [3200/4038 (79%)]\tLoss: 0.209595, Accuracy: 8/8 (100.000%)\n",
      "VAL:   LOSS--> 0.4982 (0.4982)\tACC-->75.000 (75.000)\n",
      " * Accuracy 93.2584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|█████████████████████████████████████████                                                                                                    | 64/220 [2:49:06<6:52:12, 158.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->1.1101 (1.1101)\tACC-->75.000% (75.000%)\n",
      "TRAIN: 64 [0/4038 (0%)]\tLoss: 1.110115, Accuracy: 6/8 (75.000%)\n",
      "TRAIN: LOSS-->0.3451 (0.3937)\tACC-->87.500% (86.629%)\n",
      "TRAIN: 64 [1600/4038 (40%)]\tLoss: 0.345134, Accuracy: 7/8 (87.500%)\n",
      "TRAIN: LOSS-->0.8323 (0.3860)\tACC-->87.500% (86.908%)\n",
      "TRAIN: 64 [3200/4038 (79%)]\tLoss: 0.832269, Accuracy: 7/8 (87.500%)\n",
      "VAL:   LOSS--> 0.1083 (0.1083)\tACC-->87.500 (87.500)\n",
      " * Accuracy 93.3989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|█████████████████████████████████████████▋                                                                                                   | 65/220 [2:51:45<6:49:35, 158.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.2464 (0.2464)\tACC-->75.000% (75.000%)\n",
      "TRAIN: 65 [0/4038 (0%)]\tLoss: 0.246391, Accuracy: 6/8 (75.000%)\n",
      "TRAIN: LOSS-->1.1351 (0.3913)\tACC-->75.000% (85.572%)\n",
      "TRAIN: 65 [1600/4038 (40%)]\tLoss: 1.135112, Accuracy: 6/8 (75.000%)\n",
      "TRAIN: LOSS-->0.0698 (0.3958)\tACC-->100.000% (85.567%)\n",
      "TRAIN: 65 [3200/4038 (79%)]\tLoss: 0.069827, Accuracy: 8/8 (100.000%)\n",
      "VAL:   LOSS--> 0.4468 (0.4468)\tACC-->87.500 (87.500)\n",
      " * Accuracy 89.3258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|██████████████████████████████████████████▎                                                                                                  | 66/220 [2:54:24<6:46:57, 158.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.2860 (0.2860)\tACC-->87.500% (87.500%)\n",
      "TRAIN: 66 [0/4038 (0%)]\tLoss: 0.285987, Accuracy: 7/8 (87.500%)\n",
      "TRAIN: LOSS-->0.0875 (0.3655)\tACC-->100.000% (87.065%)\n",
      "TRAIN: 66 [1600/4038 (40%)]\tLoss: 0.087491, Accuracy: 8/8 (100.000%)\n",
      "TRAIN: LOSS-->0.3513 (0.3609)\tACC-->87.500% (87.406%)\n",
      "TRAIN: 66 [3200/4038 (79%)]\tLoss: 0.351297, Accuracy: 7/8 (87.500%)\n",
      "VAL:   LOSS--> 0.0527 (0.0527)\tACC-->100.000 (100.000)\n",
      " * Accuracy 91.5730\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|██████████████████████████████████████████▉                                                                                                  | 67/220 [2:57:03<6:44:19, 158.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.2875 (0.2875)\tACC-->100.000% (100.000%)\n",
      "TRAIN: 67 [0/4038 (0%)]\tLoss: 0.287536, Accuracy: 8/8 (100.000%)\n",
      "TRAIN: LOSS-->0.8749 (0.3484)\tACC-->87.500% (87.998%)\n",
      "TRAIN: 67 [1600/4038 (40%)]\tLoss: 0.874934, Accuracy: 7/8 (87.500%)\n",
      "TRAIN: LOSS-->0.5303 (0.3635)\tACC-->87.500% (87.282%)\n",
      "TRAIN: 67 [3200/4038 (79%)]\tLoss: 0.530349, Accuracy: 7/8 (87.500%)\n",
      "VAL:   LOSS--> 0.0855 (0.0855)\tACC-->100.000 (100.000)\n",
      " * Accuracy 93.1180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 31%|███████████████████████████████████████████▌                                                                                                 | 68/220 [2:59:42<6:41:41, 158.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.4943 (0.4943)\tACC-->75.000% (75.000%)\n",
      "TRAIN: 68 [0/4038 (0%)]\tLoss: 0.494262, Accuracy: 6/8 (75.000%)\n",
      "TRAIN: LOSS-->0.0919 (0.3445)\tACC-->100.000% (88.060%)\n",
      "TRAIN: 68 [1600/4038 (40%)]\tLoss: 0.091920, Accuracy: 8/8 (100.000%)\n",
      "TRAIN: LOSS-->0.2724 (0.3574)\tACC-->87.500% (87.874%)\n",
      "TRAIN: 68 [3200/4038 (79%)]\tLoss: 0.272367, Accuracy: 7/8 (87.500%)\n",
      "VAL:   LOSS--> 0.0558 (0.0558)\tACC-->100.000 (100.000)\n",
      " * Accuracy 95.0843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 31%|████████████████████████████████████████████▏                                                                                                | 69/220 [3:02:21<6:39:03, 158.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.0736 (0.0736)\tACC-->100.000% (100.000%)\n",
      "TRAIN: 69 [0/4038 (0%)]\tLoss: 0.073554, Accuracy: 8/8 (100.000%)\n",
      "TRAIN: LOSS-->0.0685 (0.3293)\tACC-->100.000% (89.055%)\n",
      "TRAIN: 69 [1600/4038 (40%)]\tLoss: 0.068465, Accuracy: 8/8 (100.000%)\n",
      "TRAIN: LOSS-->0.2652 (0.3716)\tACC-->87.500% (87.562%)\n",
      "TRAIN: 69 [3200/4038 (79%)]\tLoss: 0.265225, Accuracy: 7/8 (87.500%)\n",
      "VAL:   LOSS--> 0.0332 (0.0332)\tACC-->100.000 (100.000)\n",
      " * Accuracy 94.6629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 32%|████████████████████████████████████████████▊                                                                                                | 70/220 [3:05:00<6:36:27, 158.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.7797 (0.7797)\tACC-->50.000% (50.000%)\n",
      "TRAIN: 70 [0/4038 (0%)]\tLoss: 0.779747, Accuracy: 4/8 (50.000%)\n",
      "TRAIN: LOSS-->0.1694 (0.3457)\tACC-->87.500% (87.624%)\n",
      "TRAIN: 70 [1600/4038 (40%)]\tLoss: 0.169373, Accuracy: 7/8 (87.500%)\n",
      "TRAIN: LOSS-->0.3277 (0.3555)\tACC-->87.500% (87.687%)\n",
      "TRAIN: 70 [3200/4038 (79%)]\tLoss: 0.327683, Accuracy: 7/8 (87.500%)\n",
      "VAL:   LOSS--> 0.0125 (0.0125)\tACC-->100.000 (100.000)\n",
      " * Accuracy 94.1011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 32%|█████████████████████████████████████████████▌                                                                                               | 71/220 [3:07:39<6:33:49, 158.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->2.4001 (2.4001)\tACC-->50.000% (50.000%)\n",
      "TRAIN: 71 [0/4038 (0%)]\tLoss: 2.400136, Accuracy: 4/8 (50.000%)\n",
      "TRAIN: LOSS-->0.3141 (0.4063)\tACC-->87.500% (86.381%)\n",
      "TRAIN: 71 [1600/4038 (40%)]\tLoss: 0.314071, Accuracy: 7/8 (87.500%)\n",
      "TRAIN: LOSS-->0.3752 (0.3832)\tACC-->87.500% (86.970%)\n",
      "TRAIN: 71 [3200/4038 (79%)]\tLoss: 0.375167, Accuracy: 7/8 (87.500%)\n",
      "VAL:   LOSS--> 0.0015 (0.0015)\tACC-->100.000 (100.000)\n",
      " * Accuracy 94.1011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|██████████████████████████████████████████████▏                                                                                              | 72/220 [3:10:19<6:31:12, 158.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.3590 (0.3590)\tACC-->87.500% (87.500%)\n",
      "TRAIN: 72 [0/4038 (0%)]\tLoss: 0.359045, Accuracy: 7/8 (87.500%)\n",
      "TRAIN: LOSS-->0.2946 (0.3947)\tACC-->87.500% (86.692%)\n",
      "TRAIN: 72 [1600/4038 (40%)]\tLoss: 0.294627, Accuracy: 7/8 (87.500%)\n",
      "TRAIN: LOSS-->0.4053 (0.3693)\tACC-->87.500% (87.282%)\n",
      "TRAIN: 72 [3200/4038 (79%)]\tLoss: 0.405337, Accuracy: 7/8 (87.500%)\n",
      "VAL:   LOSS--> 0.2336 (0.2336)\tACC-->87.500 (87.500)\n",
      " * Accuracy 93.1180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|██████████████████████████████████████████████▊                                                                                              | 73/220 [3:12:57<6:28:33, 158.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.4793 (0.4793)\tACC-->87.500% (87.500%)\n",
      "TRAIN: 73 [0/4038 (0%)]\tLoss: 0.479337, Accuracy: 7/8 (87.500%)\n",
      "TRAIN: LOSS-->0.4809 (0.3477)\tACC-->87.500% (88.246%)\n",
      "TRAIN: 73 [1600/4038 (40%)]\tLoss: 0.480927, Accuracy: 7/8 (87.500%)\n",
      "TRAIN: LOSS-->0.1694 (0.3681)\tACC-->87.500% (87.313%)\n",
      "TRAIN: 73 [3200/4038 (79%)]\tLoss: 0.169442, Accuracy: 7/8 (87.500%)\n",
      "VAL:   LOSS--> 0.0552 (0.0552)\tACC-->100.000 (100.000)\n",
      " * Accuracy 93.8202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 34%|███████████████████████████████████████████████▍                                                                                             | 74/220 [3:15:36<6:25:55, 158.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.1820 (0.1820)\tACC-->87.500% (87.500%)\n",
      "TRAIN: 74 [0/4038 (0%)]\tLoss: 0.182021, Accuracy: 7/8 (87.500%)\n",
      "TRAIN: LOSS-->0.8085 (0.3594)\tACC-->75.000% (87.313%)\n",
      "TRAIN: 74 [1600/4038 (40%)]\tLoss: 0.808472, Accuracy: 6/8 (75.000%)\n",
      "TRAIN: LOSS-->0.1094 (0.3415)\tACC-->100.000% (87.843%)\n",
      "TRAIN: 74 [3200/4038 (79%)]\tLoss: 0.109362, Accuracy: 8/8 (100.000%)\n",
      "VAL:   LOSS--> 0.3009 (0.3009)\tACC-->75.000 (75.000)\n",
      " * Accuracy 92.2753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 34%|████████████████████████████████████████████████                                                                                             | 75/220 [3:18:15<6:23:17, 158.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.2036 (0.2036)\tACC-->87.500% (87.500%)\n",
      "TRAIN: 75 [0/4038 (0%)]\tLoss: 0.203638, Accuracy: 7/8 (87.500%)\n",
      "TRAIN: LOSS-->0.2022 (0.4037)\tACC-->87.500% (86.132%)\n",
      "TRAIN: 75 [1600/4038 (40%)]\tLoss: 0.202188, Accuracy: 7/8 (87.500%)\n",
      "TRAIN: LOSS-->0.3103 (0.3909)\tACC-->87.500% (86.783%)\n",
      "TRAIN: 75 [3200/4038 (79%)]\tLoss: 0.310321, Accuracy: 7/8 (87.500%)\n",
      "VAL:   LOSS--> 0.2682 (0.2682)\tACC-->87.500 (87.500)\n",
      " * Accuracy 92.5562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 35%|████████████████████████████████████████████████▋                                                                                            | 76/220 [3:20:54<6:20:39, 158.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.0094 (0.0094)\tACC-->100.000% (100.000%)\n",
      "TRAIN: 76 [0/4038 (0%)]\tLoss: 0.009423, Accuracy: 8/8 (100.000%)\n",
      "TRAIN: LOSS-->0.9169 (0.3430)\tACC-->62.500% (88.246%)\n",
      "TRAIN: 76 [1600/4038 (40%)]\tLoss: 0.916905, Accuracy: 5/8 (62.500%)\n",
      "TRAIN: LOSS-->0.2487 (0.3574)\tACC-->87.500% (87.251%)\n",
      "TRAIN: 76 [3200/4038 (79%)]\tLoss: 0.248664, Accuracy: 7/8 (87.500%)\n",
      "VAL:   LOSS--> 0.0768 (0.0768)\tACC-->100.000 (100.000)\n",
      " * Accuracy 92.8371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 35%|█████████████████████████████████████████████████▎                                                                                           | 77/220 [3:23:33<6:18:02, 158.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.1904 (0.1904)\tACC-->100.000% (100.000%)\n",
      "TRAIN: 77 [0/4038 (0%)]\tLoss: 0.190374, Accuracy: 8/8 (100.000%)\n",
      "TRAIN: LOSS-->1.3689 (0.3430)\tACC-->75.000% (88.246%)\n",
      "TRAIN: 77 [1600/4038 (40%)]\tLoss: 1.368945, Accuracy: 6/8 (75.000%)\n",
      "TRAIN: LOSS-->0.1829 (0.3466)\tACC-->100.000% (88.310%)\n",
      "TRAIN: 77 [3200/4038 (79%)]\tLoss: 0.182867, Accuracy: 8/8 (100.000%)\n",
      "VAL:   LOSS--> 0.0001 (0.0001)\tACC-->100.000 (100.000)\n",
      " * Accuracy 91.8539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 35%|█████████████████████████████████████████████████▉                                                                                           | 78/220 [3:26:11<6:15:23, 158.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.1887 (0.1887)\tACC-->100.000% (100.000%)\n",
      "TRAIN: 78 [0/4038 (0%)]\tLoss: 0.188679, Accuracy: 8/8 (100.000%)\n",
      "TRAIN: LOSS-->0.2923 (0.3801)\tACC-->75.000% (87.189%)\n",
      "TRAIN: 78 [1600/4038 (40%)]\tLoss: 0.292255, Accuracy: 6/8 (75.000%)\n",
      "TRAIN: LOSS-->0.0997 (0.3593)\tACC-->100.000% (87.781%)\n",
      "TRAIN: 78 [3200/4038 (79%)]\tLoss: 0.099695, Accuracy: 8/8 (100.000%)\n",
      "VAL:   LOSS--> 0.0037 (0.0037)\tACC-->100.000 (100.000)\n",
      " * Accuracy 94.6629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|██████████████████████████████████████████████████▋                                                                                          | 79/220 [3:28:53<6:12:50, 158.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.5778 (0.5778)\tACC-->87.500% (87.500%)\n",
      "TRAIN: 79 [0/4038 (0%)]\tLoss: 0.577847, Accuracy: 7/8 (87.500%)\n",
      "TRAIN: LOSS-->0.0358 (0.3342)\tACC-->100.000% (88.495%)\n",
      "TRAIN: 79 [1600/4038 (40%)]\tLoss: 0.035783, Accuracy: 8/8 (100.000%)\n",
      "TRAIN: LOSS-->0.2817 (0.3271)\tACC-->87.500% (88.435%)\n",
      "TRAIN: 79 [3200/4038 (79%)]\tLoss: 0.281719, Accuracy: 7/8 (87.500%)\n",
      "VAL:   LOSS--> 0.0280 (0.0280)\tACC-->100.000 (100.000)\n",
      " * Accuracy 92.8371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|███████████████████████████████████████████████████▎                                                                                         | 80/220 [3:31:38<6:10:21, 158.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.6180 (0.6180)\tACC-->62.500% (62.500%)\n",
      "TRAIN: 80 [0/4038 (0%)]\tLoss: 0.618041, Accuracy: 5/8 (62.500%)\n",
      "TRAIN: LOSS-->0.1095 (0.3307)\tACC-->100.000% (88.371%)\n",
      "TRAIN: 80 [1600/4038 (40%)]\tLoss: 0.109455, Accuracy: 8/8 (100.000%)\n",
      "TRAIN: LOSS-->0.0762 (0.3228)\tACC-->100.000% (88.279%)\n",
      "TRAIN: 80 [3200/4038 (79%)]\tLoss: 0.076233, Accuracy: 8/8 (100.000%)\n",
      "VAL:   LOSS--> 0.0671 (0.0671)\tACC-->100.000 (100.000)\n",
      " * Accuracy 95.0843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 37%|███████████████████████████████████████████████████▉                                                                                         | 81/220 [3:34:22<6:07:52, 158.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.4493 (0.4493)\tACC-->75.000% (75.000%)\n",
      "TRAIN: 81 [0/4038 (0%)]\tLoss: 0.449349, Accuracy: 6/8 (75.000%)\n",
      "TRAIN: LOSS-->1.0442 (0.3506)\tACC-->62.500% (88.122%)\n",
      "TRAIN: 81 [1600/4038 (40%)]\tLoss: 1.044241, Accuracy: 5/8 (62.500%)\n",
      "TRAIN: LOSS-->0.3698 (0.3318)\tACC-->87.500% (88.030%)\n",
      "TRAIN: 81 [3200/4038 (79%)]\tLoss: 0.369825, Accuracy: 7/8 (87.500%)\n",
      "VAL:   LOSS--> 0.0004 (0.0004)\tACC-->100.000 (100.000)\n",
      " * Accuracy 95.5056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 37%|████████████████████████████████████████████████████▌                                                                                        | 82/220 [3:37:06<6:05:21, 158.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.5016 (0.5016)\tACC-->87.500% (87.500%)\n",
      "TRAIN: 82 [0/4038 (0%)]\tLoss: 0.501602, Accuracy: 7/8 (87.500%)\n",
      "TRAIN: LOSS-->0.0870 (0.3458)\tACC-->100.000% (88.246%)\n",
      "TRAIN: 82 [1600/4038 (40%)]\tLoss: 0.087014, Accuracy: 8/8 (100.000%)\n",
      "TRAIN: LOSS-->0.3586 (0.3462)\tACC-->75.000% (88.279%)\n",
      "TRAIN: 82 [3200/4038 (79%)]\tLoss: 0.358561, Accuracy: 6/8 (75.000%)\n",
      "VAL:   LOSS--> 0.0650 (0.0650)\tACC-->100.000 (100.000)\n",
      " * Accuracy 93.2584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|█████████████████████████████████████████████████████▏                                                                                       | 83/220 [3:39:49<6:02:51, 158.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.0367 (0.0367)\tACC-->100.000% (100.000%)\n",
      "TRAIN: 83 [0/4038 (0%)]\tLoss: 0.036739, Accuracy: 8/8 (100.000%)\n",
      "TRAIN: LOSS-->0.0837 (0.3046)\tACC-->100.000% (89.366%)\n",
      "TRAIN: 83 [1600/4038 (40%)]\tLoss: 0.083673, Accuracy: 8/8 (100.000%)\n",
      "TRAIN: LOSS-->0.0895 (0.3158)\tACC-->100.000% (88.747%)\n",
      "TRAIN: 83 [3200/4038 (79%)]\tLoss: 0.089515, Accuracy: 8/8 (100.000%)\n",
      "VAL:   LOSS--> 1.4645 (1.4645)\tACC-->75.000 (75.000)\n",
      " * Accuracy 92.5562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|█████████████████████████████████████████████████████▊                                                                                       | 84/220 [3:42:33<6:00:20, 158.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.4125 (0.4125)\tACC-->75.000% (75.000%)\n",
      "TRAIN: 84 [0/4038 (0%)]\tLoss: 0.412473, Accuracy: 6/8 (75.000%)\n",
      "TRAIN: LOSS-->0.2989 (0.3279)\tACC-->87.500% (89.055%)\n",
      "TRAIN: 84 [1600/4038 (40%)]\tLoss: 0.298866, Accuracy: 7/8 (87.500%)\n",
      "TRAIN: LOSS-->0.4830 (0.3488)\tACC-->87.500% (88.061%)\n",
      "TRAIN: 84 [3200/4038 (79%)]\tLoss: 0.482967, Accuracy: 7/8 (87.500%)\n",
      "VAL:   LOSS--> 0.0510 (0.0510)\tACC-->100.000 (100.000)\n",
      " * Accuracy 94.8034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 39%|██████████████████████████████████████████████████████▍                                                                                      | 85/220 [3:45:17<5:57:48, 159.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.5112 (0.5112)\tACC-->87.500% (87.500%)\n",
      "TRAIN: 85 [0/4038 (0%)]\tLoss: 0.511182, Accuracy: 7/8 (87.500%)\n",
      "TRAIN: LOSS-->0.0395 (0.3155)\tACC-->100.000% (88.557%)\n",
      "TRAIN: 85 [1600/4038 (40%)]\tLoss: 0.039453, Accuracy: 8/8 (100.000%)\n",
      "TRAIN: LOSS-->0.0463 (0.3227)\tACC-->100.000% (88.591%)\n",
      "TRAIN: 85 [3200/4038 (79%)]\tLoss: 0.046295, Accuracy: 8/8 (100.000%)\n",
      "VAL:   LOSS--> 0.0297 (0.0297)\tACC-->100.000 (100.000)\n",
      " * Accuracy 96.7697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 39%|███████████████████████████████████████████████████████                                                                                      | 86/220 [3:47:56<5:55:10, 159.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.6878 (0.6878)\tACC-->62.500% (62.500%)\n",
      "TRAIN: 86 [0/4038 (0%)]\tLoss: 0.687775, Accuracy: 5/8 (62.500%)\n",
      "TRAIN: LOSS-->0.0350 (0.3753)\tACC-->100.000% (87.127%)\n",
      "TRAIN: 86 [1600/4038 (40%)]\tLoss: 0.034985, Accuracy: 8/8 (100.000%)\n",
      "TRAIN: LOSS-->1.4054 (0.3534)\tACC-->62.500% (88.030%)\n",
      "TRAIN: 86 [3200/4038 (79%)]\tLoss: 1.405399, Accuracy: 5/8 (62.500%)\n",
      "VAL:   LOSS--> 0.0293 (0.0293)\tACC-->100.000 (100.000)\n",
      " * Accuracy 93.8202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|███████████████████████████████████████████████████████▊                                                                                     | 87/220 [3:50:35<5:52:30, 159.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.5436 (0.5436)\tACC-->75.000% (75.000%)\n",
      "TRAIN: 87 [0/4038 (0%)]\tLoss: 0.543620, Accuracy: 6/8 (75.000%)\n",
      "TRAIN: LOSS-->0.1155 (0.2774)\tACC-->100.000% (89.241%)\n",
      "TRAIN: 87 [1600/4038 (40%)]\tLoss: 0.115517, Accuracy: 8/8 (100.000%)\n",
      "TRAIN: LOSS-->0.6885 (0.3078)\tACC-->75.000% (88.591%)\n",
      "TRAIN: 87 [3200/4038 (79%)]\tLoss: 0.688534, Accuracy: 6/8 (75.000%)\n",
      "VAL:   LOSS--> 0.0540 (0.0540)\tACC-->100.000 (100.000)\n",
      " * Accuracy 93.5393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████████████████████████████████████████████████████████▍                                                                                    | 88/220 [3:53:13<5:49:50, 159.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.8086 (0.8086)\tACC-->62.500% (62.500%)\n",
      "TRAIN: 88 [0/4038 (0%)]\tLoss: 0.808608, Accuracy: 5/8 (62.500%)\n",
      "TRAIN: LOSS-->0.4928 (0.3401)\tACC-->62.500% (88.246%)\n",
      "TRAIN: 88 [1600/4038 (40%)]\tLoss: 0.492753, Accuracy: 5/8 (62.500%)\n",
      "TRAIN: LOSS-->0.3888 (0.3454)\tACC-->87.500% (87.874%)\n",
      "TRAIN: 88 [3200/4038 (79%)]\tLoss: 0.388768, Accuracy: 7/8 (87.500%)\n",
      "VAL:   LOSS--> 0.0079 (0.0079)\tACC-->100.000 (100.000)\n",
      " * Accuracy 91.8539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|█████████████████████████████████████████████████████████                                                                                    | 89/220 [3:55:52<5:47:11, 159.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.4851 (0.4851)\tACC-->87.500% (87.500%)\n",
      "TRAIN: 89 [0/4038 (0%)]\tLoss: 0.485142, Accuracy: 7/8 (87.500%)\n",
      "TRAIN: LOSS-->0.0210 (0.3523)\tACC-->100.000% (87.002%)\n",
      "TRAIN: 89 [1600/4038 (40%)]\tLoss: 0.021044, Accuracy: 8/8 (100.000%)\n",
      "TRAIN: LOSS-->0.4103 (0.3296)\tACC-->87.500% (87.999%)\n",
      "TRAIN: 89 [3200/4038 (79%)]\tLoss: 0.410317, Accuracy: 7/8 (87.500%)\n",
      "VAL:   LOSS--> 0.1185 (0.1185)\tACC-->100.000 (100.000)\n",
      " * Accuracy 94.9438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 41%|█████████████████████████████████████████████████████████▋                                                                                   | 90/220 [3:58:31<5:44:32, 159.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.0372 (0.0372)\tACC-->100.000% (100.000%)\n",
      "TRAIN: 90 [0/4038 (0%)]\tLoss: 0.037218, Accuracy: 8/8 (100.000%)\n",
      "TRAIN: LOSS-->0.1754 (0.3292)\tACC-->100.000% (89.179%)\n",
      "TRAIN: 90 [1600/4038 (40%)]\tLoss: 0.175427, Accuracy: 8/8 (100.000%)\n",
      "TRAIN: LOSS-->0.3716 (0.3269)\tACC-->87.500% (89.246%)\n",
      "TRAIN: 90 [3200/4038 (79%)]\tLoss: 0.371604, Accuracy: 7/8 (87.500%)\n",
      "VAL:   LOSS--> 0.0230 (0.0230)\tACC-->100.000 (100.000)\n",
      " * Accuracy 94.3820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 41%|██████████████████████████████████████████████████████████▎                                                                                  | 91/220 [4:01:09<5:41:52, 159.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.2511 (0.2511)\tACC-->87.500% (87.500%)\n",
      "TRAIN: 91 [0/4038 (0%)]\tLoss: 0.251115, Accuracy: 7/8 (87.500%)\n",
      "TRAIN: LOSS-->0.1381 (0.3348)\tACC-->87.500% (87.251%)\n",
      "TRAIN: 91 [1600/4038 (40%)]\tLoss: 0.138050, Accuracy: 7/8 (87.500%)\n",
      "TRAIN: LOSS-->0.4661 (0.3247)\tACC-->75.000% (88.310%)\n",
      "TRAIN: 91 [3200/4038 (79%)]\tLoss: 0.466081, Accuracy: 6/8 (75.000%)\n",
      "VAL:   LOSS--> 0.7905 (0.7905)\tACC-->75.000 (75.000)\n",
      " * Accuracy 91.1517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|██████████████████████████████████████████████████████████▉                                                                                  | 92/220 [4:03:48<5:39:13, 159.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.2274 (0.2274)\tACC-->100.000% (100.000%)\n",
      "TRAIN: 92 [0/4038 (0%)]\tLoss: 0.227362, Accuracy: 8/8 (100.000%)\n",
      "TRAIN: LOSS-->0.1936 (0.3363)\tACC-->87.500% (87.998%)\n",
      "TRAIN: 92 [1600/4038 (40%)]\tLoss: 0.193635, Accuracy: 7/8 (87.500%)\n",
      "TRAIN: LOSS-->0.3903 (0.3405)\tACC-->87.500% (87.812%)\n",
      "TRAIN: 92 [3200/4038 (79%)]\tLoss: 0.390305, Accuracy: 7/8 (87.500%)\n",
      "VAL:   LOSS--> 0.0384 (0.0384)\tACC-->100.000 (100.000)\n",
      " * Accuracy 94.5225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|███████████████████████████████████████████████████████████▌                                                                                 | 93/220 [4:06:27<5:36:33, 159.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.0475 (0.0475)\tACC-->100.000% (100.000%)\n",
      "TRAIN: 93 [0/4038 (0%)]\tLoss: 0.047530, Accuracy: 8/8 (100.000%)\n",
      "TRAIN: LOSS-->0.2215 (0.2665)\tACC-->87.500% (90.672%)\n",
      "TRAIN: 93 [1600/4038 (40%)]\tLoss: 0.221520, Accuracy: 7/8 (87.500%)\n",
      "TRAIN: LOSS-->0.1437 (0.2783)\tACC-->100.000% (90.056%)\n",
      "TRAIN: 93 [3200/4038 (79%)]\tLoss: 0.143656, Accuracy: 8/8 (100.000%)\n",
      "VAL:   LOSS--> 0.3457 (0.3457)\tACC-->87.500 (87.500)\n",
      " * Accuracy 93.3989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 43%|████████████████████████████████████████████████████████████▏                                                                                | 94/220 [4:09:05<5:33:53, 159.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.3700 (0.3700)\tACC-->87.500% (87.500%)\n",
      "TRAIN: 94 [0/4038 (0%)]\tLoss: 0.370012, Accuracy: 7/8 (87.500%)\n",
      "TRAIN: LOSS-->0.1377 (0.3085)\tACC-->100.000% (89.303%)\n",
      "TRAIN: 94 [1600/4038 (40%)]\tLoss: 0.137750, Accuracy: 8/8 (100.000%)\n",
      "TRAIN: LOSS-->0.3500 (0.3052)\tACC-->87.500% (89.464%)\n",
      "TRAIN: 94 [3200/4038 (79%)]\tLoss: 0.349985, Accuracy: 7/8 (87.500%)\n",
      "VAL:   LOSS--> 0.0189 (0.0189)\tACC-->100.000 (100.000)\n",
      " * Accuracy 95.7865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 43%|████████████████████████████████████████████████████████████▉                                                                                | 95/220 [4:11:44<5:31:14, 158.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.1707 (0.1707)\tACC-->100.000% (100.000%)\n",
      "TRAIN: 95 [0/4038 (0%)]\tLoss: 0.170705, Accuracy: 8/8 (100.000%)\n",
      "TRAIN: LOSS-->0.0282 (0.3081)\tACC-->100.000% (89.490%)\n",
      "TRAIN: 95 [1600/4038 (40%)]\tLoss: 0.028199, Accuracy: 8/8 (100.000%)\n",
      "TRAIN: LOSS-->0.2638 (0.3036)\tACC-->87.500% (89.495%)\n",
      "TRAIN: 95 [3200/4038 (79%)]\tLoss: 0.263792, Accuracy: 7/8 (87.500%)\n",
      "VAL:   LOSS--> 0.1471 (0.1471)\tACC-->87.500 (87.500)\n",
      " * Accuracy 93.3989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|█████████████████████████████████████████████████████████████▌                                                                               | 96/220 [4:14:22<5:28:34, 158.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.1970 (0.1970)\tACC-->87.500% (87.500%)\n",
      "TRAIN: 96 [0/4038 (0%)]\tLoss: 0.196962, Accuracy: 7/8 (87.500%)\n",
      "TRAIN: LOSS-->0.2762 (0.2966)\tACC-->87.500% (89.925%)\n",
      "TRAIN: 96 [1600/4038 (40%)]\tLoss: 0.276190, Accuracy: 7/8 (87.500%)\n",
      "TRAIN: LOSS-->0.3942 (0.3099)\tACC-->87.500% (89.557%)\n",
      "TRAIN: 96 [3200/4038 (79%)]\tLoss: 0.394164, Accuracy: 7/8 (87.500%)\n",
      "VAL:   LOSS--> 0.0028 (0.0028)\tACC-->100.000 (100.000)\n",
      " * Accuracy 94.9438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|██████████████████████████████████████████████████████████████▏                                                                              | 97/220 [4:17:01<5:25:55, 158.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.2202 (0.2202)\tACC-->87.500% (87.500%)\n",
      "TRAIN: 97 [0/4038 (0%)]\tLoss: 0.220250, Accuracy: 7/8 (87.500%)\n",
      "TRAIN: LOSS-->0.5969 (0.3151)\tACC-->75.000% (89.552%)\n",
      "TRAIN: 97 [1600/4038 (40%)]\tLoss: 0.596853, Accuracy: 6/8 (75.000%)\n",
      "TRAIN: LOSS-->0.3725 (0.3139)\tACC-->87.500% (89.308%)\n",
      "TRAIN: 97 [3200/4038 (79%)]\tLoss: 0.372501, Accuracy: 7/8 (87.500%)\n",
      "VAL:   LOSS--> 0.0040 (0.0040)\tACC-->100.000 (100.000)\n",
      " * Accuracy 94.6629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 45%|██████████████████████████████████████████████████████████████▊                                                                              | 98/220 [4:19:40<5:23:15, 158.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.2413 (0.2413)\tACC-->87.500% (87.500%)\n",
      "TRAIN: 98 [0/4038 (0%)]\tLoss: 0.241335, Accuracy: 7/8 (87.500%)\n",
      "TRAIN: LOSS-->0.0903 (0.2929)\tACC-->100.000% (89.925%)\n",
      "TRAIN: 98 [1600/4038 (40%)]\tLoss: 0.090348, Accuracy: 8/8 (100.000%)\n",
      "TRAIN: LOSS-->0.0165 (0.3016)\tACC-->100.000% (89.557%)\n",
      "TRAIN: 98 [3200/4038 (79%)]\tLoss: 0.016509, Accuracy: 8/8 (100.000%)\n",
      "VAL:   LOSS--> 0.0010 (0.0010)\tACC-->100.000 (100.000)\n",
      " * Accuracy 95.7865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 45%|███████████████████████████████████████████████████████████████▍                                                                             | 99/220 [4:22:19<5:20:36, 158.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.3130 (0.3130)\tACC-->87.500% (87.500%)\n",
      "TRAIN: 99 [0/4038 (0%)]\tLoss: 0.312955, Accuracy: 7/8 (87.500%)\n",
      "TRAIN: LOSS-->0.0778 (0.2925)\tACC-->100.000% (89.055%)\n",
      "TRAIN: 99 [1600/4038 (40%)]\tLoss: 0.077810, Accuracy: 8/8 (100.000%)\n",
      "TRAIN: LOSS-->0.2008 (0.2935)\tACC-->87.500% (89.682%)\n",
      "TRAIN: 99 [3200/4038 (79%)]\tLoss: 0.200785, Accuracy: 7/8 (87.500%)\n",
      "VAL:   LOSS--> 0.0049 (0.0049)\tACC-->100.000 (100.000)\n",
      " * Accuracy 95.9270\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 45%|███████████████████████████████████████████████████████████████▋                                                                            | 100/220 [4:24:57<5:17:57, 158.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.0578 (0.0578)\tACC-->100.000% (100.000%)\n",
      "TRAIN: 100 [0/4038 (0%)]\tLoss: 0.057815, Accuracy: 8/8 (100.000%)\n",
      "TRAIN: LOSS-->0.7122 (0.3324)\tACC-->62.500% (88.184%)\n",
      "TRAIN: 100 [1600/4038 (40%)]\tLoss: 0.712166, Accuracy: 5/8 (62.500%)\n",
      "TRAIN: LOSS-->0.4251 (0.3129)\tACC-->75.000% (88.560%)\n",
      "TRAIN: 100 [3200/4038 (79%)]\tLoss: 0.425108, Accuracy: 6/8 (75.000%)\n",
      "VAL:   LOSS--> 0.0064 (0.0064)\tACC-->100.000 (100.000)\n",
      " * Accuracy 94.1011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|████████████████████████████████████████████████████████████████▎                                                                           | 101/220 [4:27:36<5:15:18, 158.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.1688 (0.1688)\tACC-->100.000% (100.000%)\n",
      "TRAIN: 101 [0/4038 (0%)]\tLoss: 0.168833, Accuracy: 8/8 (100.000%)\n",
      "TRAIN: LOSS-->0.3548 (0.2845)\tACC-->87.500% (89.988%)\n",
      "TRAIN: 101 [1600/4038 (40%)]\tLoss: 0.354799, Accuracy: 7/8 (87.500%)\n",
      "TRAIN: LOSS-->0.2971 (0.2949)\tACC-->87.500% (89.807%)\n",
      "TRAIN: 101 [3200/4038 (79%)]\tLoss: 0.297111, Accuracy: 7/8 (87.500%)\n",
      "VAL:   LOSS--> 0.0115 (0.0115)\tACC-->100.000 (100.000)\n",
      " * Accuracy 94.6629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|████████████████████████████████████████████████████████████████▉                                                                           | 102/220 [4:30:15<5:12:38, 158.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.0270 (0.0270)\tACC-->100.000% (100.000%)\n",
      "TRAIN: 102 [0/4038 (0%)]\tLoss: 0.027002, Accuracy: 8/8 (100.000%)\n",
      "TRAIN: LOSS-->0.0483 (0.2789)\tACC-->100.000% (89.801%)\n",
      "TRAIN: 102 [1600/4038 (40%)]\tLoss: 0.048284, Accuracy: 8/8 (100.000%)\n",
      "TRAIN: LOSS-->0.0569 (0.2883)\tACC-->100.000% (89.682%)\n",
      "TRAIN: 102 [3200/4038 (79%)]\tLoss: 0.056859, Accuracy: 8/8 (100.000%)\n",
      "VAL:   LOSS--> 0.0656 (0.0656)\tACC-->100.000 (100.000)\n",
      " * Accuracy 96.4888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 47%|█████████████████████████████████████████████████████████████████▌                                                                          | 103/220 [4:32:54<5:09:59, 158.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.1817 (0.1817)\tACC-->87.500% (87.500%)\n",
      "TRAIN: 103 [0/4038 (0%)]\tLoss: 0.181666, Accuracy: 7/8 (87.500%)\n",
      "TRAIN: LOSS-->0.0480 (0.3190)\tACC-->100.000% (88.682%)\n",
      "TRAIN: 103 [1600/4038 (40%)]\tLoss: 0.048016, Accuracy: 8/8 (100.000%)\n",
      "TRAIN: LOSS-->0.2152 (0.3214)\tACC-->87.500% (88.435%)\n",
      "TRAIN: 103 [3200/4038 (79%)]\tLoss: 0.215163, Accuracy: 7/8 (87.500%)\n",
      "VAL:   LOSS--> 0.0278 (0.0278)\tACC-->100.000 (100.000)\n",
      " * Accuracy 95.7865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 47%|██████████████████████████████████████████████████████████████████▏                                                                         | 104/220 [4:35:33<5:07:20, 158.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.0879 (0.0879)\tACC-->100.000% (100.000%)\n",
      "TRAIN: 104 [0/4038 (0%)]\tLoss: 0.087910, Accuracy: 8/8 (100.000%)\n",
      "TRAIN: LOSS-->0.1095 (0.2931)\tACC-->100.000% (89.925%)\n",
      "TRAIN: 104 [1600/4038 (40%)]\tLoss: 0.109488, Accuracy: 8/8 (100.000%)\n",
      "TRAIN: LOSS-->0.0917 (0.2899)\tACC-->100.000% (90.087%)\n",
      "TRAIN: 104 [3200/4038 (79%)]\tLoss: 0.091674, Accuracy: 8/8 (100.000%)\n",
      "VAL:   LOSS--> 0.0036 (0.0036)\tACC-->100.000 (100.000)\n",
      " * Accuracy 95.5056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|██████████████████████████████████████████████████████████████████▊                                                                         | 105/220 [4:38:11<5:04:41, 158.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.2971 (0.2971)\tACC-->87.500% (87.500%)\n",
      "TRAIN: 105 [0/4038 (0%)]\tLoss: 0.297053, Accuracy: 7/8 (87.500%)\n",
      "TRAIN: LOSS-->0.2483 (0.2652)\tACC-->100.000% (90.796%)\n",
      "TRAIN: 105 [1600/4038 (40%)]\tLoss: 0.248267, Accuracy: 8/8 (100.000%)\n",
      "TRAIN: LOSS-->0.3751 (0.2707)\tACC-->75.000% (90.524%)\n",
      "TRAIN: 105 [3200/4038 (79%)]\tLoss: 0.375132, Accuracy: 6/8 (75.000%)\n",
      "VAL:   LOSS--> 0.5229 (0.5229)\tACC-->75.000 (75.000)\n",
      " * Accuracy 92.4157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|███████████████████████████████████████████████████████████████████▍                                                                        | 106/220 [4:40:50<5:02:02, 158.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.0902 (0.0902)\tACC-->100.000% (100.000%)\n",
      "TRAIN: 106 [0/4038 (0%)]\tLoss: 0.090237, Accuracy: 8/8 (100.000%)\n",
      "TRAIN: LOSS-->0.1722 (0.3116)\tACC-->87.500% (89.179%)\n",
      "TRAIN: 106 [1600/4038 (40%)]\tLoss: 0.172168, Accuracy: 7/8 (87.500%)\n",
      "TRAIN: LOSS-->0.2288 (0.3091)\tACC-->87.500% (89.464%)\n",
      "TRAIN: 106 [3200/4038 (79%)]\tLoss: 0.228772, Accuracy: 7/8 (87.500%)\n",
      "VAL:   LOSS--> 0.0056 (0.0056)\tACC-->100.000 (100.000)\n",
      " * Accuracy 95.2247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 49%|████████████████████████████████████████████████████████████████████                                                                        | 107/220 [4:43:29<4:59:23, 158.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.7398 (0.7398)\tACC-->87.500% (87.500%)\n",
      "TRAIN: 107 [0/4038 (0%)]\tLoss: 0.739791, Accuracy: 7/8 (87.500%)\n",
      "TRAIN: LOSS-->0.1578 (0.3270)\tACC-->100.000% (88.308%)\n",
      "TRAIN: 107 [1600/4038 (40%)]\tLoss: 0.157818, Accuracy: 8/8 (100.000%)\n",
      "TRAIN: LOSS-->0.7677 (0.3066)\tACC-->75.000% (89.495%)\n",
      "TRAIN: 107 [3200/4038 (79%)]\tLoss: 0.767687, Accuracy: 6/8 (75.000%)\n",
      "VAL:   LOSS--> 0.4479 (0.4479)\tACC-->75.000 (75.000)\n",
      " * Accuracy 95.2247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 49%|████████████████████████████████████████████████████████████████████▋                                                                       | 108/220 [4:46:08<4:56:43, 158.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.0811 (0.0811)\tACC-->100.000% (100.000%)\n",
      "TRAIN: 108 [0/4038 (0%)]\tLoss: 0.081067, Accuracy: 8/8 (100.000%)\n",
      "TRAIN: LOSS-->0.1968 (0.2958)\tACC-->87.500% (89.614%)\n",
      "TRAIN: 108 [1600/4038 (40%)]\tLoss: 0.196812, Accuracy: 7/8 (87.500%)\n",
      "TRAIN: LOSS-->0.2200 (0.2955)\tACC-->100.000% (89.433%)\n",
      "TRAIN: 108 [3200/4038 (79%)]\tLoss: 0.219996, Accuracy: 8/8 (100.000%)\n",
      "VAL:   LOSS--> 0.0006 (0.0006)\tACC-->100.000 (100.000)\n",
      " * Accuracy 96.4888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████████████████████████████████████████████████████████████████████▎                                                                      | 109/220 [4:48:45<4:54:03, 158.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.1142 (0.1142)\tACC-->100.000% (100.000%)\n",
      "TRAIN: 109 [0/4038 (0%)]\tLoss: 0.114215, Accuracy: 8/8 (100.000%)\n",
      "TRAIN: LOSS-->0.0180 (0.3012)\tACC-->100.000% (90.174%)\n",
      "TRAIN: 109 [1600/4038 (40%)]\tLoss: 0.017961, Accuracy: 8/8 (100.000%)\n",
      "TRAIN: LOSS-->1.0670 (0.3042)\tACC-->62.500% (89.589%)\n",
      "TRAIN: 109 [3200/4038 (79%)]\tLoss: 1.066996, Accuracy: 5/8 (62.500%)\n",
      "VAL:   LOSS--> 0.0347 (0.0347)\tACC-->100.000 (100.000)\n",
      " * Accuracy 94.3820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|██████████████████████████████████████████████████████████████████████                                                                      | 110/220 [4:51:22<4:51:22, 158.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.0783 (0.0783)\tACC-->100.000% (100.000%)\n",
      "TRAIN: 110 [0/4038 (0%)]\tLoss: 0.078268, Accuracy: 8/8 (100.000%)\n",
      "TRAIN: LOSS-->0.0822 (0.2620)\tACC-->100.000% (91.418%)\n",
      "TRAIN: 110 [1600/4038 (40%)]\tLoss: 0.082244, Accuracy: 8/8 (100.000%)\n",
      "TRAIN: LOSS-->0.5081 (0.2800)\tACC-->75.000% (90.337%)\n",
      "TRAIN: 110 [3200/4038 (79%)]\tLoss: 0.508119, Accuracy: 6/8 (75.000%)\n",
      "VAL:   LOSS--> 0.0063 (0.0063)\tACC-->100.000 (100.000)\n",
      " * Accuracy 96.3483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|██████████████████████████████████████████████████████████████████████▋                                                                     | 111/220 [4:53:59<4:48:41, 158.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.8480 (0.8480)\tACC-->75.000% (75.000%)\n",
      "TRAIN: 111 [0/4038 (0%)]\tLoss: 0.847958, Accuracy: 6/8 (75.000%)\n",
      "TRAIN: LOSS-->0.0673 (0.3095)\tACC-->100.000% (89.055%)\n",
      "TRAIN: 111 [1600/4038 (40%)]\tLoss: 0.067294, Accuracy: 8/8 (100.000%)\n",
      "TRAIN: LOSS-->0.0227 (0.2870)\tACC-->100.000% (89.464%)\n",
      "TRAIN: 111 [3200/4038 (79%)]\tLoss: 0.022664, Accuracy: 8/8 (100.000%)\n",
      "VAL:   LOSS--> 0.0334 (0.0334)\tACC-->100.000 (100.000)\n",
      " * Accuracy 93.6798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 51%|███████████████████████████████████████████████████████████████████████▎                                                                    | 112/220 [4:56:36<4:46:01, 158.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.2266 (0.2266)\tACC-->87.500% (87.500%)\n",
      "TRAIN: 112 [0/4038 (0%)]\tLoss: 0.226592, Accuracy: 7/8 (87.500%)\n",
      "TRAIN: LOSS-->0.9943 (0.2567)\tACC-->62.500% (90.299%)\n",
      "TRAIN: 112 [1600/4038 (40%)]\tLoss: 0.994317, Accuracy: 5/8 (62.500%)\n",
      "TRAIN: LOSS-->0.4859 (0.2838)\tACC-->87.500% (89.744%)\n",
      "TRAIN: 112 [3200/4038 (79%)]\tLoss: 0.485862, Accuracy: 7/8 (87.500%)\n",
      "VAL:   LOSS--> 0.0079 (0.0079)\tACC-->100.000 (100.000)\n",
      " * Accuracy 96.3483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 51%|███████████████████████████████████████████████████████████████████████▉                                                                    | 113/220 [4:59:14<4:43:20, 158.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.2029 (0.2029)\tACC-->100.000% (100.000%)\n",
      "TRAIN: 113 [0/4038 (0%)]\tLoss: 0.202869, Accuracy: 8/8 (100.000%)\n",
      "TRAIN: LOSS-->0.1764 (0.2949)\tACC-->100.000% (90.236%)\n",
      "TRAIN: 113 [1600/4038 (40%)]\tLoss: 0.176350, Accuracy: 8/8 (100.000%)\n",
      "TRAIN: LOSS-->0.0119 (0.2748)\tACC-->100.000% (90.617%)\n",
      "TRAIN: 113 [3200/4038 (79%)]\tLoss: 0.011862, Accuracy: 8/8 (100.000%)\n",
      "VAL:   LOSS--> 0.7865 (0.7865)\tACC-->75.000 (75.000)\n",
      " * Accuracy 94.3820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|████████████████████████████████████████████████████████████████████████▌                                                                   | 114/220 [5:01:51<4:40:40, 158.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.0116 (0.0116)\tACC-->100.000% (100.000%)\n",
      "TRAIN: 114 [0/4038 (0%)]\tLoss: 0.011647, Accuracy: 8/8 (100.000%)\n",
      "TRAIN: LOSS-->1.1307 (0.2961)\tACC-->75.000% (90.236%)\n",
      "TRAIN: 114 [1600/4038 (40%)]\tLoss: 1.130731, Accuracy: 6/8 (75.000%)\n",
      "TRAIN: LOSS-->0.2326 (0.2889)\tACC-->87.500% (89.744%)\n",
      "TRAIN: 114 [3200/4038 (79%)]\tLoss: 0.232593, Accuracy: 7/8 (87.500%)\n",
      "VAL:   LOSS--> 0.1605 (0.1605)\tACC-->87.500 (87.500)\n",
      " * Accuracy 95.3652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|█████████████████████████████████████████████████████████████████████████▏                                                                  | 115/220 [5:04:28<4:38:00, 158.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.1637 (0.1637)\tACC-->87.500% (87.500%)\n",
      "TRAIN: 115 [0/4038 (0%)]\tLoss: 0.163728, Accuracy: 7/8 (87.500%)\n",
      "TRAIN: LOSS-->0.4327 (0.2863)\tACC-->87.500% (90.112%)\n",
      "TRAIN: 115 [1600/4038 (40%)]\tLoss: 0.432721, Accuracy: 7/8 (87.500%)\n",
      "TRAIN: LOSS-->0.3240 (0.2962)\tACC-->87.500% (89.620%)\n",
      "TRAIN: 115 [3200/4038 (79%)]\tLoss: 0.324014, Accuracy: 7/8 (87.500%)\n",
      "VAL:   LOSS--> 0.2068 (0.2068)\tACC-->87.500 (87.500)\n",
      " * Accuracy 95.7865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 53%|█████████████████████████████████████████████████████████████████████████▊                                                                  | 116/220 [5:07:05<4:35:19, 158.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.0453 (0.0453)\tACC-->100.000% (100.000%)\n",
      "TRAIN: 116 [0/4038 (0%)]\tLoss: 0.045262, Accuracy: 8/8 (100.000%)\n",
      "TRAIN: LOSS-->0.4775 (0.2870)\tACC-->75.000% (90.174%)\n",
      "TRAIN: 116 [1600/4038 (40%)]\tLoss: 0.477488, Accuracy: 6/8 (75.000%)\n",
      "TRAIN: LOSS-->0.2601 (0.2886)\tACC-->87.500% (90.056%)\n",
      "TRAIN: 116 [3200/4038 (79%)]\tLoss: 0.260090, Accuracy: 7/8 (87.500%)\n",
      "VAL:   LOSS--> 0.0038 (0.0038)\tACC-->100.000 (100.000)\n",
      " * Accuracy 95.7865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 53%|██████████████████████████████████████████████████████████████████████████▍                                                                 | 117/220 [5:09:41<4:32:38, 158.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.0381 (0.0381)\tACC-->100.000% (100.000%)\n",
      "TRAIN: 117 [0/4038 (0%)]\tLoss: 0.038146, Accuracy: 8/8 (100.000%)\n",
      "TRAIN: LOSS-->0.0869 (0.2788)\tACC-->100.000% (90.547%)\n",
      "TRAIN: 117 [1600/4038 (40%)]\tLoss: 0.086943, Accuracy: 8/8 (100.000%)\n",
      "TRAIN: LOSS-->0.0598 (0.2871)\tACC-->100.000% (90.337%)\n",
      "TRAIN: 117 [3200/4038 (79%)]\tLoss: 0.059802, Accuracy: 8/8 (100.000%)\n",
      "VAL:   LOSS--> 0.1175 (0.1175)\tACC-->87.500 (87.500)\n",
      " * Accuracy 95.9270\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 54%|███████████████████████████████████████████████████████████████████████████                                                                 | 118/220 [5:12:18<4:29:57, 158.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.3326 (0.3326)\tACC-->87.500% (87.500%)\n",
      "TRAIN: 118 [0/4038 (0%)]\tLoss: 0.332618, Accuracy: 7/8 (87.500%)\n",
      "TRAIN: LOSS-->0.0698 (0.3031)\tACC-->100.000% (89.117%)\n",
      "TRAIN: 118 [1600/4038 (40%)]\tLoss: 0.069791, Accuracy: 8/8 (100.000%)\n",
      "TRAIN: LOSS-->0.0718 (0.2959)\tACC-->100.000% (89.557%)\n",
      "TRAIN: 118 [3200/4038 (79%)]\tLoss: 0.071761, Accuracy: 8/8 (100.000%)\n",
      "VAL:   LOSS--> 3.0469 (3.0469)\tACC-->87.500 (87.500)\n",
      " * Accuracy 95.2247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 54%|███████████████████████████████████████████████████████████████████████████▋                                                                | 119/220 [5:14:56<4:27:17, 158.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.5980 (0.5980)\tACC-->87.500% (87.500%)\n",
      "TRAIN: 119 [0/4038 (0%)]\tLoss: 0.597976, Accuracy: 7/8 (87.500%)\n",
      "TRAIN: LOSS-->0.1545 (0.3098)\tACC-->100.000% (89.863%)\n",
      "TRAIN: 119 [1600/4038 (40%)]\tLoss: 0.154455, Accuracy: 8/8 (100.000%)\n",
      "TRAIN: LOSS-->0.1870 (0.2901)\tACC-->100.000% (89.994%)\n",
      "TRAIN: 119 [3200/4038 (79%)]\tLoss: 0.187030, Accuracy: 8/8 (100.000%)\n",
      "VAL:   LOSS--> 0.3252 (0.3252)\tACC-->75.000 (75.000)\n",
      " * Accuracy 94.9438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 55%|████████████████████████████████████████████████████████████████████████████▎                                                               | 120/220 [5:17:33<4:24:37, 158.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.4504 (0.4504)\tACC-->87.500% (87.500%)\n",
      "TRAIN: 120 [0/4038 (0%)]\tLoss: 0.450435, Accuracy: 7/8 (87.500%)\n",
      "TRAIN: LOSS-->0.3573 (0.2704)\tACC-->87.500% (90.423%)\n",
      "TRAIN: 120 [1600/4038 (40%)]\tLoss: 0.357263, Accuracy: 7/8 (87.500%)\n",
      "TRAIN: LOSS-->0.0484 (0.2766)\tACC-->100.000% (90.461%)\n",
      "TRAIN: 120 [3200/4038 (79%)]\tLoss: 0.048434, Accuracy: 8/8 (100.000%)\n",
      "VAL:   LOSS--> 0.0158 (0.0158)\tACC-->100.000 (100.000)\n",
      " * Accuracy 95.9270\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 55%|█████████████████████████████████████████████████████████████████████████████                                                               | 121/220 [5:20:10<4:21:57, 158.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.0340 (0.0340)\tACC-->100.000% (100.000%)\n",
      "TRAIN: 121 [0/4038 (0%)]\tLoss: 0.033960, Accuracy: 8/8 (100.000%)\n",
      "TRAIN: LOSS-->0.5390 (0.2548)\tACC-->75.000% (90.858%)\n",
      "TRAIN: 121 [1600/4038 (40%)]\tLoss: 0.538951, Accuracy: 6/8 (75.000%)\n",
      "TRAIN: LOSS-->0.1663 (0.2825)\tACC-->100.000% (89.900%)\n",
      "TRAIN: 121 [3200/4038 (79%)]\tLoss: 0.166252, Accuracy: 8/8 (100.000%)\n",
      "VAL:   LOSS--> 0.0917 (0.0917)\tACC-->87.500 (87.500)\n",
      " * Accuracy 95.6461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 55%|█████████████████████████████████████████████████████████████████████████████▋                                                              | 122/220 [5:22:48<4:19:17, 158.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.0046 (0.0046)\tACC-->100.000% (100.000%)\n",
      "TRAIN: 122 [0/4038 (0%)]\tLoss: 0.004567, Accuracy: 8/8 (100.000%)\n",
      "TRAIN: LOSS-->0.1700 (0.2693)\tACC-->87.500% (89.801%)\n",
      "TRAIN: 122 [1600/4038 (40%)]\tLoss: 0.170024, Accuracy: 7/8 (87.500%)\n",
      "TRAIN: LOSS-->0.3148 (0.2661)\tACC-->87.500% (90.181%)\n",
      "TRAIN: 122 [3200/4038 (79%)]\tLoss: 0.314818, Accuracy: 7/8 (87.500%)\n",
      "VAL:   LOSS--> 1.9197 (1.9197)\tACC-->87.500 (87.500)\n",
      " * Accuracy 95.0843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|██████████████████████████████████████████████████████████████████████████████▎                                                             | 123/220 [5:25:25<4:16:37, 158.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.3215 (0.3215)\tACC-->87.500% (87.500%)\n",
      "TRAIN: 123 [0/4038 (0%)]\tLoss: 0.321518, Accuracy: 7/8 (87.500%)\n",
      "TRAIN: LOSS-->0.2787 (0.2708)\tACC-->87.500% (90.361%)\n",
      "TRAIN: 123 [1600/4038 (40%)]\tLoss: 0.278746, Accuracy: 7/8 (87.500%)\n",
      "TRAIN: LOSS-->0.0096 (0.2713)\tACC-->100.000% (90.586%)\n",
      "TRAIN: 123 [3200/4038 (79%)]\tLoss: 0.009608, Accuracy: 8/8 (100.000%)\n",
      "VAL:   LOSS--> 3.1676 (3.1676)\tACC-->75.000 (75.000)\n",
      " * Accuracy 97.3315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|██████████████████████████████████████████████████████████████████████████████▉                                                             | 124/220 [5:28:02<4:13:58, 158.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.1496 (0.1496)\tACC-->100.000% (100.000%)\n",
      "TRAIN: 124 [0/4038 (0%)]\tLoss: 0.149625, Accuracy: 8/8 (100.000%)\n",
      "TRAIN: LOSS-->0.6580 (0.2503)\tACC-->75.000% (91.978%)\n",
      "TRAIN: 124 [1600/4038 (40%)]\tLoss: 0.658043, Accuracy: 6/8 (75.000%)\n",
      "TRAIN: LOSS-->0.3767 (0.2577)\tACC-->87.500% (91.241%)\n",
      "TRAIN: 124 [3200/4038 (79%)]\tLoss: 0.376744, Accuracy: 7/8 (87.500%)\n",
      "VAL:   LOSS--> 0.0785 (0.0785)\tACC-->100.000 (100.000)\n",
      " * Accuracy 95.6461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|███████████████████████████████████████████████████████████████████████████████▌                                                            | 125/220 [5:30:39<4:11:18, 158.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.0222 (0.0222)\tACC-->100.000% (100.000%)\n",
      "TRAIN: 125 [0/4038 (0%)]\tLoss: 0.022226, Accuracy: 8/8 (100.000%)\n",
      "TRAIN: LOSS-->0.8159 (0.2725)\tACC-->62.500% (90.423%)\n",
      "TRAIN: 125 [1600/4038 (40%)]\tLoss: 0.815904, Accuracy: 5/8 (62.500%)\n",
      "TRAIN: LOSS-->0.4165 (0.2692)\tACC-->75.000% (90.929%)\n",
      "TRAIN: 125 [3200/4038 (79%)]\tLoss: 0.416539, Accuracy: 6/8 (75.000%)\n",
      "VAL:   LOSS--> 0.0008 (0.0008)\tACC-->100.000 (100.000)\n",
      " * Accuracy 96.2079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|████████████████████████████████████████████████████████████████████████████████▏                                                           | 126/220 [5:33:16<4:08:38, 158.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.3599 (0.3599)\tACC-->87.500% (87.500%)\n",
      "TRAIN: 126 [0/4038 (0%)]\tLoss: 0.359873, Accuracy: 7/8 (87.500%)\n",
      "TRAIN: LOSS-->0.1921 (0.3015)\tACC-->87.500% (89.428%)\n",
      "TRAIN: 126 [1600/4038 (40%)]\tLoss: 0.192067, Accuracy: 7/8 (87.500%)\n",
      "TRAIN: LOSS-->0.2390 (0.2876)\tACC-->87.500% (90.118%)\n",
      "TRAIN: 126 [3200/4038 (79%)]\tLoss: 0.238968, Accuracy: 7/8 (87.500%)\n",
      "VAL:   LOSS--> 0.4176 (0.4176)\tACC-->87.500 (87.500)\n",
      " * Accuracy 94.9438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 58%|████████████████████████████████████████████████████████████████████████████████▊                                                           | 127/220 [5:35:54<4:05:58, 158.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.1612 (0.1612)\tACC-->100.000% (100.000%)\n",
      "TRAIN: 127 [0/4038 (0%)]\tLoss: 0.161205, Accuracy: 8/8 (100.000%)\n",
      "TRAIN: LOSS-->0.2086 (0.2598)\tACC-->87.500% (90.547%)\n",
      "TRAIN: 127 [1600/4038 (40%)]\tLoss: 0.208603, Accuracy: 7/8 (87.500%)\n",
      "TRAIN: LOSS-->0.0884 (0.2821)\tACC-->100.000% (90.586%)\n",
      "TRAIN: 127 [3200/4038 (79%)]\tLoss: 0.088391, Accuracy: 8/8 (100.000%)\n",
      "VAL:   LOSS--> 0.0173 (0.0173)\tACC-->100.000 (100.000)\n",
      " * Accuracy 94.5225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 58%|█████████████████████████████████████████████████████████████████████████████████▍                                                          | 128/220 [5:38:32<4:03:19, 158.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.1394 (0.1394)\tACC-->87.500% (87.500%)\n",
      "TRAIN: 128 [0/4038 (0%)]\tLoss: 0.139441, Accuracy: 7/8 (87.500%)\n",
      "TRAIN: LOSS-->0.0332 (0.2851)\tACC-->100.000% (90.112%)\n",
      "TRAIN: 128 [1600/4038 (40%)]\tLoss: 0.033163, Accuracy: 8/8 (100.000%)\n",
      "TRAIN: LOSS-->0.0065 (0.2865)\tACC-->100.000% (90.118%)\n",
      "TRAIN: 128 [3200/4038 (79%)]\tLoss: 0.006548, Accuracy: 8/8 (100.000%)\n",
      "VAL:   LOSS--> 0.1319 (0.1319)\tACC-->87.500 (87.500)\n",
      " * Accuracy 96.2079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 59%|██████████████████████████████████████████████████████████████████████████████████                                                          | 129/220 [5:41:09<4:00:39, 158.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.0046 (0.0046)\tACC-->100.000% (100.000%)\n",
      "TRAIN: 129 [0/4038 (0%)]\tLoss: 0.004636, Accuracy: 8/8 (100.000%)\n",
      "TRAIN: LOSS-->0.5354 (0.2527)\tACC-->87.500% (90.299%)\n",
      "TRAIN: 129 [1600/4038 (40%)]\tLoss: 0.535423, Accuracy: 7/8 (87.500%)\n",
      "TRAIN: LOSS-->0.2949 (0.2514)\tACC-->87.500% (90.555%)\n",
      "TRAIN: 129 [3200/4038 (79%)]\tLoss: 0.294927, Accuracy: 7/8 (87.500%)\n",
      "VAL:   LOSS--> 0.0338 (0.0338)\tACC-->100.000 (100.000)\n",
      " * Accuracy 96.3483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 59%|██████████████████████████████████████████████████████████████████████████████████▋                                                         | 130/220 [5:43:46<3:58:00, 158.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.0143 (0.0143)\tACC-->100.000% (100.000%)\n",
      "TRAIN: 130 [0/4038 (0%)]\tLoss: 0.014260, Accuracy: 8/8 (100.000%)\n",
      "TRAIN: LOSS-->0.0747 (0.2557)\tACC-->100.000% (91.356%)\n",
      "TRAIN: 130 [1600/4038 (40%)]\tLoss: 0.074702, Accuracy: 8/8 (100.000%)\n",
      "TRAIN: LOSS-->0.0872 (0.2622)\tACC-->100.000% (91.178%)\n",
      "TRAIN: 130 [3200/4038 (79%)]\tLoss: 0.087198, Accuracy: 8/8 (100.000%)\n",
      "VAL:   LOSS--> 0.0574 (0.0574)\tACC-->100.000 (100.000)\n",
      " * Accuracy 94.3820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|███████████████████████████████████████████████████████████████████████████████████▎                                                        | 131/220 [5:46:24<3:55:20, 158.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.0518 (0.0518)\tACC-->100.000% (100.000%)\n",
      "TRAIN: 131 [0/4038 (0%)]\tLoss: 0.051848, Accuracy: 8/8 (100.000%)\n",
      "TRAIN: LOSS-->0.1501 (0.2837)\tACC-->100.000% (90.609%)\n",
      "TRAIN: 131 [1600/4038 (40%)]\tLoss: 0.150067, Accuracy: 8/8 (100.000%)\n",
      "TRAIN: LOSS-->0.1259 (0.2578)\tACC-->100.000% (91.022%)\n",
      "TRAIN: 131 [3200/4038 (79%)]\tLoss: 0.125871, Accuracy: 8/8 (100.000%)\n",
      "VAL:   LOSS--> 0.1246 (0.1246)\tACC-->87.500 (87.500)\n",
      " * Accuracy 93.3989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|████████████████████████████████████████████████████████████████████████████████████                                                        | 132/220 [5:49:01<3:52:41, 158.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.0235 (0.0235)\tACC-->100.000% (100.000%)\n",
      "TRAIN: 132 [0/4038 (0%)]\tLoss: 0.023542, Accuracy: 8/8 (100.000%)\n",
      "TRAIN: LOSS-->0.3083 (0.2557)\tACC-->87.500% (91.294%)\n",
      "TRAIN: 132 [1600/4038 (40%)]\tLoss: 0.308267, Accuracy: 7/8 (87.500%)\n",
      "TRAIN: LOSS-->0.0132 (0.2405)\tACC-->100.000% (91.708%)\n",
      "TRAIN: 132 [3200/4038 (79%)]\tLoss: 0.013173, Accuracy: 8/8 (100.000%)\n",
      "VAL:   LOSS--> 0.0407 (0.0407)\tACC-->100.000 (100.000)\n",
      " * Accuracy 93.9607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|████████████████████████████████████████████████████████████████████████████████████▋                                                       | 133/220 [5:51:39<3:50:01, 158.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.0142 (0.0142)\tACC-->100.000% (100.000%)\n",
      "TRAIN: 133 [0/4038 (0%)]\tLoss: 0.014202, Accuracy: 8/8 (100.000%)\n",
      "TRAIN: LOSS-->0.2609 (0.3228)\tACC-->87.500% (88.930%)\n",
      "TRAIN: 133 [1600/4038 (40%)]\tLoss: 0.260912, Accuracy: 7/8 (87.500%)\n",
      "TRAIN: LOSS-->0.4299 (0.2772)\tACC-->75.000% (90.368%)\n",
      "TRAIN: 133 [3200/4038 (79%)]\tLoss: 0.429904, Accuracy: 6/8 (75.000%)\n",
      "VAL:   LOSS--> 0.0920 (0.0920)\tACC-->100.000 (100.000)\n",
      " * Accuracy 94.8034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 61%|█████████████████████████████████████████████████████████████████████████████████████▎                                                      | 134/220 [5:54:16<3:47:22, 158.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.0830 (0.0830)\tACC-->100.000% (100.000%)\n",
      "TRAIN: 134 [0/4038 (0%)]\tLoss: 0.082996, Accuracy: 8/8 (100.000%)\n",
      "TRAIN: LOSS-->0.2978 (0.2588)\tACC-->87.500% (91.169%)\n",
      "TRAIN: 134 [1600/4038 (40%)]\tLoss: 0.297784, Accuracy: 7/8 (87.500%)\n",
      "TRAIN: LOSS-->0.1737 (0.2705)\tACC-->87.500% (91.209%)\n",
      "TRAIN: 134 [3200/4038 (79%)]\tLoss: 0.173673, Accuracy: 7/8 (87.500%)\n",
      "VAL:   LOSS--> 0.0706 (0.0706)\tACC-->100.000 (100.000)\n",
      " * Accuracy 95.5056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 61%|█████████████████████████████████████████████████████████████████████████████████████▉                                                      | 135/220 [5:56:53<3:44:42, 158.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.1143 (0.1143)\tACC-->100.000% (100.000%)\n",
      "TRAIN: 135 [0/4038 (0%)]\tLoss: 0.114271, Accuracy: 8/8 (100.000%)\n",
      "TRAIN: LOSS-->0.0594 (0.2303)\tACC-->100.000% (92.786%)\n",
      "TRAIN: 135 [1600/4038 (40%)]\tLoss: 0.059368, Accuracy: 8/8 (100.000%)\n",
      "TRAIN: LOSS-->0.2567 (0.2509)\tACC-->87.500% (92.176%)\n",
      "TRAIN: 135 [3200/4038 (79%)]\tLoss: 0.256659, Accuracy: 7/8 (87.500%)\n",
      "VAL:   LOSS--> 0.0042 (0.0042)\tACC-->100.000 (100.000)\n",
      " * Accuracy 96.2079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|██████████████████████████████████████████████████████████████████████████████████████▌                                                     | 136/220 [5:59:31<3:42:03, 158.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.2979 (0.2979)\tACC-->100.000% (100.000%)\n",
      "TRAIN: 136 [0/4038 (0%)]\tLoss: 0.297889, Accuracy: 8/8 (100.000%)\n",
      "TRAIN: LOSS-->0.0595 (0.2509)\tACC-->100.000% (91.294%)\n",
      "TRAIN: 136 [1600/4038 (40%)]\tLoss: 0.059468, Accuracy: 8/8 (100.000%)\n",
      "TRAIN: LOSS-->0.1771 (0.2466)\tACC-->87.500% (91.085%)\n",
      "TRAIN: 136 [3200/4038 (79%)]\tLoss: 0.177061, Accuracy: 7/8 (87.500%)\n",
      "VAL:   LOSS--> 0.1687 (0.1687)\tACC-->87.500 (87.500)\n",
      " * Accuracy 95.5056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|███████████████████████████████████████████████████████████████████████████████████████▏                                                    | 137/220 [6:02:07<3:39:23, 158.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.2120 (0.2120)\tACC-->87.500% (87.500%)\n",
      "TRAIN: 137 [0/4038 (0%)]\tLoss: 0.212036, Accuracy: 7/8 (87.500%)\n",
      "TRAIN: LOSS-->0.2678 (0.2478)\tACC-->100.000% (90.796%)\n",
      "TRAIN: 137 [1600/4038 (40%)]\tLoss: 0.267809, Accuracy: 8/8 (100.000%)\n",
      "TRAIN: LOSS-->0.2747 (0.2621)\tACC-->87.500% (90.742%)\n",
      "TRAIN: 137 [3200/4038 (79%)]\tLoss: 0.274726, Accuracy: 7/8 (87.500%)\n",
      "VAL:   LOSS--> 0.0005 (0.0005)\tACC-->100.000 (100.000)\n",
      " * Accuracy 92.9775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 63%|███████████████████████████████████████████████████████████████████████████████████████▊                                                    | 138/220 [6:04:44<3:36:43, 158.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.0302 (0.0302)\tACC-->100.000% (100.000%)\n",
      "TRAIN: 138 [0/4038 (0%)]\tLoss: 0.030226, Accuracy: 8/8 (100.000%)\n",
      "TRAIN: LOSS-->0.0360 (0.2476)\tACC-->100.000% (91.915%)\n",
      "TRAIN: 138 [1600/4038 (40%)]\tLoss: 0.035978, Accuracy: 8/8 (100.000%)\n",
      "TRAIN: LOSS-->0.0277 (0.2456)\tACC-->100.000% (91.739%)\n",
      "TRAIN: 138 [3200/4038 (79%)]\tLoss: 0.027697, Accuracy: 8/8 (100.000%)\n",
      "VAL:   LOSS--> 0.1765 (0.1765)\tACC-->87.500 (87.500)\n",
      " * Accuracy 96.6292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 63%|████████████████████████████████████████████████████████████████████████████████████████▍                                                   | 139/220 [6:07:21<3:34:04, 158.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.0935 (0.0935)\tACC-->100.000% (100.000%)\n",
      "TRAIN: 139 [0/4038 (0%)]\tLoss: 0.093522, Accuracy: 8/8 (100.000%)\n",
      "TRAIN: LOSS-->0.6913 (0.2668)\tACC-->75.000% (90.050%)\n",
      "TRAIN: 139 [1600/4038 (40%)]\tLoss: 0.691335, Accuracy: 6/8 (75.000%)\n",
      "TRAIN: LOSS-->0.4424 (0.2532)\tACC-->87.500% (91.334%)\n",
      "TRAIN: 139 [3200/4038 (79%)]\tLoss: 0.442442, Accuracy: 7/8 (87.500%)\n",
      "VAL:   LOSS--> 0.0069 (0.0069)\tACC-->100.000 (100.000)\n",
      " * Accuracy 92.9775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 64%|█████████████████████████████████████████████████████████████████████████████████████████                                                   | 140/220 [6:09:59<3:31:25, 158.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.0900 (0.0900)\tACC-->100.000% (100.000%)\n",
      "TRAIN: 140 [0/4038 (0%)]\tLoss: 0.090023, Accuracy: 8/8 (100.000%)\n",
      "TRAIN: LOSS-->0.0590 (0.2706)\tACC-->100.000% (90.112%)\n",
      "TRAIN: 140 [1600/4038 (40%)]\tLoss: 0.058992, Accuracy: 8/8 (100.000%)\n",
      "TRAIN: LOSS-->0.0491 (0.2674)\tACC-->100.000% (90.461%)\n",
      "TRAIN: 140 [3200/4038 (79%)]\tLoss: 0.049150, Accuracy: 8/8 (100.000%)\n",
      "VAL:   LOSS--> 0.1262 (0.1262)\tACC-->100.000 (100.000)\n",
      " * Accuracy 95.6461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 64%|█████████████████████████████████████████████████████████████████████████████████████████▋                                                  | 141/220 [6:12:35<3:28:45, 158.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.4795 (0.4795)\tACC-->75.000% (75.000%)\n",
      "TRAIN: 141 [0/4038 (0%)]\tLoss: 0.479466, Accuracy: 6/8 (75.000%)\n",
      "TRAIN: LOSS-->0.0739 (0.2536)\tACC-->100.000% (91.294%)\n",
      "TRAIN: 141 [1600/4038 (40%)]\tLoss: 0.073867, Accuracy: 8/8 (100.000%)\n",
      "TRAIN: LOSS-->0.4663 (0.2439)\tACC-->75.000% (91.708%)\n",
      "TRAIN: 141 [3200/4038 (79%)]\tLoss: 0.466313, Accuracy: 6/8 (75.000%)\n",
      "VAL:   LOSS--> 0.1351 (0.1351)\tACC-->100.000 (100.000)\n",
      " * Accuracy 94.5225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 65%|██████████████████████████████████████████████████████████████████████████████████████████▎                                                 | 142/220 [6:15:12<3:26:06, 158.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.2962 (0.2962)\tACC-->87.500% (87.500%)\n",
      "TRAIN: 142 [0/4038 (0%)]\tLoss: 0.296168, Accuracy: 7/8 (87.500%)\n",
      "TRAIN: LOSS-->0.6788 (0.2683)\tACC-->75.000% (91.107%)\n",
      "TRAIN: 142 [1600/4038 (40%)]\tLoss: 0.678824, Accuracy: 6/8 (75.000%)\n",
      "TRAIN: LOSS-->0.5695 (0.2599)\tACC-->75.000% (90.991%)\n",
      "TRAIN: 142 [3200/4038 (79%)]\tLoss: 0.569483, Accuracy: 6/8 (75.000%)\n",
      "VAL:   LOSS--> 0.0026 (0.0026)\tACC-->100.000 (100.000)\n",
      " * Accuracy 96.6292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 65%|███████████████████████████████████████████████████████████████████████████████████████████                                                 | 143/220 [6:17:49<3:23:26, 158.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->1.0746 (1.0746)\tACC-->75.000% (75.000%)\n",
      "TRAIN: 143 [0/4038 (0%)]\tLoss: 1.074621, Accuracy: 6/8 (75.000%)\n",
      "TRAIN: LOSS-->0.0184 (0.2389)\tACC-->100.000% (92.040%)\n",
      "TRAIN: 143 [1600/4038 (40%)]\tLoss: 0.018433, Accuracy: 8/8 (100.000%)\n",
      "TRAIN: LOSS-->0.2572 (0.2324)\tACC-->87.500% (92.363%)\n",
      "TRAIN: 143 [3200/4038 (79%)]\tLoss: 0.257240, Accuracy: 7/8 (87.500%)\n",
      "VAL:   LOSS--> 0.0343 (0.0343)\tACC-->100.000 (100.000)\n",
      " * Accuracy 96.0674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 65%|███████████████████████████████████████████████████████████████████████████████████████████▋                                                | 144/220 [6:20:26<3:20:47, 158.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.2241 (0.2241)\tACC-->87.500% (87.500%)\n",
      "TRAIN: 144 [0/4038 (0%)]\tLoss: 0.224097, Accuracy: 7/8 (87.500%)\n",
      "TRAIN: LOSS-->0.4711 (0.2914)\tACC-->87.500% (89.863%)\n",
      "TRAIN: 144 [1600/4038 (40%)]\tLoss: 0.471105, Accuracy: 7/8 (87.500%)\n",
      "TRAIN: LOSS-->0.0144 (0.2612)\tACC-->100.000% (90.960%)\n",
      "TRAIN: 144 [3200/4038 (79%)]\tLoss: 0.014432, Accuracy: 8/8 (100.000%)\n",
      "VAL:   LOSS--> 0.0011 (0.0011)\tACC-->100.000 (100.000)\n",
      " * Accuracy 96.7697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 66%|████████████████████████████████████████████████████████████████████████████████████████████▎                                               | 145/220 [6:23:04<3:18:08, 158.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.0593 (0.0593)\tACC-->100.000% (100.000%)\n",
      "TRAIN: 145 [0/4038 (0%)]\tLoss: 0.059314, Accuracy: 8/8 (100.000%)\n",
      "TRAIN: LOSS-->0.1784 (0.2426)\tACC-->100.000% (90.920%)\n",
      "TRAIN: 145 [1600/4038 (40%)]\tLoss: 0.178447, Accuracy: 8/8 (100.000%)\n",
      "TRAIN: LOSS-->0.2793 (0.2540)\tACC-->100.000% (90.711%)\n",
      "TRAIN: 145 [3200/4038 (79%)]\tLoss: 0.279321, Accuracy: 8/8 (100.000%)\n",
      "VAL:   LOSS--> 0.0280 (0.0280)\tACC-->100.000 (100.000)\n",
      " * Accuracy 95.2247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 66%|████████████████████████████████████████████████████████████████████████████████████████████▉                                               | 146/220 [6:25:41<3:15:29, 158.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.0212 (0.0212)\tACC-->100.000% (100.000%)\n",
      "TRAIN: 146 [0/4038 (0%)]\tLoss: 0.021246, Accuracy: 8/8 (100.000%)\n",
      "TRAIN: LOSS-->0.8312 (0.2393)\tACC-->62.500% (91.604%)\n",
      "TRAIN: 146 [1600/4038 (40%)]\tLoss: 0.831152, Accuracy: 5/8 (62.500%)\n",
      "TRAIN: LOSS-->0.0604 (0.2505)\tACC-->100.000% (91.428%)\n",
      "TRAIN: 146 [3200/4038 (79%)]\tLoss: 0.060385, Accuracy: 8/8 (100.000%)\n",
      "VAL:   LOSS--> 0.0476 (0.0476)\tACC-->100.000 (100.000)\n",
      " * Accuracy 96.4888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|█████████████████████████████████████████████████████████████████████████████████████████████▌                                              | 147/220 [6:28:18<3:12:49, 158.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.1699 (0.1699)\tACC-->100.000% (100.000%)\n",
      "TRAIN: 147 [0/4038 (0%)]\tLoss: 0.169902, Accuracy: 8/8 (100.000%)\n",
      "TRAIN: LOSS-->0.4641 (0.2190)\tACC-->75.000% (93.035%)\n",
      "TRAIN: 147 [1600/4038 (40%)]\tLoss: 0.464111, Accuracy: 6/8 (75.000%)\n",
      "TRAIN: LOSS-->0.0065 (0.2428)\tACC-->100.000% (91.771%)\n",
      "TRAIN: 147 [3200/4038 (79%)]\tLoss: 0.006459, Accuracy: 8/8 (100.000%)\n",
      "VAL:   LOSS--> 0.0003 (0.0003)\tACC-->100.000 (100.000)\n",
      " * Accuracy 97.1910\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|██████████████████████████████████████████████████████████████████████████████████████████████▏                                             | 148/220 [6:30:55<3:10:10, 158.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.0219 (0.0219)\tACC-->100.000% (100.000%)\n",
      "TRAIN: 148 [0/4038 (0%)]\tLoss: 0.021906, Accuracy: 8/8 (100.000%)\n",
      "TRAIN: LOSS-->0.2116 (0.2326)\tACC-->87.500% (91.791%)\n",
      "TRAIN: 148 [1600/4038 (40%)]\tLoss: 0.211600, Accuracy: 7/8 (87.500%)\n",
      "TRAIN: LOSS-->0.0478 (0.2267)\tACC-->100.000% (91.802%)\n",
      "TRAIN: 148 [3200/4038 (79%)]\tLoss: 0.047829, Accuracy: 8/8 (100.000%)\n",
      "VAL:   LOSS--> 0.1429 (0.1429)\tACC-->87.500 (87.500)\n",
      " * Accuracy 95.0843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 68%|██████████████████████████████████████████████████████████████████████████████████████████████▊                                             | 149/220 [6:33:32<3:07:31, 158.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.1106 (0.1106)\tACC-->100.000% (100.000%)\n",
      "TRAIN: 149 [0/4038 (0%)]\tLoss: 0.110621, Accuracy: 8/8 (100.000%)\n",
      "TRAIN: LOSS-->0.3670 (0.2780)\tACC-->87.500% (90.734%)\n",
      "TRAIN: 149 [1600/4038 (40%)]\tLoss: 0.367031, Accuracy: 7/8 (87.500%)\n",
      "TRAIN: LOSS-->0.0945 (0.2611)\tACC-->100.000% (91.054%)\n",
      "TRAIN: 149 [3200/4038 (79%)]\tLoss: 0.094484, Accuracy: 8/8 (100.000%)\n",
      "VAL:   LOSS--> 0.0156 (0.0156)\tACC-->100.000 (100.000)\n",
      " * Accuracy 95.0843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 68%|███████████████████████████████████████████████████████████████████████████████████████████████▍                                            | 150/220 [6:36:09<3:04:52, 158.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.0224 (0.0224)\tACC-->100.000% (100.000%)\n",
      "TRAIN: 150 [0/4038 (0%)]\tLoss: 0.022436, Accuracy: 8/8 (100.000%)\n",
      "TRAIN: LOSS-->0.2203 (0.2582)\tACC-->87.500% (91.107%)\n",
      "TRAIN: 150 [1600/4038 (40%)]\tLoss: 0.220291, Accuracy: 7/8 (87.500%)\n",
      "TRAIN: LOSS-->0.3214 (0.2482)\tACC-->87.500% (91.147%)\n",
      "TRAIN: 150 [3200/4038 (79%)]\tLoss: 0.321390, Accuracy: 7/8 (87.500%)\n",
      "VAL:   LOSS--> 0.0270 (0.0270)\tACC-->100.000 (100.000)\n",
      " * Accuracy 96.7697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 69%|████████████████████████████████████████████████████████████████████████████████████████████████                                            | 151/220 [6:38:46<3:02:13, 158.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.1593 (0.1593)\tACC-->87.500% (87.500%)\n",
      "TRAIN: 151 [0/4038 (0%)]\tLoss: 0.159260, Accuracy: 7/8 (87.500%)\n",
      "TRAIN: LOSS-->0.2639 (0.2710)\tACC-->87.500% (89.988%)\n",
      "TRAIN: 151 [1600/4038 (40%)]\tLoss: 0.263946, Accuracy: 7/8 (87.500%)\n",
      "TRAIN: LOSS-->0.4267 (0.2484)\tACC-->75.000% (90.960%)\n",
      "TRAIN: 151 [3200/4038 (79%)]\tLoss: 0.426745, Accuracy: 6/8 (75.000%)\n",
      "VAL:   LOSS--> 0.0003 (0.0003)\tACC-->100.000 (100.000)\n",
      " * Accuracy 96.7697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 69%|████████████████████████████████████████████████████████████████████████████████████████████████▋                                           | 152/220 [6:41:23<2:59:34, 158.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.1384 (0.1384)\tACC-->87.500% (87.500%)\n",
      "TRAIN: 152 [0/4038 (0%)]\tLoss: 0.138373, Accuracy: 7/8 (87.500%)\n",
      "TRAIN: LOSS-->0.0639 (0.2565)\tACC-->100.000% (91.294%)\n",
      "TRAIN: 152 [1600/4038 (40%)]\tLoss: 0.063950, Accuracy: 8/8 (100.000%)\n",
      "TRAIN: LOSS-->0.0084 (0.2309)\tACC-->100.000% (91.958%)\n",
      "TRAIN: 152 [3200/4038 (79%)]\tLoss: 0.008400, Accuracy: 8/8 (100.000%)\n",
      "VAL:   LOSS--> 0.0971 (0.0971)\tACC-->100.000 (100.000)\n",
      " * Accuracy 97.6124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|█████████████████████████████████████████████████████████████████████████████████████████████████▎                                          | 153/220 [6:44:00<2:56:55, 158.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.0397 (0.0397)\tACC-->100.000% (100.000%)\n",
      "TRAIN: 153 [0/4038 (0%)]\tLoss: 0.039733, Accuracy: 8/8 (100.000%)\n",
      "TRAIN: LOSS-->0.1220 (0.2464)\tACC-->87.500% (91.604%)\n",
      "TRAIN: 153 [1600/4038 (40%)]\tLoss: 0.122048, Accuracy: 7/8 (87.500%)\n",
      "TRAIN: LOSS-->0.0549 (0.2423)\tACC-->100.000% (91.334%)\n",
      "TRAIN: 153 [3200/4038 (79%)]\tLoss: 0.054863, Accuracy: 8/8 (100.000%)\n",
      "VAL:   LOSS--> 0.0797 (0.0797)\tACC-->100.000 (100.000)\n",
      " * Accuracy 94.9438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|██████████████████████████████████████████████████████████████████████████████████████████████████                                          | 154/220 [6:46:38<2:54:16, 158.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.0357 (0.0357)\tACC-->100.000% (100.000%)\n",
      "TRAIN: 154 [0/4038 (0%)]\tLoss: 0.035689, Accuracy: 8/8 (100.000%)\n",
      "TRAIN: LOSS-->0.2383 (0.2184)\tACC-->87.500% (92.164%)\n",
      "TRAIN: 154 [1600/4038 (40%)]\tLoss: 0.238313, Accuracy: 7/8 (87.500%)\n",
      "TRAIN: LOSS-->0.0418 (0.2285)\tACC-->100.000% (91.552%)\n",
      "TRAIN: 154 [3200/4038 (79%)]\tLoss: 0.041786, Accuracy: 8/8 (100.000%)\n",
      "VAL:   LOSS--> 0.1191 (0.1191)\tACC-->87.500 (87.500)\n",
      " * Accuracy 97.1910\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|██████████████████████████████████████████████████████████████████████████████████████████████████▋                                         | 155/220 [6:49:16<2:51:37, 158.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.0957 (0.0957)\tACC-->87.500% (87.500%)\n",
      "TRAIN: 155 [0/4038 (0%)]\tLoss: 0.095682, Accuracy: 7/8 (87.500%)\n",
      "TRAIN: LOSS-->0.1318 (0.2149)\tACC-->100.000% (92.848%)\n",
      "TRAIN: 155 [1600/4038 (40%)]\tLoss: 0.131780, Accuracy: 8/8 (100.000%)\n",
      "TRAIN: LOSS-->0.0764 (0.2158)\tACC-->100.000% (92.737%)\n",
      "TRAIN: 155 [3200/4038 (79%)]\tLoss: 0.076389, Accuracy: 8/8 (100.000%)\n",
      "VAL:   LOSS--> 0.0098 (0.0098)\tACC-->100.000 (100.000)\n",
      " * Accuracy 97.0506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 71%|███████████████████████████████████████████████████████████████████████████████████████████████████▎                                        | 156/220 [6:51:53<2:48:58, 158.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.1281 (0.1281)\tACC-->87.500% (87.500%)\n",
      "TRAIN: 156 [0/4038 (0%)]\tLoss: 0.128086, Accuracy: 7/8 (87.500%)\n",
      "TRAIN: LOSS-->0.1107 (0.2407)\tACC-->100.000% (91.542%)\n",
      "TRAIN: 156 [1600/4038 (40%)]\tLoss: 0.110717, Accuracy: 8/8 (100.000%)\n",
      "TRAIN: LOSS-->0.2647 (0.2256)\tACC-->87.500% (91.708%)\n",
      "TRAIN: 156 [3200/4038 (79%)]\tLoss: 0.264658, Accuracy: 7/8 (87.500%)\n",
      "VAL:   LOSS--> 0.0028 (0.0028)\tACC-->100.000 (100.000)\n",
      " * Accuracy 95.3652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 71%|███████████████████████████████████████████████████████████████████████████████████████████████████▉                                        | 157/220 [6:54:30<2:46:20, 158.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.0471 (0.0471)\tACC-->100.000% (100.000%)\n",
      "TRAIN: 157 [0/4038 (0%)]\tLoss: 0.047052, Accuracy: 8/8 (100.000%)\n",
      "TRAIN: LOSS-->0.0711 (0.2469)\tACC-->100.000% (91.045%)\n",
      "TRAIN: 157 [1600/4038 (40%)]\tLoss: 0.071109, Accuracy: 8/8 (100.000%)\n",
      "TRAIN: LOSS-->0.0703 (0.2431)\tACC-->100.000% (91.521%)\n",
      "TRAIN: 157 [3200/4038 (79%)]\tLoss: 0.070307, Accuracy: 8/8 (100.000%)\n",
      "VAL:   LOSS--> 0.2925 (0.2925)\tACC-->75.000 (75.000)\n",
      " * Accuracy 94.3820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 72%|████████████████████████████████████████████████████████████████████████████████████████████████████▌                                       | 158/220 [6:57:07<2:43:41, 158.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.1030 (0.1030)\tACC-->100.000% (100.000%)\n",
      "TRAIN: 158 [0/4038 (0%)]\tLoss: 0.102964, Accuracy: 8/8 (100.000%)\n",
      "TRAIN: LOSS-->0.4411 (0.2425)\tACC-->87.500% (91.294%)\n",
      "TRAIN: 158 [1600/4038 (40%)]\tLoss: 0.441077, Accuracy: 7/8 (87.500%)\n",
      "TRAIN: LOSS-->0.0123 (0.2412)\tACC-->100.000% (91.521%)\n",
      "TRAIN: 158 [3200/4038 (79%)]\tLoss: 0.012275, Accuracy: 8/8 (100.000%)\n",
      "VAL:   LOSS--> 0.0198 (0.0198)\tACC-->100.000 (100.000)\n",
      " * Accuracy 96.3483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 72%|█████████████████████████████████████████████████████████████████████████████████████████████████████▏                                      | 159/220 [6:59:45<2:41:02, 158.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.5253 (0.5253)\tACC-->75.000% (75.000%)\n",
      "TRAIN: 159 [0/4038 (0%)]\tLoss: 0.525268, Accuracy: 6/8 (75.000%)\n",
      "TRAIN: LOSS-->0.0680 (0.2451)\tACC-->100.000% (91.356%)\n",
      "TRAIN: 159 [1600/4038 (40%)]\tLoss: 0.067978, Accuracy: 8/8 (100.000%)\n",
      "TRAIN: LOSS-->0.0066 (0.2345)\tACC-->100.000% (91.926%)\n",
      "TRAIN: 159 [3200/4038 (79%)]\tLoss: 0.006583, Accuracy: 8/8 (100.000%)\n",
      "VAL:   LOSS--> 0.0005 (0.0005)\tACC-->100.000 (100.000)\n",
      " * Accuracy 95.5056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 73%|█████████████████████████████████████████████████████████████████████████████████████████████████████▊                                      | 160/220 [7:02:21<2:38:23, 158.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.3801 (0.3801)\tACC-->87.500% (87.500%)\n",
      "TRAIN: 160 [0/4038 (0%)]\tLoss: 0.380050, Accuracy: 7/8 (87.500%)\n",
      "TRAIN: LOSS-->0.0151 (0.2262)\tACC-->100.000% (91.978%)\n",
      "TRAIN: 160 [1600/4038 (40%)]\tLoss: 0.015075, Accuracy: 8/8 (100.000%)\n",
      "TRAIN: LOSS-->0.1915 (0.2465)\tACC-->87.500% (91.272%)\n",
      "TRAIN: 160 [3200/4038 (79%)]\tLoss: 0.191508, Accuracy: 7/8 (87.500%)\n",
      "VAL:   LOSS--> 0.5498 (0.5498)\tACC-->75.000 (75.000)\n",
      " * Accuracy 96.0674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 73%|██████████████████████████████████████████████████████████████████████████████████████████████████████▍                                     | 161/220 [7:04:58<2:35:44, 158.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.1237 (0.1237)\tACC-->87.500% (87.500%)\n",
      "TRAIN: 161 [0/4038 (0%)]\tLoss: 0.123735, Accuracy: 7/8 (87.500%)\n",
      "TRAIN: LOSS-->0.0483 (0.2382)\tACC-->100.000% (91.791%)\n",
      "TRAIN: 161 [1600/4038 (40%)]\tLoss: 0.048301, Accuracy: 8/8 (100.000%)\n",
      "TRAIN: LOSS-->0.2154 (0.2470)\tACC-->100.000% (91.459%)\n",
      "TRAIN: 161 [3200/4038 (79%)]\tLoss: 0.215400, Accuracy: 8/8 (100.000%)\n",
      "VAL:   LOSS--> 0.5231 (0.5231)\tACC-->75.000 (75.000)\n",
      " * Accuracy 97.7528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 74%|███████████████████████████████████████████████████████████████████████████████████████████████████████                                     | 162/220 [7:07:36<2:33:05, 158.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.2792 (0.2792)\tACC-->87.500% (87.500%)\n",
      "TRAIN: 162 [0/4038 (0%)]\tLoss: 0.279201, Accuracy: 7/8 (87.500%)\n",
      "TRAIN: LOSS-->0.1834 (0.2225)\tACC-->87.500% (91.729%)\n",
      "TRAIN: 162 [1600/4038 (40%)]\tLoss: 0.183393, Accuracy: 7/8 (87.500%)\n",
      "TRAIN: LOSS-->0.1758 (0.2388)\tACC-->87.500% (91.397%)\n",
      "TRAIN: 162 [3200/4038 (79%)]\tLoss: 0.175850, Accuracy: 7/8 (87.500%)\n",
      "VAL:   LOSS--> 0.0318 (0.0318)\tACC-->100.000 (100.000)\n",
      " * Accuracy 95.5056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 74%|███████████████████████████████████████████████████████████████████████████████████████████████████████▋                                    | 163/220 [7:10:13<2:30:26, 158.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.3631 (0.3631)\tACC-->75.000% (75.000%)\n",
      "TRAIN: 163 [0/4038 (0%)]\tLoss: 0.363129, Accuracy: 6/8 (75.000%)\n",
      "TRAIN: LOSS-->0.1402 (0.2230)\tACC-->100.000% (92.040%)\n",
      "TRAIN: 163 [1600/4038 (40%)]\tLoss: 0.140211, Accuracy: 8/8 (100.000%)\n",
      "TRAIN: LOSS-->0.0582 (0.2385)\tACC-->100.000% (91.365%)\n",
      "TRAIN: 163 [3200/4038 (79%)]\tLoss: 0.058179, Accuracy: 8/8 (100.000%)\n",
      "VAL:   LOSS--> 0.0022 (0.0022)\tACC-->100.000 (100.000)\n",
      " * Accuracy 95.5056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                   | 164/220 [7:12:51<2:27:48, 158.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.0192 (0.0192)\tACC-->100.000% (100.000%)\n",
      "TRAIN: 164 [0/4038 (0%)]\tLoss: 0.019211, Accuracy: 8/8 (100.000%)\n",
      "TRAIN: LOSS-->0.7181 (0.2419)\tACC-->87.500% (91.915%)\n",
      "TRAIN: 164 [1600/4038 (40%)]\tLoss: 0.718140, Accuracy: 7/8 (87.500%)\n",
      "TRAIN: LOSS-->0.1254 (0.2357)\tACC-->100.000% (91.989%)\n",
      "TRAIN: 164 [3200/4038 (79%)]\tLoss: 0.125365, Accuracy: 8/8 (100.000%)\n",
      "VAL:   LOSS--> 0.0524 (0.0524)\tACC-->100.000 (100.000)\n",
      " * Accuracy 95.5056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|█████████████████████████████████████████████████████████████████████████████████████████████████████████                                   | 165/220 [7:15:27<2:25:09, 158.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.5595 (0.5595)\tACC-->87.500% (87.500%)\n",
      "TRAIN: 165 [0/4038 (0%)]\tLoss: 0.559483, Accuracy: 7/8 (87.500%)\n",
      "TRAIN: LOSS-->0.1283 (0.2508)\tACC-->87.500% (91.418%)\n",
      "TRAIN: 165 [1600/4038 (40%)]\tLoss: 0.128290, Accuracy: 7/8 (87.500%)\n",
      "TRAIN: LOSS-->0.3936 (0.2340)\tACC-->62.500% (91.926%)\n",
      "TRAIN: 165 [3200/4038 (79%)]\tLoss: 0.393601, Accuracy: 5/8 (62.500%)\n",
      "VAL:   LOSS--> 0.0250 (0.0250)\tACC-->100.000 (100.000)\n",
      " * Accuracy 96.2079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|█████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                  | 166/220 [7:18:04<2:22:30, 158.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.4324 (0.4324)\tACC-->87.500% (87.500%)\n",
      "TRAIN: 166 [0/4038 (0%)]\tLoss: 0.432434, Accuracy: 7/8 (87.500%)\n",
      "TRAIN: LOSS-->0.0684 (0.2457)\tACC-->100.000% (92.475%)\n",
      "TRAIN: 166 [1600/4038 (40%)]\tLoss: 0.068357, Accuracy: 8/8 (100.000%)\n",
      "TRAIN: LOSS-->0.2466 (0.2445)\tACC-->87.500% (92.082%)\n",
      "TRAIN: 166 [3200/4038 (79%)]\tLoss: 0.246628, Accuracy: 7/8 (87.500%)\n",
      "VAL:   LOSS--> 0.2308 (0.2308)\tACC-->87.500 (87.500)\n",
      " * Accuracy 93.5393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 76%|██████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                 | 167/220 [7:20:41<2:19:51, 158.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.0086 (0.0086)\tACC-->100.000% (100.000%)\n",
      "TRAIN: 167 [0/4038 (0%)]\tLoss: 0.008608, Accuracy: 8/8 (100.000%)\n",
      "TRAIN: LOSS-->0.0367 (0.2509)\tACC-->100.000% (91.356%)\n",
      "TRAIN: 167 [1600/4038 (40%)]\tLoss: 0.036678, Accuracy: 8/8 (100.000%)\n",
      "TRAIN: LOSS-->0.0846 (0.2289)\tACC-->100.000% (91.895%)\n",
      "TRAIN: 167 [3200/4038 (79%)]\tLoss: 0.084646, Accuracy: 8/8 (100.000%)\n",
      "VAL:   LOSS--> 0.0521 (0.0521)\tACC-->100.000 (100.000)\n",
      " * Accuracy 97.4719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 76%|██████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                 | 168/220 [7:23:19<2:17:13, 158.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.2049 (0.2049)\tACC-->87.500% (87.500%)\n",
      "TRAIN: 168 [0/4038 (0%)]\tLoss: 0.204877, Accuracy: 7/8 (87.500%)\n",
      "TRAIN: LOSS-->0.3201 (0.2383)\tACC-->87.500% (91.418%)\n",
      "TRAIN: 168 [1600/4038 (40%)]\tLoss: 0.320100, Accuracy: 7/8 (87.500%)\n",
      "TRAIN: LOSS-->0.0225 (0.2315)\tACC-->100.000% (91.833%)\n",
      "TRAIN: 168 [3200/4038 (79%)]\tLoss: 0.022522, Accuracy: 8/8 (100.000%)\n",
      "VAL:   LOSS--> 0.0240 (0.0240)\tACC-->100.000 (100.000)\n",
      " * Accuracy 92.8371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 77%|███████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                | 169/220 [7:25:56<2:14:34, 158.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.0588 (0.0588)\tACC-->100.000% (100.000%)\n",
      "TRAIN: 169 [0/4038 (0%)]\tLoss: 0.058756, Accuracy: 8/8 (100.000%)\n",
      "TRAIN: LOSS-->0.0029 (0.2293)\tACC-->100.000% (92.226%)\n",
      "TRAIN: 169 [1600/4038 (40%)]\tLoss: 0.002933, Accuracy: 8/8 (100.000%)\n",
      "TRAIN: LOSS-->0.1469 (0.2268)\tACC-->87.500% (92.519%)\n",
      "TRAIN: 169 [3200/4038 (79%)]\tLoss: 0.146903, Accuracy: 7/8 (87.500%)\n",
      "VAL:   LOSS--> 0.1689 (0.1689)\tACC-->87.500 (87.500)\n",
      " * Accuracy 96.3483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 77%|████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                               | 170/220 [7:28:33<2:11:55, 158.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.0335 (0.0335)\tACC-->100.000% (100.000%)\n",
      "TRAIN: 170 [0/4038 (0%)]\tLoss: 0.033503, Accuracy: 8/8 (100.000%)\n",
      "TRAIN: LOSS-->0.5490 (0.2402)\tACC-->75.000% (92.102%)\n",
      "TRAIN: 170 [1600/4038 (40%)]\tLoss: 0.549001, Accuracy: 6/8 (75.000%)\n",
      "TRAIN: LOSS-->0.2561 (0.2512)\tACC-->100.000% (91.490%)\n",
      "TRAIN: 170 [3200/4038 (79%)]\tLoss: 0.256085, Accuracy: 8/8 (100.000%)\n",
      "VAL:   LOSS--> 0.0000 (0.0000)\tACC-->100.000 (100.000)\n",
      " * Accuracy 95.7865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 78%|████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                               | 171/220 [7:31:11<2:09:17, 158.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.0869 (0.0869)\tACC-->100.000% (100.000%)\n",
      "TRAIN: 171 [0/4038 (0%)]\tLoss: 0.086899, Accuracy: 8/8 (100.000%)\n",
      "TRAIN: LOSS-->1.3285 (0.2299)\tACC-->62.500% (92.164%)\n",
      "TRAIN: 171 [1600/4038 (40%)]\tLoss: 1.328461, Accuracy: 5/8 (62.500%)\n"
     ]
    }
   ],
   "source": [
    "sample_submission = pd.read_csv('sample_submission.csv')\n",
    "sample_submission.columns = ['file', 'species']\n",
    "# sample_submission['category_id'] = 0\n",
    "sample_submission.head(3)\n",
    "\n",
    "test_trans = valid_trans\n",
    "test_data_dir = 'd:/db/data/seedlings/test/'\n",
    "\n",
    "if __name__ == '__main__':  \n",
    "    epochs=220\n",
    "    runId = datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')    \n",
    "    recorder = RecorderMeter(epochs)  # epoc is updated\n",
    "#     model_name = (type(model).__name__)\n",
    "\n",
    "    exp_name = datetime.datetime.now().strftime(model_name + '_' + dataset + '_%Y-%m-%d_%H-%M-%S')    \n",
    "    mPath = './logs' + '/' + dataset + '/' + model_name + '/'    \n",
    "    if not os.path.isdir(mPath):\n",
    "        os.makedirs(mPath)    \n",
    "    print(\"Random Seed: {}\".format(manualSeed))\n",
    "    print(\"python version : {}\".format(sys.version.replace('\\n', ' ')))\n",
    "    print(\"torch  version : {}\".format(torch.__version__))\n",
    "    print(\"cudnn  version : {}\".format(torch.backends.cudnn.version()))    \n",
    "    print(\"=> Final model name '{}'\".format(model_name))            \n",
    "    print (\"MODEL: {}\".format( str(model_name)))\n",
    "    print (\"dataset: {}\".format(dataset))\n",
    "    print('    Total params: %.2fM' % (sum(p.numel() for p in model.parameters()) / 1000000.0))    \n",
    "    \n",
    "    print (\"MODEL: {}\".format( str(type(model).__name__)))\n",
    "    \n",
    "    start_training_time = time.time()\n",
    "    training_time=time.time()\n",
    "    for epoch in tqdm(range(0, epochs)):        \n",
    "        train_result, accuracy_tr=train(t_loader, model, epoch, optimizer)\n",
    "        val_loss, val_accuracy= validate(v_loader, model, epoch)  \n",
    "        \n",
    "        recorder.update(epoch, train_result, accuracy_tr, val_loss, val_accuracy) \n",
    "        training_time=time.time() - start_training_time\n",
    "        recorder.plot_curve(os.path.join(mPath, model_name + '_' + exp_name + '.png'),training_time, model, model_name,\n",
    "                            str(dataset_sizes),\n",
    "                        batch_size, lr,dataset,manualSeed,len(classes))\n",
    "        \n",
    "        if float(val_accuracy) > float(98.0):            \n",
    "            print (\"EARLY STOP\")            \n",
    "            df_pred=testModel(test_data_dir,model)\n",
    "            df_pred.to_csv(str(type(model).__name__) + '_' + str(val_accuracy) + '_' + \n",
    "                           str(epoch) + \"_sub.csv\", columns=('file', 'species'), index=None)\n",
    "            torch.save(model.state_dict(), os.path.join(mPath, model_name + '_' + runId + '_' + str(val_accuracy) + '_.pth'))                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "9mH8koj_zpTc"
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), os.path.join(mPath, model_name + '_' + runId + '_' + str(val_accuracy) + 'FINAL_.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CZbOD_cEzpTg"
   },
   "source": [
    "In this step, participants will be asked to provide the following classification rates:\n",
    "\n",
    "-- TP (True Positive, which is the number of OP people correctly identified),\n",
    "\n",
    "-- FP (False Positive, which is the number of CT people incorrectly identified),\n",
    "\n",
    "-- TN (True Negative, which is the number of CT people correctly identified),\n",
    "\n",
    "-- FN (False Negative, which is the number of OP people incorrectly identified),\n",
    "\n",
    "-- Sn (True positive rate or sensitivity) as Sn = TP/(TP + FN),\n",
    "\n",
    "-- Sp (Specificity or True Negative Rate) as Sp = TN/(FP + TN)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xJl5xk-izpTh"
   },
   "source": [
    "## Confusion matrix code, from the scikit documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "zSJhsAEAzpTi"
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "# Performance monitoring\n",
    "from time import process_time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib nbagg\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    #print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "def confusion_diagnostic(model) :\n",
    "    \"Displays a synthetic matrix, which represents our classifier performances.\"\n",
    "    y_test    = [] ; y_pred    = [] ; \n",
    "    for data, target in v_loader: # We won't load the testing dataset all at once:\n",
    "        # Load the data on the GPU if needed, and wrap it into an autodiff object ----\n",
    "        if use_cuda: data, target = data.cuda(), target.cuda()\n",
    "        data, target = Variable(data, volatile=True), Variable(target)\n",
    "        # Evaluation of our model on the test mini-batch -----------------------------\n",
    "        output     = model(data) # Forward pass through the model\n",
    "        pred       = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "        y_test.append(target.data.cpu().numpy()) ; y_pred.append(pred.view(-1).cpu().numpy())\n",
    "    y_test = np.hstack(y_test) ; y_pred = np.hstack(y_pred)\n",
    "    \n",
    "    # Display --------------------------------------------------------------------   \n",
    "    cnf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    fig = plt.figure(dpi=150)\n",
    "    plot_confusion_matrix(cnf_matrix, classes=classes,\n",
    "                      title='Confusion matrix')\n",
    "    fig.canvas.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "uKXfEI9KzpTp"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "default_view": {},
   "name": "generic-SeNet-SeedLings.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
