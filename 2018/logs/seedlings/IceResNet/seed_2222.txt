save path : ./logs/
{'batch_size': 8, 'data_path': 'd:/db/data/seedlings/train/', 'dataset': 'seedlings', 'decay': 0.0005, 'epochs': 250, 'evaluate': False, 'gammas': [0.1, 0.1], 'imgDim': 3, 'img_scale': 224, 'learning_rate': 0.002, 'manualSeed': 2222, 'momentum': 0.9, 'ngpu': 1, 'num_classes': 12, 'print_freq': 200, 'resume': '', 'save_path': './logs/', 'save_path_model': './logs//seedlings/IceResNet/', 'schedule': [150, 225], 'start_epoch': 0, 'tensorboard': True, 'test_data_path': 'd:/db/data/seedlings/test/', 'use_cuda': True, 'validationRatio': 0.85, 'workers': 0}

==>>[2018-03-22 20:03:51] [Epoch=000/250] [Need: 00:00:00] [learning_rate=0.0020] [Best : Accuracy=0.00, Error=100.00]

==>>Epoch=[000/250]], [2018-03-22 20:03:51], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [000][000/505]   Time 4.446 (4.446)   Data 0.082 (0.082)   Loss 2.7825 (2.7825)   Prec@1 0.000 (0.000)   Prec@5 0.000 (0.000)   [2018-03-22 20:03:56]
  Epoch: [000][200/505]   Time 0.465 (0.512)   Data 0.068 (0.087)   Loss 2.1795 (2.1668)   Prec@1 12.500 (26.555)   Prec@5 12.500 (26.555)   [2018-03-22 20:05:34]
  Epoch: [000][400/505]   Time 0.468 (0.498)   Data 0.071 (0.087)   Loss 1.5566 (2.0684)   Prec@1 37.500 (29.395)   Prec@5 37.500 (29.395)   [2018-03-22 20:07:11]
  **Train** Prec@1 30.882 Prec@5 30.882 Error@1 69.118
  **VAL** Prec@1 44.663 Prec@5 44.663 Error@1 55.337

==>>[2018-03-22 20:08:25] [Epoch=001/250] [Need: 18:51:28] [learning_rate=0.0020] [Best : Accuracy=44.66, Error=55.34]

==>>Epoch=[001/250]], [2018-03-22 20:08:25], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [001][000/505]   Time 0.582 (0.582)   Data 0.064 (0.064)   Loss 1.4854 (1.4854)   Prec@1 62.500 (62.500)   Prec@5 62.500 (62.500)   [2018-03-22 20:08:26]
  Epoch: [001][200/505]   Time 0.448 (0.486)   Data 0.052 (0.087)   Loss 1.9055 (1.7965)   Prec@1 25.000 (40.174)   Prec@5 25.000 (40.174)   [2018-03-22 20:10:03]
  Epoch: [001][400/505]   Time 0.464 (0.486)   Data 0.066 (0.088)   Loss 1.8208 (1.7867)   Prec@1 25.000 (39.900)   Prec@5 25.000 (39.900)   [2018-03-22 20:11:40]
  **Train** Prec@1 39.896 Prec@5 39.896 Error@1 60.104
  **VAL** Prec@1 26.124 Prec@5 26.124 Error@1 73.876

==>>[2018-03-22 20:12:50] [Epoch=002/250] [Need: 18:31:47] [learning_rate=0.0020] [Best : Accuracy=44.66, Error=55.34]

==>>Epoch=[002/250]], [2018-03-22 20:12:50], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [002][000/505]   Time 0.562 (0.562)   Data 0.141 (0.141)   Loss 1.5984 (1.5984)   Prec@1 37.500 (37.500)   Prec@5 37.500 (37.500)   [2018-03-22 20:12:51]
  Epoch: [002][200/505]   Time 0.514 (0.487)   Data 0.118 (0.089)   Loss 1.4611 (1.6685)   Prec@1 50.000 (42.164)   Prec@5 50.000 (42.164)   [2018-03-22 20:14:28]
  Epoch: [002][400/505]   Time 0.451 (0.485)   Data 0.055 (0.087)   Loss 0.9602 (1.6972)   Prec@1 75.000 (40.929)   Prec@5 75.000 (40.929)   [2018-03-22 20:16:05]
  **Train** Prec@1 41.357 Prec@5 41.357 Error@1 58.643
  **VAL** Prec@1 60.534 Prec@5 60.534 Error@1 39.466

==>>[2018-03-22 20:17:16] [Epoch=003/250] [Need: 18:22:01] [learning_rate=0.0020] [Best : Accuracy=60.53, Error=39.47]

==>>Epoch=[003/250]], [2018-03-22 20:17:16], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [003][000/505]   Time 0.493 (0.493)   Data 0.076 (0.076)   Loss 2.1323 (2.1323)   Prec@1 12.500 (12.500)   Prec@5 12.500 (12.500)   [2018-03-22 20:17:16]
  Epoch: [003][200/505]   Time 0.465 (0.489)   Data 0.069 (0.091)   Loss 1.2904 (1.6155)   Prec@1 37.500 (46.331)   Prec@5 37.500 (46.331)   [2018-03-22 20:18:54]
  Epoch: [003][400/505]   Time 0.471 (0.484)   Data 0.074 (0.087)   Loss 1.7660 (1.6020)   Prec@1 50.000 (45.885)   Prec@5 50.000 (45.885)   [2018-03-22 20:20:30]
  **Train** Prec@1 46.186 Prec@5 46.186 Error@1 53.814
  **VAL** Prec@1 56.461 Prec@5 56.461 Error@1 43.539

==>>[2018-03-22 20:21:41] [Epoch=004/250] [Need: 18:15:07] [learning_rate=0.0020] [Best : Accuracy=60.53, Error=39.47]

==>>Epoch=[004/250]], [2018-03-22 20:21:41], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [004][000/505]   Time 0.455 (0.455)   Data 0.044 (0.044)   Loss 1.3864 (1.3864)   Prec@1 50.000 (50.000)   Prec@5 50.000 (50.000)   [2018-03-22 20:21:41]
  Epoch: [004][200/505]   Time 0.501 (0.482)   Data 0.105 (0.084)   Loss 1.3246 (1.5727)   Prec@1 50.000 (47.015)   Prec@5 50.000 (47.015)   [2018-03-22 20:23:18]
  Epoch: [004][400/505]   Time 0.449 (0.481)   Data 0.052 (0.083)   Loss 1.8344 (1.5341)   Prec@1 37.500 (48.660)   Prec@5 37.500 (48.660)   [2018-03-22 20:24:54]
  **Train** Prec@1 49.059 Prec@5 49.059 Error@1 50.941
  **VAL** Prec@1 67.135 Prec@5 67.135 Error@1 32.865

==>>[2018-03-22 20:26:06] [Epoch=005/250] [Need: 18:08:59] [learning_rate=0.0020] [Best : Accuracy=67.13, Error=32.87]

==>>Epoch=[005/250]], [2018-03-22 20:26:06], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [005][000/505]   Time 0.494 (0.494)   Data 0.076 (0.076)   Loss 1.2698 (1.2698)   Prec@1 50.000 (50.000)   Prec@5 50.000 (50.000)   [2018-03-22 20:26:06]
  Epoch: [005][200/505]   Time 0.650 (0.488)   Data 0.247 (0.090)   Loss 0.8041 (1.4489)   Prec@1 75.000 (50.995)   Prec@5 75.000 (50.995)   [2018-03-22 20:27:44]
  Epoch: [005][400/505]   Time 0.471 (0.483)   Data 0.076 (0.085)   Loss 1.3594 (1.4523)   Prec@1 50.000 (51.403)   Prec@5 50.000 (51.403)   [2018-03-22 20:29:19]
  **Train** Prec@1 50.941 Prec@5 50.941 Error@1 49.059
  **VAL** Prec@1 36.657 Prec@5 36.657 Error@1 63.343

==>>[2018-03-22 20:30:31] [Epoch=006/250] [Need: 18:03:27] [learning_rate=0.0020] [Best : Accuracy=67.13, Error=32.87]

==>>Epoch=[006/250]], [2018-03-22 20:30:31], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [006][000/505]   Time 0.484 (0.484)   Data 0.063 (0.063)   Loss 0.9577 (0.9577)   Prec@1 75.000 (75.000)   Prec@5 75.000 (75.000)   [2018-03-22 20:30:31]
  Epoch: [006][200/505]   Time 0.473 (0.478)   Data 0.077 (0.081)   Loss 0.6823 (1.4129)   Prec@1 75.000 (52.425)   Prec@5 75.000 (52.425)   [2018-03-22 20:32:07]
  Epoch: [006][400/505]   Time 0.538 (0.482)   Data 0.142 (0.085)   Loss 1.2980 (1.4095)   Prec@1 50.000 (52.681)   Prec@5 50.000 (52.681)   [2018-03-22 20:33:44]
  **Train** Prec@1 52.476 Prec@5 52.476 Error@1 47.524
  **VAL** Prec@1 64.747 Prec@5 64.747 Error@1 35.253

==>>[2018-03-22 20:34:56] [Epoch=007/250] [Need: 17:58:13] [learning_rate=0.0020] [Best : Accuracy=67.13, Error=32.87]

==>>Epoch=[007/250]], [2018-03-22 20:34:56], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [007][000/505]   Time 0.481 (0.481)   Data 0.060 (0.060)   Loss 0.8223 (0.8223)   Prec@1 75.000 (75.000)   Prec@5 75.000 (75.000)   [2018-03-22 20:34:57]
  Epoch: [007][200/505]   Time 0.454 (0.482)   Data 0.059 (0.084)   Loss 1.8186 (1.3352)   Prec@1 50.000 (53.794)   Prec@5 50.000 (53.794)   [2018-03-22 20:36:33]
  Epoch: [007][400/505]   Time 0.456 (0.481)   Data 0.060 (0.084)   Loss 1.3287 (1.3855)   Prec@1 62.500 (52.899)   Prec@5 62.500 (52.899)   [2018-03-22 20:38:09]
  **Train** Prec@1 53.640 Prec@5 53.640 Error@1 46.360
  **VAL** Prec@1 69.663 Prec@5 69.663 Error@1 30.337

==>>[2018-03-22 20:39:21] [Epoch=008/250] [Need: 17:53:06] [learning_rate=0.0020] [Best : Accuracy=69.66, Error=30.34]

==>>Epoch=[008/250]], [2018-03-22 20:39:21], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [008][000/505]   Time 0.493 (0.493)   Data 0.074 (0.074)   Loss 1.0916 (1.0916)   Prec@1 50.000 (50.000)   Prec@5 50.000 (50.000)   [2018-03-22 20:39:21]
  Epoch: [008][200/505]   Time 0.533 (0.480)   Data 0.136 (0.082)   Loss 1.3825 (1.3071)   Prec@1 37.500 (55.535)   Prec@5 37.500 (55.535)   [2018-03-22 20:40:57]
  Epoch: [008][400/505]   Time 0.439 (0.483)   Data 0.042 (0.086)   Loss 1.9611 (1.3402)   Prec@1 50.000 (54.645)   Prec@5 50.000 (54.645)   [2018-03-22 20:42:35]
  **Train** Prec@1 55.052 Prec@5 55.052 Error@1 44.948
  **VAL** Prec@1 64.607 Prec@5 64.607 Error@1 35.393

==>>[2018-03-22 20:43:46] [Epoch=009/250] [Need: 17:48:11] [learning_rate=0.0020] [Best : Accuracy=69.66, Error=30.34]

==>>Epoch=[009/250]], [2018-03-22 20:43:46], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [009][000/505]   Time 0.488 (0.488)   Data 0.072 (0.072)   Loss 1.3052 (1.3052)   Prec@1 50.000 (50.000)   Prec@5 50.000 (50.000)   [2018-03-22 20:43:46]
  Epoch: [009][200/505]   Time 0.436 (0.487)   Data 0.044 (0.089)   Loss 0.9020 (1.2730)   Prec@1 75.000 (57.090)   Prec@5 75.000 (57.090)   [2018-03-22 20:45:24]
  Epoch: [009][400/505]   Time 0.520 (0.484)   Data 0.101 (0.086)   Loss 1.4024 (1.2896)   Prec@1 50.000 (56.297)   Prec@5 50.000 (56.297)   [2018-03-22 20:47:00]
  **Train** Prec@1 56.241 Prec@5 56.241 Error@1 43.759
  **VAL** Prec@1 60.815 Prec@5 60.815 Error@1 39.185

==>>[2018-03-22 20:48:11] [Epoch=010/250] [Need: 17:43:20] [learning_rate=0.0020] [Best : Accuracy=69.66, Error=30.34]

==>>Epoch=[010/250]], [2018-03-22 20:48:11], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [010][000/505]   Time 0.446 (0.446)   Data 0.039 (0.039)   Loss 1.1917 (1.1917)   Prec@1 62.500 (62.500)   Prec@5 62.500 (62.500)   [2018-03-22 20:48:11]
  Epoch: [010][200/505]   Time 0.450 (0.485)   Data 0.053 (0.088)   Loss 1.4492 (1.2409)   Prec@1 37.500 (59.017)   Prec@5 37.500 (59.017)   [2018-03-22 20:49:48]
  Epoch: [010][400/505]   Time 0.446 (0.483)   Data 0.051 (0.086)   Loss 1.5619 (1.2317)   Prec@1 50.000 (59.383)   Prec@5 50.000 (59.383)   [2018-03-22 20:51:25]
  **Train** Prec@1 59.113 Prec@5 59.113 Error@1 40.887
  **VAL** Prec@1 72.612 Prec@5 72.612 Error@1 27.388

==>>[2018-03-22 20:52:36] [Epoch=011/250] [Need: 17:38:33] [learning_rate=0.0020] [Best : Accuracy=72.61, Error=27.39]

==>>Epoch=[011/250]], [2018-03-22 20:52:36], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [011][000/505]   Time 0.498 (0.498)   Data 0.079 (0.079)   Loss 1.2403 (1.2403)   Prec@1 50.000 (50.000)   Prec@5 50.000 (50.000)   [2018-03-22 20:52:36]
  Epoch: [011][200/505]   Time 0.479 (0.478)   Data 0.085 (0.080)   Loss 1.0881 (1.2361)   Prec@1 50.000 (58.333)   Prec@5 50.000 (58.333)   [2018-03-22 20:54:12]
  Epoch: [011][400/505]   Time 0.458 (0.482)   Data 0.061 (0.085)   Loss 0.7190 (1.2099)   Prec@1 87.500 (59.258)   Prec@5 87.500 (59.258)   [2018-03-22 20:55:49]
  **Train** Prec@1 59.757 Prec@5 59.757 Error@1 40.243
  **VAL** Prec@1 70.506 Prec@5 70.506 Error@1 29.494

==>>[2018-03-22 20:57:01] [Epoch=012/250] [Need: 17:33:51] [learning_rate=0.0020] [Best : Accuracy=72.61, Error=27.39]

==>>Epoch=[012/250]], [2018-03-22 20:57:01], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [012][000/505]   Time 0.484 (0.484)   Data 0.068 (0.068)   Loss 1.4351 (1.4351)   Prec@1 37.500 (37.500)   Prec@5 37.500 (37.500)   [2018-03-22 20:57:01]
  Epoch: [012][200/505]   Time 0.459 (0.484)   Data 0.061 (0.086)   Loss 0.9880 (1.2006)   Prec@1 75.000 (59.017)   Prec@5 75.000 (59.017)   [2018-03-22 20:58:38]
  Epoch: [012][400/505]   Time 0.481 (0.483)   Data 0.085 (0.086)   Loss 1.2887 (1.1646)   Prec@1 62.500 (60.069)   Prec@5 62.500 (60.069)   [2018-03-22 21:00:14]
  **Train** Prec@1 60.352 Prec@5 60.352 Error@1 39.648
  **VAL** Prec@1 71.348 Prec@5 71.348 Error@1 28.652

==>>[2018-03-22 21:01:26] [Epoch=013/250] [Need: 17:29:12] [learning_rate=0.0020] [Best : Accuracy=72.61, Error=27.39]

==>>Epoch=[013/250]], [2018-03-22 21:01:26], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [013][000/505]   Time 0.602 (0.602)   Data 0.166 (0.166)   Loss 0.2682 (0.2682)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-03-22 21:01:26]
  Epoch: [013][200/505]   Time 0.441 (0.485)   Data 0.046 (0.087)   Loss 0.5981 (1.1022)   Prec@1 100.000 (62.500)   Prec@5 100.000 (62.500)   [2018-03-22 21:03:03]
  Epoch: [013][400/505]   Time 0.453 (0.483)   Data 0.060 (0.086)   Loss 1.2483 (1.1316)   Prec@1 75.000 (61.783)   Prec@5 75.000 (61.783)   [2018-03-22 21:04:39]
  **Train** Prec@1 61.912 Prec@5 61.912 Error@1 38.088
  **VAL** Prec@1 74.860 Prec@5 74.860 Error@1 25.140

==>>[2018-03-22 21:05:51] [Epoch=014/250] [Need: 17:24:35] [learning_rate=0.0020] [Best : Accuracy=74.86, Error=25.14]

==>>Epoch=[014/250]], [2018-03-22 21:05:51], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [014][000/505]   Time 0.572 (0.572)   Data 0.156 (0.156)   Loss 1.6701 (1.6701)   Prec@1 37.500 (37.500)   Prec@5 37.500 (37.500)   [2018-03-22 21:05:51]
  Epoch: [014][200/505]   Time 0.471 (0.484)   Data 0.077 (0.087)   Loss 1.7356 (1.0583)   Prec@1 62.500 (65.112)   Prec@5 62.500 (65.112)   [2018-03-22 21:07:28]
  Epoch: [014][400/505]   Time 0.468 (0.483)   Data 0.071 (0.086)   Loss 0.8903 (1.0926)   Prec@1 50.000 (63.529)   Prec@5 50.000 (63.529)   [2018-03-22 21:09:04]
  **Train** Prec@1 63.373 Prec@5 63.373 Error@1 36.627
  **VAL** Prec@1 76.826 Prec@5 76.826 Error@1 23.174

==>>[2018-03-22 21:10:15] [Epoch=015/250] [Need: 17:19:58] [learning_rate=0.0020] [Best : Accuracy=76.83, Error=23.17]

==>>Epoch=[015/250]], [2018-03-22 21:10:15], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [015][000/505]   Time 0.556 (0.556)   Data 0.125 (0.125)   Loss 1.1449 (1.1449)   Prec@1 50.000 (50.000)   Prec@5 50.000 (50.000)   [2018-03-22 21:10:16]
  Epoch: [015][200/505]   Time 0.513 (0.486)   Data 0.116 (0.088)   Loss 0.7805 (1.1145)   Prec@1 62.500 (61.940)   Prec@5 62.500 (61.940)   [2018-03-22 21:11:53]
  Epoch: [015][400/505]   Time 0.487 (0.482)   Data 0.094 (0.085)   Loss 1.2818 (1.0904)   Prec@1 50.000 (63.030)   Prec@5 50.000 (63.030)   [2018-03-22 21:13:28]
  **Train** Prec@1 63.076 Prec@5 63.076 Error@1 36.924
  **VAL** Prec@1 82.584 Prec@5 82.584 Error@1 17.416

==>>[2018-03-22 21:14:40] [Epoch=016/250] [Need: 17:15:25] [learning_rate=0.0020] [Best : Accuracy=82.58, Error=17.42]

==>>Epoch=[016/250]], [2018-03-22 21:14:40], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [016][000/505]   Time 0.520 (0.520)   Data 0.083 (0.083)   Loss 0.9723 (0.9723)   Prec@1 62.500 (62.500)   Prec@5 62.500 (62.500)   [2018-03-22 21:14:41]
  Epoch: [016][200/505]   Time 0.453 (0.483)   Data 0.058 (0.085)   Loss 0.6987 (1.0805)   Prec@1 75.000 (63.993)   Prec@5 75.000 (63.993)   [2018-03-22 21:16:17]
  Epoch: [016][400/505]   Time 0.491 (0.483)   Data 0.095 (0.087)   Loss 1.2477 (1.0309)   Prec@1 50.000 (65.742)   Prec@5 50.000 (65.742)   [2018-03-22 21:17:54]
  **Train** Prec@1 65.577 Prec@5 65.577 Error@1 34.423
  **VAL** Prec@1 63.764 Prec@5 63.764 Error@1 36.236

==>>[2018-03-22 21:19:05] [Epoch=017/250] [Need: 17:10:51] [learning_rate=0.0020] [Best : Accuracy=82.58, Error=17.42]

==>>Epoch=[017/250]], [2018-03-22 21:19:05], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [017][000/505]   Time 0.546 (0.546)   Data 0.124 (0.124)   Loss 1.2670 (1.2670)   Prec@1 50.000 (50.000)   Prec@5 50.000 (50.000)   [2018-03-22 21:19:06]
  Epoch: [017][200/505]   Time 0.544 (0.484)   Data 0.146 (0.087)   Loss 0.7327 (1.0023)   Prec@1 75.000 (66.978)   Prec@5 75.000 (66.978)   [2018-03-22 21:20:42]
  Epoch: [017][400/505]   Time 0.443 (0.483)   Data 0.048 (0.087)   Loss 0.8953 (1.0175)   Prec@1 62.500 (65.991)   Prec@5 62.500 (65.991)   [2018-03-22 21:22:19]
  **Train** Prec@1 66.295 Prec@5 66.295 Error@1 33.705
  **VAL** Prec@1 83.006 Prec@5 83.006 Error@1 16.994

==>>[2018-03-22 21:23:30] [Epoch=018/250] [Need: 17:06:16] [learning_rate=0.0020] [Best : Accuracy=83.01, Error=16.99]

==>>Epoch=[018/250]], [2018-03-22 21:23:30], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [018][000/505]   Time 0.492 (0.492)   Data 0.060 (0.060)   Loss 0.6703 (0.6703)   Prec@1 75.000 (75.000)   Prec@5 75.000 (75.000)   [2018-03-22 21:23:30]
  Epoch: [018][200/505]   Time 0.478 (0.480)   Data 0.083 (0.083)   Loss 0.8592 (0.9474)   Prec@1 62.500 (68.595)   Prec@5 62.500 (68.595)   [2018-03-22 21:25:06]
  Epoch: [018][400/505]   Time 0.470 (0.481)   Data 0.075 (0.084)   Loss 0.3858 (0.9515)   Prec@1 100.000 (68.454)   Prec@5 100.000 (68.454)   [2018-03-22 21:26:43]
  **Train** Prec@1 68.400 Prec@5 68.400 Error@1 31.600
  **VAL** Prec@1 83.006 Prec@5 83.006 Error@1 16.994

==>>[2018-03-22 21:27:55] [Epoch=019/250] [Need: 17:01:42] [learning_rate=0.0020] [Best : Accuracy=83.01, Error=16.99]

==>>Epoch=[019/250]], [2018-03-22 21:27:55], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [019][000/505]   Time 0.514 (0.514)   Data 0.084 (0.084)   Loss 0.7356 (0.7356)   Prec@1 75.000 (75.000)   Prec@5 75.000 (75.000)   [2018-03-22 21:27:55]
  Epoch: [019][200/505]   Time 0.480 (0.480)   Data 0.087 (0.083)   Loss 0.8701 (0.9645)   Prec@1 62.500 (67.600)   Prec@5 62.500 (67.600)   [2018-03-22 21:29:31]
  Epoch: [019][400/505]   Time 0.567 (0.487)   Data 0.170 (0.085)   Loss 1.4209 (0.9682)   Prec@1 37.500 (68.236)   Prec@5 37.500 (68.236)   [2018-03-22 21:31:10]
  **Train** Prec@1 68.351 Prec@5 68.351 Error@1 31.649
  **VAL** Prec@1 82.444 Prec@5 82.444 Error@1 17.556

==>>[2018-03-22 21:32:22] [Epoch=020/250] [Need: 16:57:44] [learning_rate=0.0020] [Best : Accuracy=83.01, Error=16.99]

==>>Epoch=[020/250]], [2018-03-22 21:32:22], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [020][000/505]   Time 0.549 (0.549)   Data 0.112 (0.112)   Loss 1.5442 (1.5442)   Prec@1 37.500 (37.500)   Prec@5 37.500 (37.500)   [2018-03-22 21:32:23]
  Epoch: [020][200/505]   Time 0.476 (0.486)   Data 0.053 (0.081)   Loss 1.6402 (0.9343)   Prec@1 50.000 (68.532)   Prec@5 50.000 (68.532)   [2018-03-22 21:34:00]
  Epoch: [020][400/505]   Time 0.468 (0.489)   Data 0.068 (0.084)   Loss 0.6811 (0.9297)   Prec@1 75.000 (69.108)   Prec@5 75.000 (69.108)   [2018-03-22 21:35:39]
  **Train** Prec@1 69.242 Prec@5 69.242 Error@1 30.758
  **VAL** Prec@1 83.567 Prec@5 83.567 Error@1 16.433

==>>[2018-03-22 21:36:51] [Epoch=021/250] [Need: 16:53:54] [learning_rate=0.0020] [Best : Accuracy=83.57, Error=16.43]

==>>Epoch=[021/250]], [2018-03-22 21:36:51], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [021][000/505]   Time 0.523 (0.523)   Data 0.081 (0.081)   Loss 0.4458 (0.4458)   Prec@1 87.500 (87.500)   Prec@5 87.500 (87.500)   [2018-03-22 21:36:52]
  Epoch: [021][200/505]   Time 0.461 (0.489)   Data 0.063 (0.083)   Loss 0.2988 (0.9033)   Prec@1 100.000 (70.336)   Prec@5 100.000 (70.336)   [2018-03-22 21:38:29]
  Epoch: [021][400/505]   Time 0.493 (0.489)   Data 0.070 (0.085)   Loss 0.4058 (0.9037)   Prec@1 87.500 (70.262)   Prec@5 87.500 (70.262)   [2018-03-22 21:40:08]
  **Train** Prec@1 70.480 Prec@5 70.480 Error@1 29.520
  **VAL** Prec@1 85.393 Prec@5 85.393 Error@1 14.607

==>>[2018-03-22 21:41:20] [Epoch=022/250] [Need: 16:50:04] [learning_rate=0.0020] [Best : Accuracy=85.39, Error=14.61]

==>>Epoch=[022/250]], [2018-03-22 21:41:20], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [022][000/505]   Time 0.459 (0.459)   Data 0.041 (0.041)   Loss 0.5816 (0.5816)   Prec@1 87.500 (87.500)   Prec@5 87.500 (87.500)   [2018-03-22 21:41:21]
  Epoch: [022][200/505]   Time 0.465 (0.492)   Data 0.069 (0.088)   Loss 1.1394 (0.9027)   Prec@1 75.000 (70.149)   Prec@5 75.000 (70.149)   [2018-03-22 21:42:59]
  Epoch: [022][400/505]   Time 0.476 (0.491)   Data 0.065 (0.087)   Loss 0.5712 (0.8921)   Prec@1 87.500 (70.200)   Prec@5 87.500 (70.200)   [2018-03-22 21:44:37]
  **Train** Prec@1 70.258 Prec@5 70.258 Error@1 29.742
  **VAL** Prec@1 84.691 Prec@5 84.691 Error@1 15.309

==>>[2018-03-22 21:45:49] [Epoch=023/250] [Need: 16:46:09] [learning_rate=0.0020] [Best : Accuracy=85.39, Error=14.61]

==>>Epoch=[023/250]], [2018-03-22 21:45:49], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [023][000/505]   Time 0.500 (0.500)   Data 0.060 (0.060)   Loss 1.1603 (1.1603)   Prec@1 62.500 (62.500)   Prec@5 62.500 (62.500)   [2018-03-22 21:45:50]
  Epoch: [023][200/505]   Time 0.471 (0.487)   Data 0.071 (0.082)   Loss 0.9340 (0.8701)   Prec@1 75.000 (70.149)   Prec@5 75.000 (70.149)   [2018-03-22 21:47:27]
  Epoch: [023][400/505]   Time 0.542 (0.489)   Data 0.128 (0.084)   Loss 0.6060 (0.8759)   Prec@1 87.500 (70.293)   Prec@5 87.500 (70.293)   [2018-03-22 21:49:05]
  **Train** Prec@1 70.258 Prec@5 70.258 Error@1 29.742
  **VAL** Prec@1 85.674 Prec@5 85.674 Error@1 14.326

==>>[2018-03-22 21:50:18] [Epoch=024/250] [Need: 16:42:13] [learning_rate=0.0020] [Best : Accuracy=85.67, Error=14.33]

==>>Epoch=[024/250]], [2018-03-22 21:50:18], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [024][000/505]   Time 0.569 (0.569)   Data 0.144 (0.144)   Loss 0.8597 (0.8597)   Prec@1 75.000 (75.000)   Prec@5 75.000 (75.000)   [2018-03-22 21:50:19]
  Epoch: [024][200/505]   Time 0.492 (0.494)   Data 0.091 (0.089)   Loss 0.9025 (0.8293)   Prec@1 62.500 (72.512)   Prec@5 62.500 (72.512)   [2018-03-22 21:51:58]
  Epoch: [024][400/505]   Time 0.483 (0.490)   Data 0.068 (0.086)   Loss 0.9217 (0.8360)   Prec@1 75.000 (71.727)   Prec@5 75.000 (71.727)   [2018-03-22 21:53:35]
  **Train** Prec@1 71.842 Prec@5 71.842 Error@1 28.158
  **VAL** Prec@1 83.848 Prec@5 83.848 Error@1 16.152

==>>[2018-03-22 21:54:47] [Epoch=025/250] [Need: 16:38:11] [learning_rate=0.0020] [Best : Accuracy=85.67, Error=14.33]

==>>Epoch=[025/250]], [2018-03-22 21:54:47], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [025][000/505]   Time 0.463 (0.463)   Data 0.048 (0.048)   Loss 1.0840 (1.0840)   Prec@1 50.000 (50.000)   Prec@5 50.000 (50.000)   [2018-03-22 21:54:48]
  Epoch: [025][200/505]   Time 0.468 (0.488)   Data 0.065 (0.084)   Loss 1.2839 (0.8506)   Prec@1 50.000 (71.455)   Prec@5 50.000 (71.455)   [2018-03-22 21:56:25]
  Epoch: [025][400/505]   Time 0.498 (0.488)   Data 0.094 (0.085)   Loss 0.4400 (0.8287)   Prec@1 100.000 (71.415)   Prec@5 100.000 (71.415)   [2018-03-22 21:58:03]
  **Train** Prec@1 71.545 Prec@5 71.545 Error@1 28.455
  **VAL** Prec@1 75.843 Prec@5 75.843 Error@1 24.157

==>>[2018-03-22 21:59:16] [Epoch=026/250] [Need: 16:34:09] [learning_rate=0.0020] [Best : Accuracy=85.67, Error=14.33]

==>>Epoch=[026/250]], [2018-03-22 21:59:16], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [026][000/505]   Time 0.556 (0.556)   Data 0.140 (0.140)   Loss 0.7894 (0.7894)   Prec@1 75.000 (75.000)   Prec@5 75.000 (75.000)   [2018-03-22 21:59:17]
  Epoch: [026][200/505]   Time 0.467 (0.491)   Data 0.050 (0.087)   Loss 0.7810 (0.8148)   Prec@1 62.500 (73.259)   Prec@5 62.500 (73.259)   [2018-03-22 22:00:55]
  Epoch: [026][400/505]   Time 0.459 (0.491)   Data 0.059 (0.087)   Loss 0.6337 (0.8361)   Prec@1 62.500 (72.007)   Prec@5 62.500 (72.007)   [2018-03-22 22:02:33]
  **Train** Prec@1 72.610 Prec@5 72.610 Error@1 27.390
  **VAL** Prec@1 88.062 Prec@5 88.062 Error@1 11.938

==>>[2018-03-22 22:03:45] [Epoch=027/250] [Need: 16:30:03] [learning_rate=0.0020] [Best : Accuracy=88.06, Error=11.94]

==>>Epoch=[027/250]], [2018-03-22 22:03:45], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [027][000/505]   Time 0.488 (0.488)   Data 0.061 (0.061)   Loss 1.2894 (1.2894)   Prec@1 62.500 (62.500)   Prec@5 62.500 (62.500)   [2018-03-22 22:03:45]
  Epoch: [027][200/505]   Time 0.494 (0.496)   Data 0.097 (0.091)   Loss 0.5256 (0.8045)   Prec@1 75.000 (74.316)   Prec@5 75.000 (74.316)   [2018-03-22 22:05:24]
  Epoch: [027][400/505]   Time 0.454 (0.492)   Data 0.053 (0.087)   Loss 0.5212 (0.8086)   Prec@1 100.000 (73.535)   Prec@5 100.000 (73.535)   [2018-03-22 22:07:02]
  **Train** Prec@1 73.873 Prec@5 73.873 Error@1 26.127
  **VAL** Prec@1 86.657 Prec@5 86.657 Error@1 13.343

==>>[2018-03-22 22:08:14] [Epoch=028/250] [Need: 16:25:59] [learning_rate=0.0020] [Best : Accuracy=88.06, Error=11.94]

==>>Epoch=[028/250]], [2018-03-22 22:08:14], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [028][000/505]   Time 0.463 (0.463)   Data 0.046 (0.046)   Loss 1.7150 (1.7150)   Prec@1 87.500 (87.500)   Prec@5 87.500 (87.500)   [2018-03-22 22:08:14]
  Epoch: [028][200/505]   Time 0.463 (0.488)   Data 0.068 (0.084)   Loss 0.8220 (0.7990)   Prec@1 87.500 (73.010)   Prec@5 87.500 (73.010)   [2018-03-22 22:09:52]
  Epoch: [028][400/505]   Time 0.449 (0.490)   Data 0.053 (0.087)   Loss 1.0587 (0.7646)   Prec@1 62.500 (74.813)   Prec@5 62.500 (74.813)   [2018-03-22 22:11:31]
  **Train** Prec@1 74.938 Prec@5 74.938 Error@1 25.062
  **VAL** Prec@1 84.270 Prec@5 84.270 Error@1 15.730

==>>[2018-03-22 22:12:42] [Epoch=029/250] [Need: 16:21:48] [learning_rate=0.0020] [Best : Accuracy=88.06, Error=11.94]

==>>Epoch=[029/250]], [2018-03-22 22:12:42], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [029][000/505]   Time 0.472 (0.472)   Data 0.048 (0.048)   Loss 1.3553 (1.3553)   Prec@1 50.000 (50.000)   Prec@5 50.000 (50.000)   [2018-03-22 22:12:43]
  Epoch: [029][200/505]   Time 0.554 (0.488)   Data 0.152 (0.084)   Loss 0.7476 (0.8071)   Prec@1 75.000 (72.388)   Prec@5 75.000 (72.388)   [2018-03-22 22:14:21]
  Epoch: [029][400/505]   Time 0.451 (0.490)   Data 0.050 (0.086)   Loss 0.7251 (0.7980)   Prec@1 75.000 (72.382)   Prec@5 75.000 (72.382)   [2018-03-22 22:15:59]
  **Train** Prec@1 72.536 Prec@5 72.536 Error@1 27.464
  **VAL** Prec@1 90.871 Prec@5 90.871 Error@1 9.129

==>>[2018-03-22 22:17:11] [Epoch=030/250] [Need: 16:17:34] [learning_rate=0.0020] [Best : Accuracy=90.87, Error=9.13]

==>>Epoch=[030/250]], [2018-03-22 22:17:11], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [030][000/505]   Time 0.488 (0.488)   Data 0.063 (0.063)   Loss 0.6185 (0.6185)   Prec@1 87.500 (87.500)   Prec@5 87.500 (87.500)   [2018-03-22 22:17:11]
  Epoch: [030][200/505]   Time 0.440 (0.487)   Data 0.042 (0.083)   Loss 1.6451 (0.7702)   Prec@1 25.000 (74.876)   Prec@5 25.000 (74.876)   [2018-03-22 22:18:49]
  Epoch: [030][400/505]   Time 0.465 (0.490)   Data 0.069 (0.086)   Loss 0.9969 (0.7762)   Prec@1 62.500 (73.784)   Prec@5 62.500 (73.784)   [2018-03-22 22:20:27]
  **Train** Prec@1 74.096 Prec@5 74.096 Error@1 25.904
  **VAL** Prec@1 87.079 Prec@5 87.079 Error@1 12.921

==>>[2018-03-22 22:21:40] [Epoch=031/250] [Need: 16:13:24] [learning_rate=0.0020] [Best : Accuracy=90.87, Error=9.13]

==>>Epoch=[031/250]], [2018-03-22 22:21:40], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [031][000/505]   Time 0.526 (0.526)   Data 0.070 (0.070)   Loss 0.8222 (0.8222)   Prec@1 62.500 (62.500)   Prec@5 62.500 (62.500)   [2018-03-22 22:21:40]
  Epoch: [031][200/505]   Time 0.472 (0.489)   Data 0.070 (0.084)   Loss 0.3876 (0.7782)   Prec@1 87.500 (72.823)   Prec@5 87.500 (72.823)   [2018-03-22 22:23:18]
  Epoch: [031][400/505]   Time 0.559 (0.490)   Data 0.148 (0.085)   Loss 0.3208 (0.7719)   Prec@1 100.000 (73.597)   Prec@5 100.000 (73.597)   [2018-03-22 22:24:56]
  **Train** Prec@1 73.650 Prec@5 73.650 Error@1 26.350
  **VAL** Prec@1 85.253 Prec@5 85.253 Error@1 14.747

==>>[2018-03-22 22:26:09] [Epoch=032/250] [Need: 16:09:12] [learning_rate=0.0020] [Best : Accuracy=90.87, Error=9.13]

==>>Epoch=[032/250]], [2018-03-22 22:26:09], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [032][000/505]   Time 0.599 (0.599)   Data 0.161 (0.161)   Loss 0.3041 (0.3041)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-03-22 22:26:09]
  Epoch: [032][200/505]   Time 0.458 (0.489)   Data 0.055 (0.085)   Loss 0.5112 (0.7652)   Prec@1 87.500 (75.435)   Prec@5 87.500 (75.435)   [2018-03-22 22:27:47]
  Epoch: [032][400/505]   Time 0.439 (0.490)   Data 0.041 (0.087)   Loss 1.1555 (0.7599)   Prec@1 62.500 (75.000)   Prec@5 62.500 (75.000)   [2018-03-22 22:29:25]
  **Train** Prec@1 75.012 Prec@5 75.012 Error@1 24.988
  **VAL** Prec@1 89.045 Prec@5 89.045 Error@1 10.955

==>>[2018-03-22 22:30:37] [Epoch=033/250] [Need: 16:04:58] [learning_rate=0.0020] [Best : Accuracy=90.87, Error=9.13]

==>>Epoch=[033/250]], [2018-03-22 22:30:37], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [033][000/505]   Time 0.527 (0.527)   Data 0.095 (0.095)   Loss 0.4343 (0.4343)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-03-22 22:30:38]
  Epoch: [033][200/505]   Time 0.556 (0.488)   Data 0.144 (0.084)   Loss 0.6761 (0.6732)   Prec@1 62.500 (77.363)   Prec@5 62.500 (77.363)   [2018-03-22 22:32:15]
  Epoch: [033][400/505]   Time 0.508 (0.489)   Data 0.112 (0.085)   Loss 0.6267 (0.7128)   Prec@1 75.000 (75.655)   Prec@5 75.000 (75.655)   [2018-03-22 22:33:53]
  **Train** Prec@1 75.780 Prec@5 75.780 Error@1 24.220
  **VAL** Prec@1 86.798 Prec@5 86.798 Error@1 13.202

==>>[2018-03-22 22:35:06] [Epoch=034/250] [Need: 16:00:44] [learning_rate=0.0020] [Best : Accuracy=90.87, Error=9.13]

==>>Epoch=[034/250]], [2018-03-22 22:35:06], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [034][000/505]   Time 0.460 (0.460)   Data 0.047 (0.047)   Loss 0.4666 (0.4666)   Prec@1 75.000 (75.000)   Prec@5 75.000 (75.000)   [2018-03-22 22:35:07]
  Epoch: [034][200/505]   Time 0.474 (0.490)   Data 0.057 (0.085)   Loss 0.6898 (0.7703)   Prec@1 75.000 (75.062)   Prec@5 75.000 (75.062)   [2018-03-22 22:36:45]
  Epoch: [034][400/505]   Time 0.454 (0.490)   Data 0.059 (0.085)   Loss 0.9649 (0.7489)   Prec@1 87.500 (75.156)   Prec@5 87.500 (75.156)   [2018-03-22 22:38:23]
  **Train** Prec@1 74.913 Prec@5 74.913 Error@1 25.087
  **VAL** Prec@1 92.135 Prec@5 92.135 Error@1 7.865

==>>[2018-03-22 22:39:34] [Epoch=035/250] [Need: 15:56:26] [learning_rate=0.0020] [Best : Accuracy=92.13, Error=7.87]

==>>Epoch=[035/250]], [2018-03-22 22:39:34], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [035][000/505]   Time 0.455 (0.455)   Data 0.051 (0.051)   Loss 1.4272 (1.4272)   Prec@1 75.000 (75.000)   Prec@5 75.000 (75.000)   [2018-03-22 22:39:35]
  Epoch: [035][200/505]   Time 0.472 (0.479)   Data 0.077 (0.082)   Loss 0.7501 (0.7175)   Prec@1 62.500 (75.871)   Prec@5 62.500 (75.871)   [2018-03-22 22:41:11]
  Epoch: [035][400/505]   Time 0.503 (0.483)   Data 0.111 (0.086)   Loss 0.5300 (0.7026)   Prec@1 87.500 (76.559)   Prec@5 87.500 (76.559)   [2018-03-22 22:42:48]
  **Train** Prec@1 76.523 Prec@5 76.523 Error@1 23.477
  **VAL** Prec@1 88.202 Prec@5 88.202 Error@1 11.798

==>>[2018-03-22 22:43:59] [Epoch=036/250] [Need: 15:51:45] [learning_rate=0.0020] [Best : Accuracy=92.13, Error=7.87]

==>>Epoch=[036/250]], [2018-03-22 22:43:59], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [036][000/505]   Time 0.453 (0.453)   Data 0.048 (0.048)   Loss 0.4895 (0.4895)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-03-22 22:43:59]
  Epoch: [036][200/505]   Time 0.440 (0.484)   Data 0.046 (0.087)   Loss 0.4113 (0.7389)   Prec@1 87.500 (76.057)   Prec@5 87.500 (76.057)   [2018-03-22 22:45:36]
  Epoch: [036][400/505]   Time 0.488 (0.485)   Data 0.091 (0.088)   Loss 0.4946 (0.7118)   Prec@1 62.500 (77.057)   Prec@5 62.500 (77.057)   [2018-03-22 22:47:13]
  **Train** Prec@1 77.291 Prec@5 77.291 Error@1 22.709
  **VAL** Prec@1 91.573 Prec@5 91.573 Error@1 8.427

==>>[2018-03-22 22:48:24] [Epoch=037/250] [Need: 15:47:06] [learning_rate=0.0020] [Best : Accuracy=92.13, Error=7.87]

==>>Epoch=[037/250]], [2018-03-22 22:48:24], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [037][000/505]   Time 0.485 (0.485)   Data 0.072 (0.072)   Loss 1.9514 (1.9514)   Prec@1 50.000 (50.000)   Prec@5 50.000 (50.000)   [2018-03-22 22:48:24]
  Epoch: [037][200/505]   Time 0.542 (0.485)   Data 0.146 (0.088)   Loss 0.6670 (0.6906)   Prec@1 87.500 (76.866)   Prec@5 87.500 (76.866)   [2018-03-22 22:50:01]
  Epoch: [037][400/505]   Time 0.492 (0.483)   Data 0.098 (0.086)   Loss 0.3360 (0.7023)   Prec@1 100.000 (76.683)   Prec@5 100.000 (76.683)   [2018-03-22 22:51:37]
  **Train** Prec@1 76.746 Prec@5 76.746 Error@1 23.254
  **VAL** Prec@1 88.062 Prec@5 88.062 Error@1 11.938

==>>[2018-03-22 22:52:48] [Epoch=038/250] [Need: 15:42:27] [learning_rate=0.0020] [Best : Accuracy=92.13, Error=7.87]

==>>Epoch=[038/250]], [2018-03-22 22:52:48], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [038][000/505]   Time 0.486 (0.486)   Data 0.071 (0.071)   Loss 0.6010 (0.6010)   Prec@1 75.000 (75.000)   Prec@5 75.000 (75.000)   [2018-03-22 22:52:49]
  Epoch: [038][200/505]   Time 0.482 (0.484)   Data 0.089 (0.088)   Loss 0.9328 (0.7211)   Prec@1 62.500 (74.813)   Prec@5 62.500 (74.813)   [2018-03-22 22:54:26]
  Epoch: [038][400/505]   Time 0.480 (0.483)   Data 0.084 (0.087)   Loss 0.8965 (0.6904)   Prec@1 62.500 (76.247)   Prec@5 62.500 (76.247)   [2018-03-22 22:56:02]
  **Train** Prec@1 76.201 Prec@5 76.201 Error@1 23.799
  **VAL** Prec@1 90.169 Prec@5 90.169 Error@1 9.831

==>>[2018-03-22 22:57:12] [Epoch=039/250] [Need: 15:37:47] [learning_rate=0.0020] [Best : Accuracy=92.13, Error=7.87]

==>>Epoch=[039/250]], [2018-03-22 22:57:12], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [039][000/505]   Time 0.454 (0.454)   Data 0.051 (0.051)   Loss 0.8536 (0.8536)   Prec@1 50.000 (50.000)   Prec@5 50.000 (50.000)   [2018-03-22 22:57:13]
  Epoch: [039][200/505]   Time 0.431 (0.481)   Data 0.035 (0.086)   Loss 0.6689 (0.7039)   Prec@1 75.000 (76.430)   Prec@5 75.000 (76.430)   [2018-03-22 22:58:49]
  Epoch: [039][400/505]   Time 0.469 (0.481)   Data 0.075 (0.086)   Loss 2.2384 (0.6920)   Prec@1 75.000 (76.995)   Prec@5 75.000 (76.995)   [2018-03-22 23:00:26]
  **Train** Prec@1 77.068 Prec@5 77.068 Error@1 22.932
  **VAL** Prec@1 88.904 Prec@5 88.904 Error@1 11.096

==>>[2018-03-22 23:01:36] [Epoch=040/250] [Need: 15:33:06] [learning_rate=0.0020] [Best : Accuracy=92.13, Error=7.87]

==>>Epoch=[040/250]], [2018-03-22 23:01:36], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [040][000/505]   Time 0.487 (0.487)   Data 0.086 (0.086)   Loss 0.3497 (0.3497)   Prec@1 75.000 (75.000)   Prec@5 75.000 (75.000)   [2018-03-22 23:01:37]
  Epoch: [040][200/505]   Time 0.514 (0.482)   Data 0.122 (0.086)   Loss 0.7306 (0.6584)   Prec@1 75.000 (77.239)   Prec@5 75.000 (77.239)   [2018-03-22 23:03:13]
  Epoch: [040][400/505]   Time 0.438 (0.482)   Data 0.043 (0.087)   Loss 1.1387 (0.6505)   Prec@1 75.000 (77.805)   Prec@5 75.000 (77.805)   [2018-03-22 23:04:50]
  **Train** Prec@1 77.291 Prec@5 77.291 Error@1 22.709
  **VAL** Prec@1 86.236 Prec@5 86.236 Error@1 13.764

==>>[2018-03-22 23:06:00] [Epoch=041/250] [Need: 15:28:25] [learning_rate=0.0020] [Best : Accuracy=92.13, Error=7.87]

==>>Epoch=[041/250]], [2018-03-22 23:06:00], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [041][000/505]   Time 0.438 (0.438)   Data 0.037 (0.037)   Loss 0.8491 (0.8491)   Prec@1 62.500 (62.500)   Prec@5 62.500 (62.500)   [2018-03-22 23:06:01]
  Epoch: [041][200/505]   Time 0.469 (0.478)   Data 0.073 (0.082)   Loss 0.4788 (0.6678)   Prec@1 75.000 (77.488)   Prec@5 75.000 (77.488)   [2018-03-22 23:07:36]
  Epoch: [041][400/505]   Time 0.467 (0.480)   Data 0.072 (0.084)   Loss 0.2392 (0.6448)   Prec@1 87.500 (78.148)   Prec@5 87.500 (78.148)   [2018-03-22 23:09:13]
  **Train** Prec@1 77.935 Prec@5 77.935 Error@1 22.065
  **VAL** Prec@1 88.624 Prec@5 88.624 Error@1 11.376

==>>[2018-03-22 23:10:25] [Epoch=042/250] [Need: 15:23:47] [learning_rate=0.0020] [Best : Accuracy=92.13, Error=7.87]

==>>Epoch=[042/250]], [2018-03-22 23:10:25], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [042][000/505]   Time 0.529 (0.529)   Data 0.126 (0.126)   Loss 0.4339 (0.4339)   Prec@1 87.500 (87.500)   Prec@5 87.500 (87.500)   [2018-03-22 23:10:25]
  Epoch: [042][200/505]   Time 0.497 (0.481)   Data 0.105 (0.085)   Loss 0.7617 (0.6643)   Prec@1 87.500 (77.736)   Prec@5 87.500 (77.736)   [2018-03-22 23:12:01]
  Epoch: [042][400/505]   Time 0.483 (0.481)   Data 0.089 (0.086)   Loss 0.9665 (0.6536)   Prec@1 62.500 (77.930)   Prec@5 62.500 (77.930)   [2018-03-22 23:13:38]
  **Train** Prec@1 77.885 Prec@5 77.885 Error@1 22.115
  **VAL** Prec@1 91.713 Prec@5 91.713 Error@1 8.287

==>>[2018-03-22 23:14:49] [Epoch=043/250] [Need: 15:19:09] [learning_rate=0.0020] [Best : Accuracy=92.13, Error=7.87]

==>>Epoch=[043/250]], [2018-03-22 23:14:49], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [043][000/505]   Time 0.435 (0.435)   Data 0.035 (0.035)   Loss 0.7740 (0.7740)   Prec@1 62.500 (62.500)   Prec@5 62.500 (62.500)   [2018-03-22 23:14:49]
  Epoch: [043][200/505]   Time 0.468 (0.479)   Data 0.074 (0.083)   Loss 0.7079 (0.6882)   Prec@1 62.500 (77.177)   Prec@5 62.500 (77.177)   [2018-03-22 23:16:25]
  Epoch: [043][400/505]   Time 0.476 (0.480)   Data 0.082 (0.085)   Loss 0.6330 (0.6843)   Prec@1 75.000 (77.026)   Prec@5 75.000 (77.026)   [2018-03-22 23:18:01]
  **Train** Prec@1 77.365 Prec@5 77.365 Error@1 22.635
  **VAL** Prec@1 91.573 Prec@5 91.573 Error@1 8.427

==>>[2018-03-22 23:19:13] [Epoch=044/250] [Need: 15:14:32] [learning_rate=0.0020] [Best : Accuracy=92.13, Error=7.87]

==>>Epoch=[044/250]], [2018-03-22 23:19:13], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [044][000/505]   Time 0.475 (0.475)   Data 0.074 (0.074)   Loss 0.2851 (0.2851)   Prec@1 87.500 (87.500)   Prec@5 87.500 (87.500)   [2018-03-22 23:19:13]
  Epoch: [044][200/505]   Time 0.483 (0.479)   Data 0.090 (0.083)   Loss 0.3163 (0.6167)   Prec@1 100.000 (78.856)   Prec@5 100.000 (78.856)   [2018-03-22 23:20:49]
  Epoch: [044][400/505]   Time 0.452 (0.480)   Data 0.059 (0.085)   Loss 1.3883 (0.6386)   Prec@1 62.500 (78.180)   Prec@5 62.500 (78.180)   [2018-03-22 23:22:25]
  **Train** Prec@1 78.529 Prec@5 78.529 Error@1 21.471
  **VAL** Prec@1 89.045 Prec@5 89.045 Error@1 10.955

==>>[2018-03-22 23:23:37] [Epoch=045/250] [Need: 15:09:54] [learning_rate=0.0020] [Best : Accuracy=92.13, Error=7.87]

==>>Epoch=[045/250]], [2018-03-22 23:23:37], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [045][000/505]   Time 0.459 (0.459)   Data 0.058 (0.058)   Loss 0.7920 (0.7920)   Prec@1 75.000 (75.000)   Prec@5 75.000 (75.000)   [2018-03-22 23:23:37]
  Epoch: [045][200/505]   Time 0.459 (0.480)   Data 0.063 (0.084)   Loss 0.6236 (0.6566)   Prec@1 62.500 (78.296)   Prec@5 62.500 (78.296)   [2018-03-22 23:25:13]
  Epoch: [045][400/505]   Time 0.595 (0.480)   Data 0.191 (0.085)   Loss 0.3202 (0.6546)   Prec@1 87.500 (78.335)   Prec@5 87.500 (78.335)   [2018-03-22 23:26:49]
  **Train** Prec@1 79.000 Prec@5 79.000 Error@1 21.000
  **VAL** Prec@1 92.978 Prec@5 92.978 Error@1 7.022

==>>[2018-03-22 23:28:01] [Epoch=046/250] [Need: 15:05:17] [learning_rate=0.0020] [Best : Accuracy=92.98, Error=7.02]

==>>Epoch=[046/250]], [2018-03-22 23:28:01], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [046][000/505]   Time 0.489 (0.489)   Data 0.088 (0.088)   Loss 0.4410 (0.4410)   Prec@1 87.500 (87.500)   Prec@5 87.500 (87.500)   [2018-03-22 23:28:01]
  Epoch: [046][200/505]   Time 0.468 (0.478)   Data 0.071 (0.083)   Loss 0.5978 (0.6325)   Prec@1 75.000 (79.104)   Prec@5 75.000 (79.104)   [2018-03-22 23:29:37]
  Epoch: [046][400/505]   Time 0.440 (0.479)   Data 0.045 (0.083)   Loss 0.7761 (0.6311)   Prec@1 75.000 (78.865)   Prec@5 75.000 (78.865)   [2018-03-22 23:31:12]
  **Train** Prec@1 78.876 Prec@5 78.876 Error@1 21.124
  **VAL** Prec@1 90.730 Prec@5 90.730 Error@1 9.270

==>>[2018-03-22 23:32:25] [Epoch=047/250] [Need: 15:00:41] [learning_rate=0.0020] [Best : Accuracy=92.98, Error=7.02]

==>>Epoch=[047/250]], [2018-03-22 23:32:25], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [047][000/505]   Time 0.518 (0.518)   Data 0.120 (0.120)   Loss 0.1215 (0.1215)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-03-22 23:32:25]
  Epoch: [047][200/505]   Time 0.452 (0.479)   Data 0.055 (0.084)   Loss 0.1031 (0.6064)   Prec@1 100.000 (79.664)   Prec@5 100.000 (79.664)   [2018-03-22 23:34:01]
  Epoch: [047][400/505]   Time 0.465 (0.480)   Data 0.073 (0.085)   Loss 1.0901 (0.6209)   Prec@1 62.500 (79.115)   Prec@5 62.500 (79.115)   [2018-03-22 23:35:37]
  **Train** Prec@1 79.520 Prec@5 79.520 Error@1 20.480
  **VAL** Prec@1 91.292 Prec@5 91.292 Error@1 8.708

==>>[2018-03-22 23:36:49] [Epoch=048/250] [Need: 14:56:06] [learning_rate=0.0020] [Best : Accuracy=92.98, Error=7.02]

==>>Epoch=[048/250]], [2018-03-22 23:36:49], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [048][000/505]   Time 0.527 (0.527)   Data 0.124 (0.124)   Loss 0.2205 (0.2205)   Prec@1 87.500 (87.500)   Prec@5 87.500 (87.500)   [2018-03-22 23:36:49]
  Epoch: [048][200/505]   Time 0.547 (0.484)   Data 0.151 (0.088)   Loss 0.6026 (0.6005)   Prec@1 75.000 (79.229)   Prec@5 75.000 (79.229)   [2018-03-22 23:38:26]
  Epoch: [048][400/505]   Time 0.438 (0.481)   Data 0.047 (0.085)   Loss 0.6194 (0.5977)   Prec@1 62.500 (79.364)   Prec@5 62.500 (79.364)   [2018-03-22 23:40:01]
  **Train** Prec@1 79.198 Prec@5 79.198 Error@1 20.802
  **VAL** Prec@1 92.697 Prec@5 92.697 Error@1 7.303

==>>[2018-03-22 23:41:13] [Epoch=049/250] [Need: 14:51:30] [learning_rate=0.0020] [Best : Accuracy=92.98, Error=7.02]

==>>Epoch=[049/250]], [2018-03-22 23:41:13], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [049][000/505]   Time 0.571 (0.571)   Data 0.173 (0.173)   Loss 0.3045 (0.3045)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-03-22 23:41:13]
  Epoch: [049][200/505]   Time 0.461 (0.479)   Data 0.068 (0.084)   Loss 0.8148 (0.6329)   Prec@1 62.500 (77.799)   Prec@5 62.500 (77.799)   [2018-03-22 23:42:49]
  Epoch: [049][400/505]   Time 0.449 (0.482)   Data 0.055 (0.086)   Loss 0.2802 (0.6373)   Prec@1 100.000 (78.460)   Prec@5 100.000 (78.460)   [2018-03-22 23:44:26]
  **Train** Prec@1 78.603 Prec@5 78.603 Error@1 21.397
  **VAL** Prec@1 88.624 Prec@5 88.624 Error@1 11.376

==>>[2018-03-22 23:45:36] [Epoch=050/250] [Need: 14:46:56] [learning_rate=0.0020] [Best : Accuracy=92.98, Error=7.02]

==>>Epoch=[050/250]], [2018-03-22 23:45:36], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [050][000/505]   Time 0.460 (0.460)   Data 0.056 (0.056)   Loss 1.0483 (1.0483)   Prec@1 75.000 (75.000)   Prec@5 75.000 (75.000)   [2018-03-22 23:45:37]
  Epoch: [050][200/505]   Time 0.452 (0.479)   Data 0.056 (0.084)   Loss 0.3905 (0.5692)   Prec@1 87.500 (80.846)   Prec@5 87.500 (80.846)   [2018-03-22 23:47:13]
  Epoch: [050][400/505]   Time 0.627 (0.482)   Data 0.223 (0.086)   Loss 0.4311 (0.5748)   Prec@1 75.000 (80.892)   Prec@5 75.000 (80.892)   [2018-03-22 23:48:50]
  **Train** Prec@1 80.238 Prec@5 80.238 Error@1 19.762
  **VAL** Prec@1 91.573 Prec@5 91.573 Error@1 8.427

==>>[2018-03-22 23:50:00] [Epoch=051/250] [Need: 14:42:21] [learning_rate=0.0020] [Best : Accuracy=92.98, Error=7.02]

==>>Epoch=[051/250]], [2018-03-22 23:50:00], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [051][000/505]   Time 0.496 (0.496)   Data 0.089 (0.089)   Loss 0.3225 (0.3225)   Prec@1 87.500 (87.500)   Prec@5 87.500 (87.500)   [2018-03-22 23:50:01]
  Epoch: [051][200/505]   Time 0.466 (0.481)   Data 0.074 (0.086)   Loss 0.6376 (0.6157)   Prec@1 75.000 (78.856)   Prec@5 75.000 (78.856)   [2018-03-22 23:51:37]
  Epoch: [051][400/505]   Time 0.450 (0.482)   Data 0.057 (0.087)   Loss 0.4797 (0.6358)   Prec@1 62.500 (78.429)   Prec@5 62.500 (78.429)   [2018-03-22 23:53:14]
  **Train** Prec@1 78.603 Prec@5 78.603 Error@1 21.397
  **VAL** Prec@1 89.747 Prec@5 89.747 Error@1 10.253

==>>[2018-03-22 23:54:24] [Epoch=052/250] [Need: 14:37:47] [learning_rate=0.0020] [Best : Accuracy=92.98, Error=7.02]

==>>Epoch=[052/250]], [2018-03-22 23:54:24], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [052][000/505]   Time 0.477 (0.477)   Data 0.072 (0.072)   Loss 0.4825 (0.4825)   Prec@1 87.500 (87.500)   Prec@5 87.500 (87.500)   [2018-03-22 23:54:25]
  Epoch: [052][200/505]   Time 0.611 (0.481)   Data 0.209 (0.086)   Loss 0.2690 (0.5864)   Prec@1 87.500 (79.913)   Prec@5 87.500 (79.913)   [2018-03-22 23:56:01]
  Epoch: [052][400/505]   Time 0.448 (0.481)   Data 0.053 (0.086)   Loss 0.2904 (0.6035)   Prec@1 87.500 (79.239)   Prec@5 87.500 (79.239)   [2018-03-22 23:57:37]
  **Train** Prec@1 79.396 Prec@5 79.396 Error@1 20.604
  **VAL** Prec@1 92.275 Prec@5 92.275 Error@1 7.725

==>>[2018-03-22 23:58:48] [Epoch=053/250] [Need: 14:33:13] [learning_rate=0.0020] [Best : Accuracy=92.98, Error=7.02]

==>>Epoch=[053/250]], [2018-03-22 23:58:48], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [053][000/505]   Time 0.512 (0.512)   Data 0.111 (0.111)   Loss 0.5038 (0.5038)   Prec@1 87.500 (87.500)   Prec@5 87.500 (87.500)   [2018-03-22 23:58:49]
  Epoch: [053][200/505]   Time 0.463 (0.484)   Data 0.069 (0.089)   Loss 0.2397 (0.5720)   Prec@1 100.000 (80.659)   Prec@5 100.000 (80.659)   [2018-03-23 00:00:26]
  Epoch: [053][400/505]   Time 0.440 (0.481)   Data 0.048 (0.086)   Loss 0.3216 (0.5796)   Prec@1 87.500 (81.079)   Prec@5 87.500 (81.079)   [2018-03-23 00:02:01]
  **Train** Prec@1 80.386 Prec@5 80.386 Error@1 19.614
  **VAL** Prec@1 88.904 Prec@5 88.904 Error@1 11.096

==>>[2018-03-23 00:03:12] [Epoch=054/250] [Need: 14:28:40] [learning_rate=0.0020] [Best : Accuracy=92.98, Error=7.02]

==>>Epoch=[054/250]], [2018-03-23 00:03:12], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [054][000/505]   Time 0.558 (0.558)   Data 0.158 (0.158)   Loss 1.0306 (1.0306)   Prec@1 87.500 (87.500)   Prec@5 87.500 (87.500)   [2018-03-23 00:03:13]
  Epoch: [054][200/505]   Time 0.454 (0.481)   Data 0.061 (0.086)   Loss 1.2541 (0.6555)   Prec@1 50.000 (77.985)   Prec@5 50.000 (77.985)   [2018-03-23 00:04:49]
  Epoch: [054][400/505]   Time 0.464 (0.482)   Data 0.068 (0.087)   Loss 0.3320 (0.6048)   Prec@1 87.500 (79.551)   Prec@5 87.500 (79.551)   [2018-03-23 00:06:26]
  **Train** Prec@1 79.396 Prec@5 79.396 Error@1 20.604
  **VAL** Prec@1 91.994 Prec@5 91.994 Error@1 8.006

==>>[2018-03-23 00:07:36] [Epoch=055/250] [Need: 14:24:08] [learning_rate=0.0020] [Best : Accuracy=92.98, Error=7.02]

==>>Epoch=[055/250]], [2018-03-23 00:07:36], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [055][000/505]   Time 0.455 (0.455)   Data 0.051 (0.051)   Loss 0.1285 (0.1285)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-03-23 00:07:37]
  Epoch: [055][200/505]   Time 0.481 (0.477)   Data 0.086 (0.082)   Loss 0.7978 (0.6244)   Prec@1 75.000 (78.980)   Prec@5 75.000 (78.980)   [2018-03-23 00:09:12]
  Epoch: [055][400/505]   Time 0.483 (0.479)   Data 0.091 (0.084)   Loss 0.2098 (0.5903)   Prec@1 100.000 (80.330)   Prec@5 100.000 (80.330)   [2018-03-23 00:10:48]
  **Train** Prec@1 80.139 Prec@5 80.139 Error@1 19.861
  **VAL** Prec@1 92.837 Prec@5 92.837 Error@1 7.163

==>>[2018-03-23 00:12:00] [Epoch=056/250] [Need: 14:19:35] [learning_rate=0.0020] [Best : Accuracy=92.98, Error=7.02]

==>>Epoch=[056/250]], [2018-03-23 00:12:00], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [056][000/505]   Time 0.542 (0.542)   Data 0.139 (0.139)   Loss 0.9227 (0.9227)   Prec@1 50.000 (50.000)   Prec@5 50.000 (50.000)   [2018-03-23 00:12:01]
  Epoch: [056][200/505]   Time 0.440 (0.479)   Data 0.047 (0.084)   Loss 0.3750 (0.5979)   Prec@1 87.500 (80.597)   Prec@5 87.500 (80.597)   [2018-03-23 00:13:37]
  Epoch: [056][400/505]   Time 0.488 (0.480)   Data 0.096 (0.085)   Loss 1.2665 (0.5838)   Prec@1 62.500 (81.110)   Prec@5 62.500 (81.110)   [2018-03-23 00:15:13]
  **Train** Prec@1 80.684 Prec@5 80.684 Error@1 19.316
  **VAL** Prec@1 89.747 Prec@5 89.747 Error@1 10.253

==>>[2018-03-23 00:16:24] [Epoch=057/250] [Need: 14:15:02] [learning_rate=0.0020] [Best : Accuracy=92.98, Error=7.02]

==>>Epoch=[057/250]], [2018-03-23 00:16:24], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [057][000/505]   Time 0.504 (0.504)   Data 0.102 (0.102)   Loss 0.3370 (0.3370)   Prec@1 75.000 (75.000)   Prec@5 75.000 (75.000)   [2018-03-23 00:16:24]
  Epoch: [057][200/505]   Time 0.715 (0.485)   Data 0.312 (0.090)   Loss 0.8130 (0.6167)   Prec@1 75.000 (80.224)   Prec@5 75.000 (80.224)   [2018-03-23 00:18:01]
  Epoch: [057][400/505]   Time 0.467 (0.481)   Data 0.074 (0.086)   Loss 0.3740 (0.6153)   Prec@1 100.000 (79.988)   Prec@5 100.000 (79.988)   [2018-03-23 00:19:37]
  **Train** Prec@1 80.312 Prec@5 80.312 Error@1 19.688
  **VAL** Prec@1 92.416 Prec@5 92.416 Error@1 7.584

==>>[2018-03-23 00:20:48] [Epoch=058/250] [Need: 14:10:30] [learning_rate=0.0020] [Best : Accuracy=92.98, Error=7.02]

==>>Epoch=[058/250]], [2018-03-23 00:20:48], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [058][000/505]   Time 0.466 (0.466)   Data 0.058 (0.058)   Loss 0.3516 (0.3516)   Prec@1 75.000 (75.000)   Prec@5 75.000 (75.000)   [2018-03-23 00:20:48]
  Epoch: [058][200/505]   Time 0.442 (0.481)   Data 0.045 (0.086)   Loss 0.3577 (0.6082)   Prec@1 87.500 (79.229)   Prec@5 87.500 (79.229)   [2018-03-23 00:22:25]
  Epoch: [058][400/505]   Time 0.630 (0.482)   Data 0.235 (0.086)   Loss 0.7282 (0.6013)   Prec@1 50.000 (79.769)   Prec@5 50.000 (79.769)   [2018-03-23 00:24:01]
  **Train** Prec@1 79.916 Prec@5 79.916 Error@1 20.084
  **VAL** Prec@1 90.590 Prec@5 90.590 Error@1 9.410

==>>[2018-03-23 00:25:12] [Epoch=059/250] [Need: 14:05:58] [learning_rate=0.0020] [Best : Accuracy=92.98, Error=7.02]

==>>Epoch=[059/250]], [2018-03-23 00:25:12], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [059][000/505]   Time 0.511 (0.511)   Data 0.111 (0.111)   Loss 0.6320 (0.6320)   Prec@1 62.500 (62.500)   Prec@5 62.500 (62.500)   [2018-03-23 00:25:12]
  Epoch: [059][200/505]   Time 0.443 (0.481)   Data 0.047 (0.086)   Loss 0.1394 (0.5615)   Prec@1 100.000 (81.841)   Prec@5 100.000 (81.841)   [2018-03-23 00:26:49]
  Epoch: [059][400/505]   Time 0.457 (0.481)   Data 0.064 (0.085)   Loss 0.8023 (0.5813)   Prec@1 62.500 (81.079)   Prec@5 62.500 (81.079)   [2018-03-23 00:28:24]
  **Train** Prec@1 81.080 Prec@5 81.080 Error@1 18.920
  **VAL** Prec@1 93.820 Prec@5 93.820 Error@1 6.180

==>>[2018-03-23 00:29:36] [Epoch=060/250] [Need: 14:01:26] [learning_rate=0.0020] [Best : Accuracy=93.82, Error=6.18]

==>>Epoch=[060/250]], [2018-03-23 00:29:36], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [060][000/505]   Time 0.459 (0.459)   Data 0.052 (0.052)   Loss 0.7414 (0.7414)   Prec@1 75.000 (75.000)   Prec@5 75.000 (75.000)   [2018-03-23 00:29:36]
  Epoch: [060][200/505]   Time 0.442 (0.477)   Data 0.046 (0.082)   Loss 0.2759 (0.5994)   Prec@1 100.000 (80.162)   Prec@5 100.000 (80.162)   [2018-03-23 00:31:11]
  Epoch: [060][400/505]   Time 0.440 (0.481)   Data 0.045 (0.085)   Loss 0.1325 (0.5578)   Prec@1 100.000 (81.328)   Prec@5 100.000 (81.328)   [2018-03-23 00:32:48]
  **Train** Prec@1 81.451 Prec@5 81.451 Error@1 18.549
  **VAL** Prec@1 84.972 Prec@5 84.972 Error@1 15.028

==>>[2018-03-23 00:34:00] [Epoch=061/250] [Need: 13:56:55] [learning_rate=0.0020] [Best : Accuracy=93.82, Error=6.18]

==>>Epoch=[061/250]], [2018-03-23 00:34:00], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [061][000/505]   Time 0.558 (0.558)   Data 0.159 (0.159)   Loss 0.2799 (0.2799)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-03-23 00:34:00]
  Epoch: [061][200/505]   Time 0.452 (0.481)   Data 0.058 (0.087)   Loss 0.2995 (0.5935)   Prec@1 87.500 (80.659)   Prec@5 87.500 (80.659)   [2018-03-23 00:35:36]
  Epoch: [061][400/505]   Time 0.484 (0.479)   Data 0.087 (0.085)   Loss 0.2056 (0.5881)   Prec@1 100.000 (80.736)   Prec@5 100.000 (80.736)   [2018-03-23 00:37:12]
  **Train** Prec@1 80.609 Prec@5 80.609 Error@1 19.391
  **VAL** Prec@1 90.449 Prec@5 90.449 Error@1 9.551

==>>[2018-03-23 00:38:23] [Epoch=062/250] [Need: 13:52:22] [learning_rate=0.0020] [Best : Accuracy=93.82, Error=6.18]

==>>Epoch=[062/250]], [2018-03-23 00:38:23], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [062][000/505]   Time 0.476 (0.476)   Data 0.069 (0.069)   Loss 0.8285 (0.8285)   Prec@1 87.500 (87.500)   Prec@5 87.500 (87.500)   [2018-03-23 00:38:23]
  Epoch: [062][200/505]   Time 0.452 (0.479)   Data 0.059 (0.085)   Loss 0.5398 (0.5646)   Prec@1 87.500 (81.530)   Prec@5 87.500 (81.530)   [2018-03-23 00:39:59]
  Epoch: [062][400/505]   Time 0.471 (0.479)   Data 0.076 (0.084)   Loss 0.1615 (0.5759)   Prec@1 100.000 (81.297)   Prec@5 100.000 (81.297)   [2018-03-23 00:41:35]
  **Train** Prec@1 81.402 Prec@5 81.402 Error@1 18.598
  **VAL** Prec@1 90.730 Prec@5 90.730 Error@1 9.270

==>>[2018-03-23 00:42:46] [Epoch=063/250] [Need: 13:47:50] [learning_rate=0.0020] [Best : Accuracy=93.82, Error=6.18]

==>>Epoch=[063/250]], [2018-03-23 00:42:46], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [063][000/505]   Time 0.487 (0.487)   Data 0.080 (0.080)   Loss 0.4900 (0.4900)   Prec@1 75.000 (75.000)   Prec@5 75.000 (75.000)   [2018-03-23 00:42:47]
  Epoch: [063][200/505]   Time 0.496 (0.479)   Data 0.102 (0.085)   Loss 0.5493 (0.5668)   Prec@1 87.500 (80.659)   Prec@5 87.500 (80.659)   [2018-03-23 00:44:23]
  Epoch: [063][400/505]   Time 0.446 (0.480)   Data 0.053 (0.086)   Loss 0.1990 (0.5489)   Prec@1 87.500 (81.328)   Prec@5 87.500 (81.328)   [2018-03-23 00:45:59]
  **Train** Prec@1 80.510 Prec@5 80.510 Error@1 19.490
  **VAL** Prec@1 94.242 Prec@5 94.242 Error@1 5.758

==>>[2018-03-23 00:47:10] [Epoch=064/250] [Need: 13:43:18] [learning_rate=0.0020] [Best : Accuracy=94.24, Error=5.76]

==>>Epoch=[064/250]], [2018-03-23 00:47:10], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [064][000/505]   Time 0.497 (0.497)   Data 0.096 (0.096)   Loss 0.3118 (0.3118)   Prec@1 87.500 (87.500)   Prec@5 87.500 (87.500)   [2018-03-23 00:47:10]
  Epoch: [064][200/505]   Time 0.451 (0.481)   Data 0.051 (0.086)   Loss 0.1586 (0.5708)   Prec@1 100.000 (81.530)   Prec@5 100.000 (81.530)   [2018-03-23 00:48:47]
  Epoch: [064][400/505]   Time 0.471 (0.481)   Data 0.079 (0.087)   Loss 0.1985 (0.5693)   Prec@1 100.000 (81.359)   Prec@5 100.000 (81.359)   [2018-03-23 00:50:23]
  **Train** Prec@1 81.154 Prec@5 81.154 Error@1 18.846
  **VAL** Prec@1 94.663 Prec@5 94.663 Error@1 5.337

==>>[2018-03-23 00:51:33] [Epoch=065/250] [Need: 13:38:47] [learning_rate=0.0020] [Best : Accuracy=94.66, Error=5.34]

==>>Epoch=[065/250]], [2018-03-23 00:51:33], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [065][000/505]   Time 0.485 (0.485)   Data 0.081 (0.081)   Loss 0.2759 (0.2759)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-03-23 00:51:34]
  Epoch: [065][200/505]   Time 0.456 (0.480)   Data 0.065 (0.086)   Loss 0.9382 (0.5289)   Prec@1 75.000 (82.090)   Prec@5 75.000 (82.090)   [2018-03-23 00:53:10]
  Epoch: [065][400/505]   Time 0.502 (0.479)   Data 0.107 (0.085)   Loss 0.6759 (0.5433)   Prec@1 87.500 (81.421)   Prec@5 87.500 (81.421)   [2018-03-23 00:54:46]
  **Train** Prec@1 81.377 Prec@5 81.377 Error@1 18.623
  **VAL** Prec@1 93.399 Prec@5 93.399 Error@1 6.601

==>>[2018-03-23 00:55:57] [Epoch=066/250] [Need: 13:34:16] [learning_rate=0.0020] [Best : Accuracy=94.66, Error=5.34]

==>>Epoch=[066/250]], [2018-03-23 00:55:57], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [066][000/505]   Time 0.483 (0.483)   Data 0.082 (0.082)   Loss 0.2744 (0.2744)   Prec@1 87.500 (87.500)   Prec@5 87.500 (87.500)   [2018-03-23 00:55:57]
  Epoch: [066][200/505]   Time 0.434 (0.479)   Data 0.039 (0.084)   Loss 0.1265 (0.5284)   Prec@1 100.000 (82.774)   Prec@5 100.000 (82.774)   [2018-03-23 00:57:33]
  Epoch: [066][400/505]   Time 0.443 (0.479)   Data 0.050 (0.084)   Loss 0.4916 (0.5131)   Prec@1 87.500 (83.105)   Prec@5 87.500 (83.105)   [2018-03-23 00:59:09]
  **Train** Prec@1 82.640 Prec@5 82.640 Error@1 17.360
  **VAL** Prec@1 92.978 Prec@5 92.978 Error@1 7.022

==>>[2018-03-23 01:00:20] [Epoch=067/250] [Need: 13:29:44] [learning_rate=0.0020] [Best : Accuracy=94.66, Error=5.34]

==>>Epoch=[067/250]], [2018-03-23 01:00:20], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [067][000/505]   Time 0.438 (0.438)   Data 0.036 (0.036)   Loss 1.0618 (1.0618)   Prec@1 75.000 (75.000)   Prec@5 75.000 (75.000)   [2018-03-23 01:00:21]
  Epoch: [067][200/505]   Time 0.435 (0.478)   Data 0.039 (0.083)   Loss 0.5171 (0.5575)   Prec@1 87.500 (81.716)   Prec@5 87.500 (81.716)   [2018-03-23 01:01:56]
  Epoch: [067][400/505]   Time 0.504 (0.480)   Data 0.111 (0.085)   Loss 0.7284 (0.5265)   Prec@1 87.500 (82.824)   Prec@5 87.500 (82.824)   [2018-03-23 01:03:33]
  **Train** Prec@1 82.813 Prec@5 82.813 Error@1 17.187
  **VAL** Prec@1 91.854 Prec@5 91.854 Error@1 8.146

==>>[2018-03-23 01:04:44] [Epoch=068/250] [Need: 13:25:14] [learning_rate=0.0020] [Best : Accuracy=94.66, Error=5.34]

==>>Epoch=[068/250]], [2018-03-23 01:04:44], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [068][000/505]   Time 0.533 (0.533)   Data 0.133 (0.133)   Loss 0.2127 (0.2127)   Prec@1 87.500 (87.500)   Prec@5 87.500 (87.500)   [2018-03-23 01:04:44]
  Epoch: [068][200/505]   Time 0.448 (0.481)   Data 0.053 (0.086)   Loss 1.6179 (0.5202)   Prec@1 50.000 (82.214)   Prec@5 50.000 (82.214)   [2018-03-23 01:06:20]
  Epoch: [068][400/505]   Time 0.458 (0.480)   Data 0.055 (0.086)   Loss 1.0514 (0.5398)   Prec@1 75.000 (81.608)   Prec@5 75.000 (81.608)   [2018-03-23 01:07:57]
  **Train** Prec@1 81.476 Prec@5 81.476 Error@1 18.524
  **VAL** Prec@1 91.994 Prec@5 91.994 Error@1 8.006

==>>[2018-03-23 01:09:07] [Epoch=069/250] [Need: 13:20:43] [learning_rate=0.0020] [Best : Accuracy=94.66, Error=5.34]

==>>Epoch=[069/250]], [2018-03-23 01:09:07], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [069][000/505]   Time 0.459 (0.459)   Data 0.056 (0.056)   Loss 0.1581 (0.1581)   Prec@1 87.500 (87.500)   Prec@5 87.500 (87.500)   [2018-03-23 01:09:08]
  Epoch: [069][200/505]   Time 0.520 (0.481)   Data 0.124 (0.087)   Loss 0.5973 (0.5158)   Prec@1 75.000 (82.214)   Prec@5 75.000 (82.214)   [2018-03-23 01:10:44]
  Epoch: [069][400/505]   Time 0.473 (0.480)   Data 0.080 (0.086)   Loss 0.3460 (0.5118)   Prec@1 87.500 (82.201)   Prec@5 87.500 (82.201)   [2018-03-23 01:12:20]
  **Train** Prec@1 81.773 Prec@5 81.773 Error@1 18.227
  **VAL** Prec@1 91.292 Prec@5 91.292 Error@1 8.708

==>>[2018-03-23 01:13:31] [Epoch=070/250] [Need: 13:16:13] [learning_rate=0.0020] [Best : Accuracy=94.66, Error=5.34]

==>>Epoch=[070/250]], [2018-03-23 01:13:31], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [070][000/505]   Time 0.486 (0.486)   Data 0.081 (0.081)   Loss 1.1697 (1.1697)   Prec@1 50.000 (50.000)   Prec@5 50.000 (50.000)   [2018-03-23 01:13:31]
  Epoch: [070][200/505]   Time 0.474 (0.486)   Data 0.080 (0.091)   Loss 0.3283 (0.5109)   Prec@1 87.500 (82.960)   Prec@5 87.500 (82.960)   [2018-03-23 01:15:09]
  Epoch: [070][400/505]   Time 0.444 (0.481)   Data 0.049 (0.087)   Loss 0.2533 (0.5092)   Prec@1 100.000 (82.668)   Prec@5 100.000 (82.668)   [2018-03-23 01:16:44]
  **Train** Prec@1 82.615 Prec@5 82.615 Error@1 17.385
  **VAL** Prec@1 91.292 Prec@5 91.292 Error@1 8.708

==>>[2018-03-23 01:17:54] [Epoch=071/250] [Need: 13:11:42] [learning_rate=0.0020] [Best : Accuracy=94.66, Error=5.34]

==>>Epoch=[071/250]], [2018-03-23 01:17:54], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [071][000/505]   Time 0.497 (0.497)   Data 0.097 (0.097)   Loss 1.0737 (1.0737)   Prec@1 75.000 (75.000)   Prec@5 75.000 (75.000)   [2018-03-23 01:17:55]
  Epoch: [071][200/505]   Time 0.490 (0.482)   Data 0.094 (0.087)   Loss 0.5077 (0.5141)   Prec@1 87.500 (82.276)   Prec@5 87.500 (82.276)   [2018-03-23 01:19:31]
  Epoch: [071][400/505]   Time 0.486 (0.480)   Data 0.095 (0.086)   Loss 0.5461 (0.5251)   Prec@1 87.500 (81.951)   Prec@5 87.500 (81.951)   [2018-03-23 01:21:07]
  **Train** Prec@1 82.293 Prec@5 82.293 Error@1 17.707
  **VAL** Prec@1 91.292 Prec@5 91.292 Error@1 8.708

==>>[2018-03-23 01:22:18] [Epoch=072/250] [Need: 13:07:12] [learning_rate=0.0020] [Best : Accuracy=94.66, Error=5.34]

==>>Epoch=[072/250]], [2018-03-23 01:22:18], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [072][000/505]   Time 0.469 (0.469)   Data 0.067 (0.067)   Loss 0.6599 (0.6599)   Prec@1 75.000 (75.000)   Prec@5 75.000 (75.000)   [2018-03-23 01:22:18]
  Epoch: [072][200/505]   Time 0.443 (0.482)   Data 0.048 (0.087)   Loss 0.6456 (0.5356)   Prec@1 62.500 (81.468)   Prec@5 62.500 (81.468)   [2018-03-23 01:23:55]
  Epoch: [072][400/505]   Time 0.446 (0.479)   Data 0.050 (0.085)   Loss 0.2494 (0.5331)   Prec@1 87.500 (82.575)   Prec@5 87.500 (82.575)   [2018-03-23 01:25:30]
  **Train** Prec@1 82.046 Prec@5 82.046 Error@1 17.954
  **VAL** Prec@1 92.697 Prec@5 92.697 Error@1 7.303

==>>[2018-03-23 01:26:41] [Epoch=073/250] [Need: 13:02:42] [learning_rate=0.0020] [Best : Accuracy=94.66, Error=5.34]

==>>Epoch=[073/250]], [2018-03-23 01:26:41], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [073][000/505]   Time 0.460 (0.460)   Data 0.058 (0.058)   Loss 0.0896 (0.0896)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-03-23 01:26:42]
  Epoch: [073][200/505]   Time 0.453 (0.483)   Data 0.058 (0.088)   Loss 1.0966 (0.5478)   Prec@1 62.500 (82.090)   Prec@5 62.500 (82.090)   [2018-03-23 01:28:18]
  Epoch: [073][400/505]   Time 0.447 (0.479)   Data 0.053 (0.085)   Loss 0.8328 (0.5311)   Prec@1 87.500 (82.014)   Prec@5 87.500 (82.014)   [2018-03-23 01:29:53]
  **Train** Prec@1 82.665 Prec@5 82.665 Error@1 17.335
  **VAL** Prec@1 92.556 Prec@5 92.556 Error@1 7.444

==>>[2018-03-23 01:31:05] [Epoch=074/250] [Need: 12:58:13] [learning_rate=0.0020] [Best : Accuracy=94.66, Error=5.34]

==>>Epoch=[074/250]], [2018-03-23 01:31:05], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [074][000/505]   Time 0.496 (0.496)   Data 0.094 (0.094)   Loss 0.3974 (0.3974)   Prec@1 87.500 (87.500)   Prec@5 87.500 (87.500)   [2018-03-23 01:31:05]
  Epoch: [074][200/505]   Time 0.513 (0.482)   Data 0.118 (0.088)   Loss 0.1534 (0.4973)   Prec@1 100.000 (84.639)   Prec@5 100.000 (84.639)   [2018-03-23 01:32:42]
  Epoch: [074][400/505]   Time 0.496 (0.481)   Data 0.102 (0.086)   Loss 0.2399 (0.5131)   Prec@1 100.000 (84.009)   Prec@5 100.000 (84.009)   [2018-03-23 01:34:18]
  **Train** Prec@1 83.606 Prec@5 83.606 Error@1 16.394
  **VAL** Prec@1 90.871 Prec@5 90.871 Error@1 9.129

==>>[2018-03-23 01:35:28] [Epoch=075/250] [Need: 12:53:44] [learning_rate=0.0020] [Best : Accuracy=94.66, Error=5.34]

==>>Epoch=[075/250]], [2018-03-23 01:35:28], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [075][000/505]   Time 0.478 (0.478)   Data 0.078 (0.078)   Loss 0.3400 (0.3400)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-03-23 01:35:29]
  Epoch: [075][200/505]   Time 0.451 (0.480)   Data 0.059 (0.085)   Loss 0.1643 (0.5538)   Prec@1 100.000 (82.090)   Prec@5 100.000 (82.090)   [2018-03-23 01:37:05]
  Epoch: [075][400/505]   Time 0.483 (0.479)   Data 0.089 (0.084)   Loss 0.4993 (0.5227)   Prec@1 87.500 (82.668)   Prec@5 87.500 (82.668)   [2018-03-23 01:38:40]
  **Train** Prec@1 82.912 Prec@5 82.912 Error@1 17.088
  **VAL** Prec@1 94.101 Prec@5 94.101 Error@1 5.899

==>>[2018-03-23 01:39:52] [Epoch=076/250] [Need: 12:49:14] [learning_rate=0.0020] [Best : Accuracy=94.66, Error=5.34]

==>>Epoch=[076/250]], [2018-03-23 01:39:52], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [076][000/505]   Time 0.443 (0.443)   Data 0.041 (0.041)   Loss 0.1472 (0.1472)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-03-23 01:39:52]
  Epoch: [076][200/505]   Time 0.485 (0.472)   Data 0.089 (0.078)   Loss 0.4850 (0.4990)   Prec@1 87.500 (84.453)   Prec@5 87.500 (84.453)   [2018-03-23 01:41:27]
  Epoch: [076][400/505]   Time 0.439 (0.480)   Data 0.048 (0.086)   Loss 0.4659 (0.5114)   Prec@1 75.000 (82.918)   Prec@5 75.000 (82.918)   [2018-03-23 01:43:05]
  **Train** Prec@1 82.813 Prec@5 82.813 Error@1 17.187
  **VAL** Prec@1 86.517 Prec@5 86.517 Error@1 13.483

==>>[2018-03-23 01:44:16] [Epoch=077/250] [Need: 12:44:45] [learning_rate=0.0020] [Best : Accuracy=94.66, Error=5.34]

==>>Epoch=[077/250]], [2018-03-23 01:44:16], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [077][000/505]   Time 0.483 (0.483)   Data 0.081 (0.081)   Loss 0.4747 (0.4747)   Prec@1 87.500 (87.500)   Prec@5 87.500 (87.500)   [2018-03-23 01:44:16]
  Epoch: [077][200/505]   Time 0.557 (0.481)   Data 0.160 (0.087)   Loss 0.3019 (0.5127)   Prec@1 87.500 (83.458)   Prec@5 87.500 (83.458)   [2018-03-23 01:45:52]
  Epoch: [077][400/505]   Time 0.437 (0.480)   Data 0.044 (0.086)   Loss 0.2358 (0.5113)   Prec@1 87.500 (83.385)   Prec@5 87.500 (83.385)   [2018-03-23 01:47:28]
  **Train** Prec@1 83.160 Prec@5 83.160 Error@1 16.840
  **VAL** Prec@1 91.573 Prec@5 91.573 Error@1 8.427

==>>[2018-03-23 01:48:39] [Epoch=078/250] [Need: 12:40:16] [learning_rate=0.0020] [Best : Accuracy=94.66, Error=5.34]

==>>Epoch=[078/250]], [2018-03-23 01:48:39], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [078][000/505]   Time 0.604 (0.604)   Data 0.201 (0.201)   Loss 0.7337 (0.7337)   Prec@1 37.500 (37.500)   Prec@5 37.500 (37.500)   [2018-03-23 01:48:40]
  Epoch: [078][200/505]   Time 0.453 (0.480)   Data 0.057 (0.085)   Loss 0.4347 (0.4923)   Prec@1 75.000 (83.022)   Prec@5 75.000 (83.022)   [2018-03-23 01:50:16]
  Epoch: [078][400/505]   Time 0.454 (0.480)   Data 0.060 (0.085)   Loss 1.2450 (0.5232)   Prec@1 62.500 (82.201)   Prec@5 62.500 (82.201)   [2018-03-23 01:51:51]
  **Train** Prec@1 81.971 Prec@5 81.971 Error@1 18.029
  **VAL** Prec@1 91.854 Prec@5 91.854 Error@1 8.146

==>>[2018-03-23 01:53:03] [Epoch=079/250] [Need: 12:35:48] [learning_rate=0.0020] [Best : Accuracy=94.66, Error=5.34]

==>>Epoch=[079/250]], [2018-03-23 01:53:03], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [079][000/505]   Time 0.448 (0.448)   Data 0.046 (0.046)   Loss 0.3566 (0.3566)   Prec@1 87.500 (87.500)   Prec@5 87.500 (87.500)   [2018-03-23 01:53:03]
  Epoch: [079][200/505]   Time 0.498 (0.483)   Data 0.104 (0.088)   Loss 0.3754 (0.4895)   Prec@1 87.500 (83.769)   Prec@5 87.500 (83.769)   [2018-03-23 01:54:40]
  Epoch: [079][400/505]   Time 0.890 (0.482)   Data 0.488 (0.087)   Loss 1.7478 (0.5339)   Prec@1 62.500 (82.201)   Prec@5 62.500 (82.201)   [2018-03-23 01:56:16]
  **Train** Prec@1 82.615 Prec@5 82.615 Error@1 17.385
  **VAL** Prec@1 93.820 Prec@5 93.820 Error@1 6.180

==>>[2018-03-23 01:57:27] [Epoch=080/250] [Need: 12:31:20] [learning_rate=0.0020] [Best : Accuracy=94.66, Error=5.34]

==>>Epoch=[080/250]], [2018-03-23 01:57:27], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [080][000/505]   Time 0.539 (0.539)   Data 0.137 (0.137)   Loss 0.8273 (0.8273)   Prec@1 75.000 (75.000)   Prec@5 75.000 (75.000)   [2018-03-23 01:57:27]
  Epoch: [080][200/505]   Time 0.461 (0.481)   Data 0.065 (0.086)   Loss 0.2175 (0.5321)   Prec@1 87.500 (82.525)   Prec@5 87.500 (82.525)   [2018-03-23 01:59:03]
  Epoch: [080][400/505]   Time 0.677 (0.479)   Data 0.275 (0.085)   Loss 1.0729 (0.5371)   Prec@1 62.500 (82.076)   Prec@5 62.500 (82.076)   [2018-03-23 02:00:39]
  **Train** Prec@1 82.293 Prec@5 82.293 Error@1 17.707
  **VAL** Prec@1 94.101 Prec@5 94.101 Error@1 5.899

==>>[2018-03-23 02:01:50] [Epoch=081/250] [Need: 12:26:51] [learning_rate=0.0020] [Best : Accuracy=94.66, Error=5.34]

==>>Epoch=[081/250]], [2018-03-23 02:01:50], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [081][000/505]   Time 0.455 (0.455)   Data 0.054 (0.054)   Loss 0.7907 (0.7907)   Prec@1 75.000 (75.000)   Prec@5 75.000 (75.000)   [2018-03-23 02:01:50]
  Epoch: [081][200/505]   Time 0.475 (0.486)   Data 0.083 (0.091)   Loss 0.4371 (0.5052)   Prec@1 87.500 (82.338)   Prec@5 87.500 (82.338)   [2018-03-23 02:03:28]
  Epoch: [081][400/505]   Time 0.481 (0.481)   Data 0.087 (0.087)   Loss 0.7313 (0.5116)   Prec@1 87.500 (82.575)   Prec@5 87.500 (82.575)   [2018-03-23 02:05:03]
  **Train** Prec@1 82.516 Prec@5 82.516 Error@1 17.484
  **VAL** Prec@1 93.118 Prec@5 93.118 Error@1 6.882

==>>[2018-03-23 02:06:13] [Epoch=082/250] [Need: 12:22:22] [learning_rate=0.0020] [Best : Accuracy=94.66, Error=5.34]

==>>Epoch=[082/250]], [2018-03-23 02:06:13], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [082][000/505]   Time 0.435 (0.435)   Data 0.032 (0.032)   Loss 0.8116 (0.8116)   Prec@1 62.500 (62.500)   Prec@5 62.500 (62.500)   [2018-03-23 02:06:14]
  Epoch: [082][200/505]   Time 0.435 (0.479)   Data 0.041 (0.084)   Loss 0.5164 (0.4594)   Prec@1 87.500 (84.515)   Prec@5 87.500 (84.515)   [2018-03-23 02:07:50]
  Epoch: [082][400/505]   Time 0.461 (0.480)   Data 0.069 (0.086)   Loss 0.3082 (0.4886)   Prec@1 87.500 (83.791)   Prec@5 87.500 (83.791)   [2018-03-23 02:09:26]
  **Train** Prec@1 83.531 Prec@5 83.531 Error@1 16.469
  **VAL** Prec@1 89.466 Prec@5 89.466 Error@1 10.534

==>>[2018-03-23 02:10:37] [Epoch=083/250] [Need: 12:17:53] [learning_rate=0.0020] [Best : Accuracy=94.66, Error=5.34]

==>>Epoch=[083/250]], [2018-03-23 02:10:37], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [083][000/505]   Time 0.489 (0.489)   Data 0.085 (0.085)   Loss 0.3558 (0.3558)   Prec@1 87.500 (87.500)   Prec@5 87.500 (87.500)   [2018-03-23 02:10:37]
  Epoch: [083][200/505]   Time 0.455 (0.481)   Data 0.064 (0.086)   Loss 0.3646 (0.4962)   Prec@1 87.500 (83.147)   Prec@5 87.500 (83.147)   [2018-03-23 02:12:13]
  Epoch: [083][400/505]   Time 0.462 (0.478)   Data 0.065 (0.084)   Loss 0.2460 (0.5110)   Prec@1 100.000 (83.198)   Prec@5 100.000 (83.198)   [2018-03-23 02:13:48]
  **Train** Prec@1 83.036 Prec@5 83.036 Error@1 16.964
  **VAL** Prec@1 93.399 Prec@5 93.399 Error@1 6.601

==>>[2018-03-23 02:15:00] [Epoch=084/250] [Need: 12:13:25] [learning_rate=0.0020] [Best : Accuracy=94.66, Error=5.34]

==>>Epoch=[084/250]], [2018-03-23 02:15:00], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [084][000/505]   Time 0.452 (0.452)   Data 0.052 (0.052)   Loss 0.9516 (0.9516)   Prec@1 50.000 (50.000)   Prec@5 50.000 (50.000)   [2018-03-23 02:15:01]
  Epoch: [084][200/505]   Time 0.476 (0.483)   Data 0.083 (0.089)   Loss 0.3893 (0.4702)   Prec@1 87.500 (83.769)   Prec@5 87.500 (83.769)   [2018-03-23 02:16:37]
  Epoch: [084][400/505]   Time 0.444 (0.481)   Data 0.051 (0.086)   Loss 2.4135 (0.5055)   Prec@1 62.500 (82.512)   Prec@5 62.500 (82.512)   [2018-03-23 02:18:13]
  **Train** Prec@1 82.937 Prec@5 82.937 Error@1 17.063
  **VAL** Prec@1 91.854 Prec@5 91.854 Error@1 8.146

==>>[2018-03-23 02:19:23] [Epoch=085/250] [Need: 12:08:56] [learning_rate=0.0020] [Best : Accuracy=94.66, Error=5.34]

==>>Epoch=[085/250]], [2018-03-23 02:19:23], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [085][000/505]   Time 0.445 (0.445)   Data 0.045 (0.045)   Loss 0.2725 (0.2725)   Prec@1 87.500 (87.500)   Prec@5 87.500 (87.500)   [2018-03-23 02:19:24]
  Epoch: [085][200/505]   Time 0.454 (0.478)   Data 0.061 (0.084)   Loss 0.2300 (0.5338)   Prec@1 87.500 (81.779)   Prec@5 87.500 (81.779)   [2018-03-23 02:20:59]
  Epoch: [085][400/505]   Time 0.561 (0.479)   Data 0.164 (0.085)   Loss 0.4707 (0.5153)   Prec@1 87.500 (82.575)   Prec@5 87.500 (82.575)   [2018-03-23 02:22:36]
  **Train** Prec@1 82.467 Prec@5 82.467 Error@1 17.533
  **VAL** Prec@1 86.938 Prec@5 86.938 Error@1 13.062

==>>[2018-03-23 02:23:47] [Epoch=086/250] [Need: 12:04:28] [learning_rate=0.0020] [Best : Accuracy=94.66, Error=5.34]

==>>Epoch=[086/250]], [2018-03-23 02:23:47], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [086][000/505]   Time 0.490 (0.490)   Data 0.089 (0.089)   Loss 0.1346 (0.1346)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-03-23 02:23:47]
  Epoch: [086][200/505]   Time 0.489 (0.479)   Data 0.094 (0.085)   Loss 0.1176 (0.4665)   Prec@1 100.000 (83.520)   Prec@5 100.000 (83.520)   [2018-03-23 02:25:23]
  Epoch: [086][400/505]   Time 0.448 (0.480)   Data 0.051 (0.086)   Loss 0.5759 (0.4740)   Prec@1 87.500 (83.822)   Prec@5 87.500 (83.822)   [2018-03-23 02:26:59]
  **Train** Prec@1 84.126 Prec@5 84.126 Error@1 15.874
  **VAL** Prec@1 94.522 Prec@5 94.522 Error@1 5.478

==>>[2018-03-23 02:28:10] [Epoch=087/250] [Need: 11:59:59] [learning_rate=0.0020] [Best : Accuracy=94.66, Error=5.34]

==>>Epoch=[087/250]], [2018-03-23 02:28:10], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [087][000/505]   Time 0.481 (0.481)   Data 0.075 (0.075)   Loss 1.0966 (1.0966)   Prec@1 50.000 (50.000)   Prec@5 50.000 (50.000)   [2018-03-23 02:28:11]
  Epoch: [087][200/505]   Time 0.487 (0.477)   Data 0.093 (0.083)   Loss 0.3152 (0.5356)   Prec@1 87.500 (81.530)   Prec@5 87.500 (81.530)   [2018-03-23 02:29:46]
  Epoch: [087][400/505]   Time 0.452 (0.478)   Data 0.060 (0.084)   Loss 1.1137 (0.5335)   Prec@1 75.000 (82.107)   Prec@5 75.000 (82.107)   [2018-03-23 02:31:22]
  **Train** Prec@1 82.813 Prec@5 82.813 Error@1 17.187
  **VAL** Prec@1 93.399 Prec@5 93.399 Error@1 6.601

==>>[2018-03-23 02:32:33] [Epoch=088/250] [Need: 11:55:31] [learning_rate=0.0020] [Best : Accuracy=94.66, Error=5.34]

==>>Epoch=[088/250]], [2018-03-23 02:32:33], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [088][000/505]   Time 0.523 (0.523)   Data 0.120 (0.120)   Loss 0.7275 (0.7275)   Prec@1 62.500 (62.500)   Prec@5 62.500 (62.500)   [2018-03-23 02:32:34]
  Epoch: [088][200/505]   Time 0.458 (0.475)   Data 0.062 (0.081)   Loss 0.4456 (0.5051)   Prec@1 87.500 (83.333)   Prec@5 87.500 (83.333)   [2018-03-23 02:34:09]
  Epoch: [088][400/505]   Time 0.455 (0.478)   Data 0.060 (0.084)   Loss 0.3437 (0.4857)   Prec@1 87.500 (84.320)   Prec@5 87.500 (84.320)   [2018-03-23 02:35:45]
  **Train** Prec@1 84.497 Prec@5 84.497 Error@1 15.503
  **VAL** Prec@1 92.837 Prec@5 92.837 Error@1 7.163

==>>[2018-03-23 02:36:57] [Epoch=089/250] [Need: 11:51:03] [learning_rate=0.0020] [Best : Accuracy=94.66, Error=5.34]

==>>Epoch=[089/250]], [2018-03-23 02:36:57], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [089][000/505]   Time 0.455 (0.455)   Data 0.053 (0.053)   Loss 0.6121 (0.6121)   Prec@1 75.000 (75.000)   Prec@5 75.000 (75.000)   [2018-03-23 02:36:57]
  Epoch: [089][200/505]   Time 0.456 (0.481)   Data 0.059 (0.087)   Loss 0.5025 (0.4722)   Prec@1 75.000 (84.639)   Prec@5 75.000 (84.639)   [2018-03-23 02:38:34]
  Epoch: [089][400/505]   Time 0.462 (0.481)   Data 0.067 (0.087)   Loss 0.0856 (0.4756)   Prec@1 100.000 (84.507)   Prec@5 100.000 (84.507)   [2018-03-23 02:40:10]
  **Train** Prec@1 84.349 Prec@5 84.349 Error@1 15.651
  **VAL** Prec@1 93.258 Prec@5 93.258 Error@1 6.742

==>>[2018-03-23 02:41:20] [Epoch=090/250] [Need: 11:46:36] [learning_rate=0.0020] [Best : Accuracy=94.66, Error=5.34]

==>>Epoch=[090/250]], [2018-03-23 02:41:20], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [090][000/505]   Time 0.493 (0.493)   Data 0.096 (0.096)   Loss 0.5952 (0.5952)   Prec@1 75.000 (75.000)   Prec@5 75.000 (75.000)   [2018-03-23 02:41:21]
  Epoch: [090][200/505]   Time 0.485 (0.482)   Data 0.091 (0.088)   Loss 0.5434 (0.4806)   Prec@1 62.500 (84.328)   Prec@5 62.500 (84.328)   [2018-03-23 02:42:57]
  Epoch: [090][400/505]   Time 0.455 (0.479)   Data 0.059 (0.085)   Loss 0.1340 (0.5121)   Prec@1 100.000 (83.448)   Prec@5 100.000 (83.448)   [2018-03-23 02:44:32]
  **Train** Prec@1 83.358 Prec@5 83.358 Error@1 16.642
  **VAL** Prec@1 92.837 Prec@5 92.837 Error@1 7.163

==>>[2018-03-23 02:45:44] [Epoch=091/250] [Need: 11:42:08] [learning_rate=0.0020] [Best : Accuracy=94.66, Error=5.34]

==>>Epoch=[091/250]], [2018-03-23 02:45:44], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [091][000/505]   Time 0.496 (0.496)   Data 0.099 (0.099)   Loss 0.3516 (0.3516)   Prec@1 87.500 (87.500)   Prec@5 87.500 (87.500)   [2018-03-23 02:45:44]
  Epoch: [091][200/505]   Time 0.538 (0.485)   Data 0.144 (0.090)   Loss 0.3933 (0.4666)   Prec@1 75.000 (84.577)   Prec@5 75.000 (84.577)   [2018-03-23 02:47:21]
  Epoch: [091][400/505]   Time 0.461 (0.480)   Data 0.069 (0.086)   Loss 0.0960 (0.4823)   Prec@1 100.000 (83.603)   Prec@5 100.000 (83.603)   [2018-03-23 02:48:56]
  **Train** Prec@1 83.829 Prec@5 83.829 Error@1 16.171
  **VAL** Prec@1 94.522 Prec@5 94.522 Error@1 5.478

==>>[2018-03-23 02:50:07] [Epoch=092/250] [Need: 11:37:40] [learning_rate=0.0020] [Best : Accuracy=94.66, Error=5.34]

==>>Epoch=[092/250]], [2018-03-23 02:50:07], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [092][000/505]   Time 0.580 (0.580)   Data 0.179 (0.179)   Loss 0.2458 (0.2458)   Prec@1 87.500 (87.500)   Prec@5 87.500 (87.500)   [2018-03-23 02:50:08]
  Epoch: [092][200/505]   Time 0.458 (0.480)   Data 0.064 (0.085)   Loss 0.0488 (0.4301)   Prec@1 100.000 (85.199)   Prec@5 100.000 (85.199)   [2018-03-23 02:51:43]
  Epoch: [092][400/505]   Time 0.524 (0.481)   Data 0.130 (0.087)   Loss 0.2599 (0.4630)   Prec@1 100.000 (84.352)   Prec@5 100.000 (84.352)   [2018-03-23 02:53:20]
  **Train** Prec@1 84.349 Prec@5 84.349 Error@1 15.651
  **VAL** Prec@1 94.101 Prec@5 94.101 Error@1 5.899

==>>[2018-03-23 02:54:30] [Epoch=093/250] [Need: 11:33:13] [learning_rate=0.0020] [Best : Accuracy=94.66, Error=5.34]

==>>Epoch=[093/250]], [2018-03-23 02:54:30], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [093][000/505]   Time 0.465 (0.465)   Data 0.060 (0.060)   Loss 0.7344 (0.7344)   Prec@1 62.500 (62.500)   Prec@5 62.500 (62.500)   [2018-03-23 02:54:31]
  Epoch: [093][200/505]   Time 0.458 (0.483)   Data 0.063 (0.088)   Loss 0.1354 (0.4892)   Prec@1 100.000 (84.017)   Prec@5 100.000 (84.017)   [2018-03-23 02:56:07]
  Epoch: [093][400/505]   Time 0.476 (0.479)   Data 0.080 (0.085)   Loss 0.1067 (0.4626)   Prec@1 100.000 (85.037)   Prec@5 100.000 (85.037)   [2018-03-23 02:57:43]
  **Train** Prec@1 84.324 Prec@5 84.324 Error@1 15.676
  **VAL** Prec@1 94.242 Prec@5 94.242 Error@1 5.758

==>>[2018-03-23 02:58:54] [Epoch=094/250] [Need: 11:28:45] [learning_rate=0.0020] [Best : Accuracy=94.66, Error=5.34]

==>>Epoch=[094/250]], [2018-03-23 02:58:54], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [094][000/505]   Time 0.447 (0.447)   Data 0.047 (0.047)   Loss 1.4836 (1.4836)   Prec@1 62.500 (62.500)   Prec@5 62.500 (62.500)   [2018-03-23 02:58:54]
  Epoch: [094][200/505]   Time 0.512 (0.480)   Data 0.118 (0.086)   Loss 1.1821 (0.4589)   Prec@1 37.500 (84.639)   Prec@5 37.500 (84.639)   [2018-03-23 03:00:30]
  Epoch: [094][400/505]   Time 0.457 (0.479)   Data 0.063 (0.084)   Loss 0.6147 (0.4370)   Prec@1 75.000 (85.474)   Prec@5 75.000 (85.474)   [2018-03-23 03:02:06]
  **Train** Prec@1 85.315 Prec@5 85.315 Error@1 14.685
  **VAL** Prec@1 93.680 Prec@5 93.680 Error@1 6.320

==>>[2018-03-23 03:03:17] [Epoch=095/250] [Need: 11:24:18] [learning_rate=0.0020] [Best : Accuracy=94.66, Error=5.34]

==>>Epoch=[095/250]], [2018-03-23 03:03:17], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [095][000/505]   Time 0.502 (0.502)   Data 0.100 (0.100)   Loss 0.6488 (0.6488)   Prec@1 62.500 (62.500)   Prec@5 62.500 (62.500)   [2018-03-23 03:03:18]
  Epoch: [095][200/505]   Time 0.488 (0.475)   Data 0.094 (0.080)   Loss 0.7039 (0.5211)   Prec@1 62.500 (81.654)   Prec@5 62.500 (81.654)   [2018-03-23 03:04:53]
  Epoch: [095][400/505]   Time 0.472 (0.480)   Data 0.078 (0.085)   Loss 1.4019 (0.4921)   Prec@1 62.500 (82.918)   Prec@5 62.500 (82.918)   [2018-03-23 03:06:30]
  **Train** Prec@1 82.962 Prec@5 82.962 Error@1 17.038
  **VAL** Prec@1 93.539 Prec@5 93.539 Error@1 6.461

==>>[2018-03-23 03:07:41] [Epoch=096/250] [Need: 11:19:51] [learning_rate=0.0020] [Best : Accuracy=94.66, Error=5.34]

==>>Epoch=[096/250]], [2018-03-23 03:07:41], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [096][000/505]   Time 0.489 (0.489)   Data 0.087 (0.087)   Loss 0.6375 (0.6375)   Prec@1 87.500 (87.500)   Prec@5 87.500 (87.500)   [2018-03-23 03:07:42]
  Epoch: [096][200/505]   Time 0.446 (0.480)   Data 0.050 (0.085)   Loss 0.2598 (0.4721)   Prec@1 87.500 (85.759)   Prec@5 87.500 (85.759)   [2018-03-23 03:09:17]
  Epoch: [096][400/505]   Time 0.463 (0.480)   Data 0.071 (0.085)   Loss 0.3092 (0.4816)   Prec@1 87.500 (84.850)   Prec@5 87.500 (84.850)   [2018-03-23 03:10:53]
  **Train** Prec@1 84.993 Prec@5 84.993 Error@1 15.007
  **VAL** Prec@1 92.416 Prec@5 92.416 Error@1 7.584

==>>[2018-03-23 03:12:05] [Epoch=097/250] [Need: 11:15:24] [learning_rate=0.0020] [Best : Accuracy=94.66, Error=5.34]

==>>Epoch=[097/250]], [2018-03-23 03:12:05], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [097][000/505]   Time 0.493 (0.493)   Data 0.088 (0.088)   Loss 0.7853 (0.7853)   Prec@1 87.500 (87.500)   Prec@5 87.500 (87.500)   [2018-03-23 03:12:05]
  Epoch: [097][200/505]   Time 0.446 (0.481)   Data 0.050 (0.087)   Loss 0.0599 (0.5022)   Prec@1 100.000 (83.955)   Prec@5 100.000 (83.955)   [2018-03-23 03:13:41]
  Epoch: [097][400/505]   Time 0.518 (0.480)   Data 0.124 (0.085)   Loss 0.8204 (0.4865)   Prec@1 75.000 (83.884)   Prec@5 75.000 (83.884)   [2018-03-23 03:15:17]
  **Train** Prec@1 84.324 Prec@5 84.324 Error@1 15.676
  **VAL** Prec@1 93.399 Prec@5 93.399 Error@1 6.601

==>>[2018-03-23 03:16:28] [Epoch=098/250] [Need: 11:10:57] [learning_rate=0.0020] [Best : Accuracy=94.66, Error=5.34]

==>>Epoch=[098/250]], [2018-03-23 03:16:28], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [098][000/505]   Time 0.453 (0.453)   Data 0.049 (0.049)   Loss 0.3934 (0.3934)   Prec@1 87.500 (87.500)   Prec@5 87.500 (87.500)   [2018-03-23 03:16:29]
  Epoch: [098][200/505]   Time 0.454 (0.479)   Data 0.058 (0.084)   Loss 0.0461 (0.4658)   Prec@1 100.000 (85.199)   Prec@5 100.000 (85.199)   [2018-03-23 03:18:04]
  Epoch: [098][400/505]   Time 0.461 (0.478)   Data 0.068 (0.083)   Loss 0.2157 (0.4709)   Prec@1 100.000 (84.476)   Prec@5 100.000 (84.476)   [2018-03-23 03:19:40]
  **Train** Prec@1 83.853 Prec@5 83.853 Error@1 16.147
  **VAL** Prec@1 90.730 Prec@5 90.730 Error@1 9.270

==>>[2018-03-23 03:20:52] [Epoch=099/250] [Need: 11:06:31] [learning_rate=0.0020] [Best : Accuracy=94.66, Error=5.34]

==>>Epoch=[099/250]], [2018-03-23 03:20:52], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [099][000/505]   Time 0.482 (0.482)   Data 0.081 (0.081)   Loss 0.1835 (0.1835)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-03-23 03:20:52]
  Epoch: [099][200/505]   Time 0.441 (0.482)   Data 0.047 (0.088)   Loss 0.3090 (0.4678)   Prec@1 87.500 (84.142)   Prec@5 87.500 (84.142)   [2018-03-23 03:22:29]
  Epoch: [099][400/505]   Time 0.494 (0.480)   Data 0.104 (0.086)   Loss 0.1574 (0.4629)   Prec@1 100.000 (84.507)   Prec@5 100.000 (84.507)   [2018-03-23 03:24:04]
  **Train** Prec@1 84.943 Prec@5 84.943 Error@1 15.057
  **VAL** Prec@1 93.820 Prec@5 93.820 Error@1 6.180

==>>[2018-03-23 03:25:15] [Epoch=100/250] [Need: 11:02:04] [learning_rate=0.0020] [Best : Accuracy=94.66, Error=5.34]

==>>Epoch=[100/250]], [2018-03-23 03:25:15], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [100][000/505]   Time 0.465 (0.465)   Data 0.065 (0.065)   Loss 0.5597 (0.5597)   Prec@1 87.500 (87.500)   Prec@5 87.500 (87.500)   [2018-03-23 03:25:16]
  Epoch: [100][200/505]   Time 0.466 (0.481)   Data 0.074 (0.087)   Loss 1.3775 (0.5024)   Prec@1 62.500 (82.711)   Prec@5 62.500 (82.711)   [2018-03-23 03:26:52]
  Epoch: [100][400/505]   Time 0.455 (0.481)   Data 0.062 (0.086)   Loss 0.2521 (0.4694)   Prec@1 87.500 (83.884)   Prec@5 87.500 (83.884)   [2018-03-23 03:28:28]
  **Train** Prec@1 83.878 Prec@5 83.878 Error@1 16.122
  **VAL** Prec@1 92.135 Prec@5 92.135 Error@1 7.865

==>>[2018-03-23 03:29:39] [Epoch=101/250] [Need: 10:57:37] [learning_rate=0.0020] [Best : Accuracy=94.66, Error=5.34]

==>>Epoch=[101/250]], [2018-03-23 03:29:39], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [101][000/505]   Time 0.578 (0.578)   Data 0.175 (0.175)   Loss 0.7166 (0.7166)   Prec@1 87.500 (87.500)   Prec@5 87.500 (87.500)   [2018-03-23 03:29:39]
  Epoch: [101][200/505]   Time 0.444 (0.480)   Data 0.048 (0.086)   Loss 0.1391 (0.4233)   Prec@1 100.000 (86.132)   Prec@5 100.000 (86.132)   [2018-03-23 03:31:15]
  Epoch: [101][400/505]   Time 0.448 (0.480)   Data 0.054 (0.086)   Loss 0.8173 (0.4502)   Prec@1 75.000 (85.069)   Prec@5 75.000 (85.069)   [2018-03-23 03:32:51]
  **Train** Prec@1 84.918 Prec@5 84.918 Error@1 15.082
  **VAL** Prec@1 93.820 Prec@5 93.820 Error@1 6.180

==>>[2018-03-23 03:34:02] [Epoch=102/250] [Need: 10:53:10] [learning_rate=0.0020] [Best : Accuracy=94.66, Error=5.34]

==>>Epoch=[102/250]], [2018-03-23 03:34:02], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [102][000/505]   Time 0.526 (0.526)   Data 0.120 (0.120)   Loss 0.4860 (0.4860)   Prec@1 75.000 (75.000)   Prec@5 75.000 (75.000)   [2018-03-23 03:34:03]
  Epoch: [102][200/505]   Time 0.466 (0.479)   Data 0.069 (0.085)   Loss 0.1165 (0.4498)   Prec@1 87.500 (84.204)   Prec@5 87.500 (84.204)   [2018-03-23 03:35:39]
  Epoch: [102][400/505]   Time 0.464 (0.479)   Data 0.069 (0.085)   Loss 1.0477 (0.4649)   Prec@1 75.000 (84.040)   Prec@5 75.000 (84.040)   [2018-03-23 03:37:14]
  **Train** Prec@1 83.779 Prec@5 83.779 Error@1 16.221
  **VAL** Prec@1 88.624 Prec@5 88.624 Error@1 11.376

==>>[2018-03-23 03:38:26] [Epoch=103/250] [Need: 10:48:44] [learning_rate=0.0020] [Best : Accuracy=94.66, Error=5.34]

==>>Epoch=[103/250]], [2018-03-23 03:38:26], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [103][000/505]   Time 0.486 (0.486)   Data 0.079 (0.079)   Loss 0.3212 (0.3212)   Prec@1 87.500 (87.500)   Prec@5 87.500 (87.500)   [2018-03-23 03:38:26]
  Epoch: [103][200/505]   Time 0.497 (0.478)   Data 0.100 (0.084)   Loss 0.4842 (0.4775)   Prec@1 87.500 (84.950)   Prec@5 87.500 (84.950)   [2018-03-23 03:40:02]
  Epoch: [103][400/505]   Time 0.449 (0.479)   Data 0.054 (0.084)   Loss 0.8012 (0.4867)   Prec@1 62.500 (84.352)   Prec@5 62.500 (84.352)   [2018-03-23 03:41:38]
  **Train** Prec@1 84.993 Prec@5 84.993 Error@1 15.007
  **VAL** Prec@1 92.697 Prec@5 92.697 Error@1 7.303

==>>[2018-03-23 03:42:49] [Epoch=104/250] [Need: 10:44:17] [learning_rate=0.0020] [Best : Accuracy=94.66, Error=5.34]

==>>Epoch=[104/250]], [2018-03-23 03:42:49], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [104][000/505]   Time 0.473 (0.473)   Data 0.071 (0.071)   Loss 1.3496 (1.3496)   Prec@1 50.000 (50.000)   Prec@5 50.000 (50.000)   [2018-03-23 03:42:50]
  Epoch: [104][200/505]   Time 0.496 (0.479)   Data 0.103 (0.085)   Loss 0.2915 (0.4898)   Prec@1 75.000 (83.333)   Prec@5 75.000 (83.333)   [2018-03-23 03:44:26]
  Epoch: [104][400/505]   Time 0.505 (0.480)   Data 0.109 (0.085)   Loss 0.0802 (0.4538)   Prec@1 100.000 (84.383)   Prec@5 100.000 (84.383)   [2018-03-23 03:46:02]
  **Train** Prec@1 84.274 Prec@5 84.274 Error@1 15.726
  **VAL** Prec@1 93.118 Prec@5 93.118 Error@1 6.882

==>>[2018-03-23 03:47:13] [Epoch=105/250] [Need: 10:39:50] [learning_rate=0.0020] [Best : Accuracy=94.66, Error=5.34]

==>>Epoch=[105/250]], [2018-03-23 03:47:13], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [105][000/505]   Time 0.570 (0.570)   Data 0.168 (0.168)   Loss 0.0827 (0.0827)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-03-23 03:47:13]
  Epoch: [105][200/505]   Time 0.468 (0.480)   Data 0.072 (0.086)   Loss 0.4330 (0.4512)   Prec@1 75.000 (85.448)   Prec@5 75.000 (85.448)   [2018-03-23 03:48:49]
  Epoch: [105][400/505]   Time 0.505 (0.479)   Data 0.112 (0.084)   Loss 0.0915 (0.4645)   Prec@1 100.000 (84.882)   Prec@5 100.000 (84.882)   [2018-03-23 03:50:25]
  **Train** Prec@1 85.191 Prec@5 85.191 Error@1 14.809
  **VAL** Prec@1 94.522 Prec@5 94.522 Error@1 5.478

==>>[2018-03-23 03:51:36] [Epoch=106/250] [Need: 10:35:24] [learning_rate=0.0020] [Best : Accuracy=94.66, Error=5.34]

==>>Epoch=[106/250]], [2018-03-23 03:51:36], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [106][000/505]   Time 0.451 (0.451)   Data 0.052 (0.052)   Loss 0.8191 (0.8191)   Prec@1 62.500 (62.500)   Prec@5 62.500 (62.500)   [2018-03-23 03:51:36]
  Epoch: [106][200/505]   Time 0.514 (0.482)   Data 0.119 (0.087)   Loss 0.1206 (0.4517)   Prec@1 100.000 (84.639)   Prec@5 100.000 (84.639)   [2018-03-23 03:53:13]
  Epoch: [106][400/505]   Time 0.513 (0.480)   Data 0.118 (0.086)   Loss 0.1463 (0.4623)   Prec@1 100.000 (84.663)   Prec@5 100.000 (84.663)   [2018-03-23 03:54:49]
  **Train** Prec@1 84.844 Prec@5 84.844 Error@1 15.156
  **VAL** Prec@1 93.680 Prec@5 93.680 Error@1 6.320

==>>[2018-03-23 03:55:59] [Epoch=107/250] [Need: 10:30:57] [learning_rate=0.0020] [Best : Accuracy=94.66, Error=5.34]

==>>Epoch=[107/250]], [2018-03-23 03:55:59], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [107][000/505]   Time 0.465 (0.465)   Data 0.065 (0.065)   Loss 0.2132 (0.2132)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-03-23 03:56:00]
  Epoch: [107][200/505]   Time 0.537 (0.482)   Data 0.142 (0.088)   Loss 0.3093 (0.4568)   Prec@1 87.500 (86.132)   Prec@5 87.500 (86.132)   [2018-03-23 03:57:36]
  Epoch: [107][400/505]   Time 0.448 (0.479)   Data 0.053 (0.085)   Loss 0.2889 (0.4707)   Prec@1 75.000 (85.006)   Prec@5 75.000 (85.006)   [2018-03-23 03:59:12]
  **Train** Prec@1 85.042 Prec@5 85.042 Error@1 14.958
  **VAL** Prec@1 93.118 Prec@5 93.118 Error@1 6.882

==>>[2018-03-23 04:00:23] [Epoch=108/250] [Need: 10:26:31] [learning_rate=0.0020] [Best : Accuracy=94.66, Error=5.34]

==>>Epoch=[108/250]], [2018-03-23 04:00:23], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [108][000/505]   Time 0.562 (0.562)   Data 0.160 (0.160)   Loss 0.6046 (0.6046)   Prec@1 75.000 (75.000)   Prec@5 75.000 (75.000)   [2018-03-23 04:00:23]
  Epoch: [108][200/505]   Time 0.497 (0.482)   Data 0.102 (0.087)   Loss 0.3946 (0.4142)   Prec@1 87.500 (86.007)   Prec@5 87.500 (86.007)   [2018-03-23 04:02:00]
  Epoch: [108][400/505]   Time 0.451 (0.480)   Data 0.054 (0.085)   Loss 0.3916 (0.4434)   Prec@1 75.000 (84.850)   Prec@5 75.000 (84.850)   [2018-03-23 04:03:35]
  **Train** Prec@1 85.265 Prec@5 85.265 Error@1 14.735
  **VAL** Prec@1 92.837 Prec@5 92.837 Error@1 7.163

==>>[2018-03-23 04:04:46] [Epoch=109/250] [Need: 10:22:04] [learning_rate=0.0020] [Best : Accuracy=94.66, Error=5.34]

==>>Epoch=[109/250]], [2018-03-23 04:04:46], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [109][000/505]   Time 0.513 (0.513)   Data 0.108 (0.108)   Loss 0.3554 (0.3554)   Prec@1 87.500 (87.500)   Prec@5 87.500 (87.500)   [2018-03-23 04:04:47]
  Epoch: [109][200/505]   Time 0.437 (0.479)   Data 0.045 (0.085)   Loss 0.7219 (0.4853)   Prec@1 87.500 (84.142)   Prec@5 87.500 (84.142)   [2018-03-23 04:06:23]
  Epoch: [109][400/505]   Time 0.441 (0.480)   Data 0.049 (0.086)   Loss 0.5395 (0.4644)   Prec@1 75.000 (84.507)   Prec@5 75.000 (84.507)   [2018-03-23 04:07:59]
  **Train** Prec@1 84.993 Prec@5 84.993 Error@1 15.007
  **VAL** Prec@1 95.787 Prec@5 95.787 Error@1 4.213

==>>[2018-03-23 04:09:38] [Epoch=110/250] [Need: 10:17:38] [learning_rate=0.0020] [Best : Accuracy=95.79, Error=4.21]

==>>Epoch=[110/250]], [2018-03-23 04:09:38], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [110][000/505]   Time 0.585 (0.585)   Data 0.094 (0.094)   Loss 0.2483 (0.2483)   Prec@1 87.500 (87.500)   Prec@5 87.500 (87.500)   [2018-03-23 04:09:39]
  Epoch: [110][200/505]   Time 0.444 (0.476)   Data 0.048 (0.080)   Loss 0.7987 (0.4317)   Prec@1 75.000 (85.199)   Prec@5 75.000 (85.199)   [2018-03-23 04:11:14]
  Epoch: [110][400/505]   Time 0.459 (0.480)   Data 0.063 (0.085)   Loss 0.2813 (0.4474)   Prec@1 87.500 (85.069)   Prec@5 87.500 (85.069)   [2018-03-23 04:12:51]
  **Train** Prec@1 84.894 Prec@5 84.894 Error@1 15.106
  **VAL** Prec@1 93.399 Prec@5 93.399 Error@1 6.601

==>>[2018-03-23 04:14:02] [Epoch=111/250] [Need: 10:13:48] [learning_rate=0.0020] [Best : Accuracy=95.79, Error=4.21]

==>>Epoch=[111/250]], [2018-03-23 04:14:02], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [111][000/505]   Time 0.466 (0.466)   Data 0.064 (0.064)   Loss 0.1580 (0.1580)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-03-23 04:14:03]
  Epoch: [111][200/505]   Time 0.473 (0.478)   Data 0.081 (0.083)   Loss 0.5801 (0.4380)   Prec@1 87.500 (85.137)   Prec@5 87.500 (85.137)   [2018-03-23 04:15:38]
  Epoch: [111][400/505]   Time 0.479 (0.479)   Data 0.084 (0.084)   Loss 0.5563 (0.4398)   Prec@1 87.500 (85.318)   Prec@5 87.500 (85.318)   [2018-03-23 04:17:14]
  **Train** Prec@1 85.092 Prec@5 85.092 Error@1 14.908
  **VAL** Prec@1 93.399 Prec@5 93.399 Error@1 6.601

==>>[2018-03-23 04:18:25] [Epoch=112/250] [Need: 10:09:21] [learning_rate=0.0020] [Best : Accuracy=95.79, Error=4.21]

==>>Epoch=[112/250]], [2018-03-23 04:18:25], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [112][000/505]   Time 0.517 (0.517)   Data 0.111 (0.111)   Loss 0.2400 (0.2400)   Prec@1 87.500 (87.500)   Prec@5 87.500 (87.500)   [2018-03-23 04:18:26]
  Epoch: [112][200/505]   Time 0.520 (0.481)   Data 0.128 (0.086)   Loss 0.1033 (0.4280)   Prec@1 100.000 (85.386)   Prec@5 100.000 (85.386)   [2018-03-23 04:20:02]
  Epoch: [112][400/505]   Time 0.447 (0.480)   Data 0.054 (0.085)   Loss 1.3909 (0.4517)   Prec@1 62.500 (84.850)   Prec@5 62.500 (84.850)   [2018-03-23 04:21:38]
  **Train** Prec@1 84.126 Prec@5 84.126 Error@1 15.874
  **VAL** Prec@1 92.697 Prec@5 92.697 Error@1 7.303

==>>[2018-03-23 04:22:49] [Epoch=113/250] [Need: 10:04:54] [learning_rate=0.0020] [Best : Accuracy=95.79, Error=4.21]

==>>Epoch=[113/250]], [2018-03-23 04:22:49], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [113][000/505]   Time 0.500 (0.500)   Data 0.098 (0.098)   Loss 0.1744 (0.1744)   Prec@1 87.500 (87.500)   Prec@5 87.500 (87.500)   [2018-03-23 04:22:49]
  Epoch: [113][200/505]   Time 0.454 (0.476)   Data 0.062 (0.081)   Loss 0.6455 (0.4603)   Prec@1 62.500 (84.080)   Prec@5 62.500 (84.080)   [2018-03-23 04:24:25]
  Epoch: [113][400/505]   Time 0.462 (0.479)   Data 0.069 (0.084)   Loss 0.4957 (0.4455)   Prec@1 87.500 (85.287)   Prec@5 87.500 (85.287)   [2018-03-23 04:26:01]
  **Train** Prec@1 85.315 Prec@5 85.315 Error@1 14.685
  **VAL** Prec@1 95.225 Prec@5 95.225 Error@1 4.775

==>>[2018-03-23 04:27:39] [Epoch=114/250] [Need: 10:00:27] [learning_rate=0.0020] [Best : Accuracy=95.79, Error=4.21]

==>>Epoch=[114/250]], [2018-03-23 04:27:39], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [114][000/505]   Time 0.466 (0.466)   Data 0.070 (0.070)   Loss 0.4656 (0.4656)   Prec@1 87.500 (87.500)   Prec@5 87.500 (87.500)   [2018-03-23 04:27:40]
  Epoch: [114][200/505]   Time 0.438 (0.484)   Data 0.045 (0.089)   Loss 0.1734 (0.4721)   Prec@1 87.500 (83.458)   Prec@5 87.500 (83.458)   [2018-03-23 04:29:16]
  Epoch: [114][400/505]   Time 0.463 (0.481)   Data 0.069 (0.086)   Loss 1.0977 (0.4658)   Prec@1 62.500 (84.133)   Prec@5 62.500 (84.133)   [2018-03-23 04:30:52]
  **Train** Prec@1 84.522 Prec@5 84.522 Error@1 15.478
  **VAL** Prec@1 92.275 Prec@5 92.275 Error@1 7.725

==>>[2018-03-23 04:32:02] [Epoch=115/250] [Need: 09:56:32] [learning_rate=0.0020] [Best : Accuracy=95.79, Error=4.21]

==>>Epoch=[115/250]], [2018-03-23 04:32:02], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [115][000/505]   Time 0.448 (0.448)   Data 0.046 (0.046)   Loss 0.4346 (0.4346)   Prec@1 75.000 (75.000)   Prec@5 75.000 (75.000)   [2018-03-23 04:32:03]
  Epoch: [115][200/505]   Time 0.460 (0.482)   Data 0.061 (0.087)   Loss 0.0236 (0.4327)   Prec@1 100.000 (85.448)   Prec@5 100.000 (85.448)   [2018-03-23 04:33:39]
  Epoch: [115][400/505]   Time 0.441 (0.483)   Data 0.048 (0.088)   Loss 0.3398 (0.4411)   Prec@1 75.000 (85.162)   Prec@5 75.000 (85.162)   [2018-03-23 04:35:16]
  **Train** Prec@1 85.736 Prec@5 85.736 Error@1 14.264
  **VAL** Prec@1 93.258 Prec@5 93.258 Error@1 6.742

==>>[2018-03-23 04:36:26] [Epoch=116/250] [Need: 09:52:05] [learning_rate=0.0020] [Best : Accuracy=95.79, Error=4.21]

==>>Epoch=[116/250]], [2018-03-23 04:36:26], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [116][000/505]   Time 0.496 (0.496)   Data 0.092 (0.092)   Loss 0.2884 (0.2884)   Prec@1 87.500 (87.500)   Prec@5 87.500 (87.500)   [2018-03-23 04:36:26]
  Epoch: [116][200/505]   Time 0.478 (0.483)   Data 0.085 (0.088)   Loss 0.8486 (0.4565)   Prec@1 75.000 (84.888)   Prec@5 75.000 (84.888)   [2018-03-23 04:38:03]
  Epoch: [116][400/505]   Time 0.486 (0.480)   Data 0.091 (0.086)   Loss 0.3504 (0.4609)   Prec@1 87.500 (85.224)   Prec@5 87.500 (85.224)   [2018-03-23 04:39:38]
  **Train** Prec@1 85.067 Prec@5 85.067 Error@1 14.933
  **VAL** Prec@1 93.539 Prec@5 93.539 Error@1 6.461

==>>[2018-03-23 04:40:49] [Epoch=117/250] [Need: 09:47:38] [learning_rate=0.0020] [Best : Accuracy=95.79, Error=4.21]

==>>Epoch=[117/250]], [2018-03-23 04:40:49], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [117][000/505]   Time 0.454 (0.454)   Data 0.053 (0.053)   Loss 0.2075 (0.2075)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-03-23 04:40:50]
  Epoch: [117][200/505]   Time 0.481 (0.480)   Data 0.085 (0.086)   Loss 0.5302 (0.4323)   Prec@1 75.000 (86.629)   Prec@5 75.000 (86.629)   [2018-03-23 04:42:26]
  Epoch: [117][400/505]   Time 0.472 (0.480)   Data 0.078 (0.086)   Loss 0.6286 (0.4156)   Prec@1 75.000 (86.440)   Prec@5 75.000 (86.440)   [2018-03-23 04:44:02]
  **Train** Prec@1 86.256 Prec@5 86.256 Error@1 13.744
  **VAL** Prec@1 94.101 Prec@5 94.101 Error@1 5.899

==>>[2018-03-23 04:45:13] [Epoch=118/250] [Need: 09:43:11] [learning_rate=0.0020] [Best : Accuracy=95.79, Error=4.21]

==>>Epoch=[118/250]], [2018-03-23 04:45:13], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [118][000/505]   Time 0.450 (0.450)   Data 0.044 (0.044)   Loss 1.2417 (1.2417)   Prec@1 75.000 (75.000)   Prec@5 75.000 (75.000)   [2018-03-23 04:45:13]
  Epoch: [118][200/505]   Time 0.661 (0.481)   Data 0.263 (0.086)   Loss 0.2153 (0.4529)   Prec@1 100.000 (83.955)   Prec@5 100.000 (83.955)   [2018-03-23 04:46:49]
  Epoch: [118][400/505]   Time 0.540 (0.480)   Data 0.147 (0.085)   Loss 0.3006 (0.4511)   Prec@1 87.500 (84.726)   Prec@5 87.500 (84.726)   [2018-03-23 04:48:25]
  **Train** Prec@1 85.364 Prec@5 85.364 Error@1 14.636
  **VAL** Prec@1 93.118 Prec@5 93.118 Error@1 6.882

==>>[2018-03-23 04:49:36] [Epoch=119/250] [Need: 09:38:44] [learning_rate=0.0020] [Best : Accuracy=95.79, Error=4.21]

==>>Epoch=[119/250]], [2018-03-23 04:49:36], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [119][000/505]   Time 0.501 (0.501)   Data 0.099 (0.099)   Loss 0.6572 (0.6572)   Prec@1 62.500 (62.500)   Prec@5 62.500 (62.500)   [2018-03-23 04:49:37]
  Epoch: [119][200/505]   Time 0.455 (0.483)   Data 0.060 (0.088)   Loss 0.0975 (0.4775)   Prec@1 100.000 (83.955)   Prec@5 100.000 (83.955)   [2018-03-23 04:51:13]
  Epoch: [119][400/505]   Time 0.454 (0.480)   Data 0.061 (0.085)   Loss 0.1880 (0.4504)   Prec@1 100.000 (85.318)   Prec@5 100.000 (85.318)   [2018-03-23 04:52:49]
  **Train** Prec@1 85.240 Prec@5 85.240 Error@1 14.760
  **VAL** Prec@1 95.646 Prec@5 95.646 Error@1 4.354

==>>[2018-03-23 04:54:26] [Epoch=120/250] [Need: 09:34:17] [learning_rate=0.0020] [Best : Accuracy=95.79, Error=4.21]

==>>Epoch=[120/250]], [2018-03-23 04:54:26], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [120][000/505]   Time 0.512 (0.512)   Data 0.112 (0.112)   Loss 0.4771 (0.4771)   Prec@1 87.500 (87.500)   Prec@5 87.500 (87.500)   [2018-03-23 04:54:27]
  Epoch: [120][200/505]   Time 0.479 (0.478)   Data 0.086 (0.084)   Loss 0.0364 (0.4468)   Prec@1 100.000 (85.075)   Prec@5 100.000 (85.075)   [2018-03-23 04:56:02]
  Epoch: [120][400/505]   Time 0.457 (0.479)   Data 0.064 (0.084)   Loss 0.1209 (0.4245)   Prec@1 100.000 (85.411)   Prec@5 100.000 (85.411)   [2018-03-23 04:57:38]
  **Train** Prec@1 84.770 Prec@5 84.770 Error@1 15.230
  **VAL** Prec@1 94.944 Prec@5 94.944 Error@1 5.056

==>>[2018-03-23 04:58:44] [Epoch=121/250] [Need: 09:30:12] [learning_rate=0.0020] [Best : Accuracy=95.79, Error=4.21]

==>>Epoch=[121/250]], [2018-03-23 04:58:44], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [121][000/505]   Time 0.555 (0.555)   Data 0.152 (0.152)   Loss 0.0757 (0.0757)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-03-23 04:58:44]
  Epoch: [121][200/505]   Time 0.486 (0.491)   Data 0.093 (0.096)   Loss 0.2309 (0.4186)   Prec@1 100.000 (86.381)   Prec@5 100.000 (86.381)   [2018-03-23 05:00:22]
  Epoch: [121][400/505]   Time 0.480 (0.484)   Data 0.089 (0.089)   Loss 0.9811 (0.4450)   Prec@1 75.000 (85.224)   Prec@5 75.000 (85.224)   [2018-03-23 05:01:58]
  **Train** Prec@1 85.810 Prec@5 85.810 Error@1 14.190
  **VAL** Prec@1 95.365 Prec@5 95.365 Error@1 4.635

==>>[2018-03-23 05:03:35] [Epoch=122/250] [Need: 09:25:47] [learning_rate=0.0020] [Best : Accuracy=95.79, Error=4.21]

==>>Epoch=[122/250]], [2018-03-23 05:03:35], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [122][000/505]   Time 0.447 (0.447)   Data 0.054 (0.054)   Loss 0.9376 (0.9376)   Prec@1 75.000 (75.000)   Prec@5 75.000 (75.000)   [2018-03-23 05:03:36]
  Epoch: [122][200/505]   Time 0.530 (0.480)   Data 0.138 (0.086)   Loss 0.3782 (0.4440)   Prec@1 75.000 (84.826)   Prec@5 75.000 (84.826)   [2018-03-23 05:05:12]
  Epoch: [122][400/505]   Time 0.502 (0.478)   Data 0.107 (0.084)   Loss 0.0416 (0.4404)   Prec@1 100.000 (85.256)   Prec@5 100.000 (85.256)   [2018-03-23 05:06:47]
  **Train** Prec@1 84.894 Prec@5 84.894 Error@1 15.106
  **VAL** Prec@1 94.242 Prec@5 94.242 Error@1 5.758

==>>[2018-03-23 05:07:58] [Epoch=123/250] [Need: 09:21:47] [learning_rate=0.0020] [Best : Accuracy=95.79, Error=4.21]

==>>Epoch=[123/250]], [2018-03-23 05:07:58], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [123][000/505]   Time 0.474 (0.474)   Data 0.070 (0.070)   Loss 0.3477 (0.3477)   Prec@1 87.500 (87.500)   Prec@5 87.500 (87.500)   [2018-03-23 05:07:59]
  Epoch: [123][200/505]   Time 0.463 (0.475)   Data 0.068 (0.081)   Loss 0.0286 (0.4518)   Prec@1 100.000 (84.577)   Prec@5 100.000 (84.577)   [2018-03-23 05:09:34]
  Epoch: [123][400/505]   Time 0.521 (0.479)   Data 0.126 (0.085)   Loss 0.1480 (0.4193)   Prec@1 100.000 (86.347)   Prec@5 100.000 (86.347)   [2018-03-23 05:11:10]
  **Train** Prec@1 86.206 Prec@5 86.206 Error@1 13.794
  **VAL** Prec@1 94.944 Prec@5 94.944 Error@1 5.056

==>>[2018-03-23 05:12:22] [Epoch=124/250] [Need: 09:17:19] [learning_rate=0.0020] [Best : Accuracy=95.79, Error=4.21]

==>>Epoch=[124/250]], [2018-03-23 05:12:22], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [124][000/505]   Time 0.547 (0.547)   Data 0.150 (0.150)   Loss 0.2032 (0.2032)   Prec@1 87.500 (87.500)   Prec@5 87.500 (87.500)   [2018-03-23 05:12:22]
  Epoch: [124][200/505]   Time 0.436 (0.479)   Data 0.044 (0.085)   Loss 0.0532 (0.4135)   Prec@1 100.000 (85.634)   Prec@5 100.000 (85.634)   [2018-03-23 05:13:58]
  Epoch: [124][400/505]   Time 0.462 (0.480)   Data 0.068 (0.086)   Loss 0.2250 (0.4236)   Prec@1 100.000 (85.723)   Prec@5 100.000 (85.723)   [2018-03-23 05:15:34]
  **Train** Prec@1 85.513 Prec@5 85.513 Error@1 14.487
  **VAL** Prec@1 93.680 Prec@5 93.680 Error@1 6.320

==>>[2018-03-23 05:16:45] [Epoch=125/250] [Need: 09:12:52] [learning_rate=0.0020] [Best : Accuracy=95.79, Error=4.21]

==>>Epoch=[125/250]], [2018-03-23 05:16:45], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [125][000/505]   Time 0.583 (0.583)   Data 0.179 (0.179)   Loss 0.6560 (0.6560)   Prec@1 75.000 (75.000)   Prec@5 75.000 (75.000)   [2018-03-23 05:16:45]
  Epoch: [125][200/505]   Time 0.449 (0.477)   Data 0.059 (0.083)   Loss 0.2031 (0.4079)   Prec@1 100.000 (86.505)   Prec@5 100.000 (86.505)   [2018-03-23 05:18:21]
  Epoch: [125][400/505]   Time 0.455 (0.480)   Data 0.063 (0.086)   Loss 0.5826 (0.3995)   Prec@1 75.000 (86.721)   Prec@5 75.000 (86.721)   [2018-03-23 05:19:57]
  **Train** Prec@1 86.330 Prec@5 86.330 Error@1 13.670
  **VAL** Prec@1 93.118 Prec@5 93.118 Error@1 6.882

==>>[2018-03-23 05:21:08] [Epoch=126/250] [Need: 09:08:24] [learning_rate=0.0020] [Best : Accuracy=95.79, Error=4.21]

==>>Epoch=[126/250]], [2018-03-23 05:21:08], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [126][000/505]   Time 0.570 (0.570)   Data 0.169 (0.169)   Loss 0.4836 (0.4836)   Prec@1 87.500 (87.500)   Prec@5 87.500 (87.500)   [2018-03-23 05:21:08]
  Epoch: [126][200/505]   Time 0.453 (0.480)   Data 0.062 (0.086)   Loss 0.4325 (0.4180)   Prec@1 87.500 (85.510)   Prec@5 87.500 (85.510)   [2018-03-23 05:22:44]
  Epoch: [126][400/505]   Time 0.463 (0.479)   Data 0.068 (0.085)   Loss 0.4743 (0.4253)   Prec@1 75.000 (85.318)   Prec@5 75.000 (85.318)   [2018-03-23 05:24:20]
  **Train** Prec@1 85.736 Prec@5 85.736 Error@1 14.264
  **VAL** Prec@1 94.522 Prec@5 94.522 Error@1 5.478

==>>[2018-03-23 05:25:31] [Epoch=127/250] [Need: 09:03:56] [learning_rate=0.0020] [Best : Accuracy=95.79, Error=4.21]

==>>Epoch=[127/250]], [2018-03-23 05:25:31], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [127][000/505]   Time 0.458 (0.458)   Data 0.058 (0.058)   Loss 0.7268 (0.7268)   Prec@1 87.500 (87.500)   Prec@5 87.500 (87.500)   [2018-03-23 05:25:31]
  Epoch: [127][200/505]   Time 0.484 (0.483)   Data 0.092 (0.089)   Loss 0.4570 (0.4287)   Prec@1 75.000 (85.386)   Prec@5 75.000 (85.386)   [2018-03-23 05:27:08]
  Epoch: [127][400/505]   Time 0.439 (0.479)   Data 0.048 (0.086)   Loss 0.0739 (0.4311)   Prec@1 100.000 (85.256)   Prec@5 100.000 (85.256)   [2018-03-23 05:28:43]
  **Train** Prec@1 85.884 Prec@5 85.884 Error@1 14.116
  **VAL** Prec@1 94.944 Prec@5 94.944 Error@1 5.056

==>>[2018-03-23 05:29:53] [Epoch=128/250] [Need: 08:59:29] [learning_rate=0.0020] [Best : Accuracy=95.79, Error=4.21]

==>>Epoch=[128/250]], [2018-03-23 05:29:53], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [128][000/505]   Time 0.487 (0.487)   Data 0.079 (0.079)   Loss 0.5537 (0.5537)   Prec@1 87.500 (87.500)   Prec@5 87.500 (87.500)   [2018-03-23 05:29:54]
  Epoch: [128][200/505]   Time 0.475 (0.479)   Data 0.084 (0.085)   Loss 0.1347 (0.4314)   Prec@1 100.000 (85.759)   Prec@5 100.000 (85.759)   [2018-03-23 05:31:30]
  Epoch: [128][400/505]   Time 0.524 (0.478)   Data 0.130 (0.084)   Loss 0.5236 (0.4123)   Prec@1 87.500 (86.004)   Prec@5 87.500 (86.004)   [2018-03-23 05:33:05]
  **Train** Prec@1 85.736 Prec@5 85.736 Error@1 14.264
  **VAL** Prec@1 93.118 Prec@5 93.118 Error@1 6.882

==>>[2018-03-23 05:34:16] [Epoch=129/250] [Need: 08:55:01] [learning_rate=0.0020] [Best : Accuracy=95.79, Error=4.21]

==>>Epoch=[129/250]], [2018-03-23 05:34:16], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [129][000/505]   Time 0.492 (0.492)   Data 0.090 (0.090)   Loss 0.0777 (0.0777)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-03-23 05:34:17]
  Epoch: [129][200/505]   Time 0.439 (0.480)   Data 0.043 (0.086)   Loss 0.2260 (0.4464)   Prec@1 87.500 (85.572)   Prec@5 87.500 (85.572)   [2018-03-23 05:35:53]
  Epoch: [129][400/505]   Time 0.599 (0.481)   Data 0.197 (0.087)   Loss 0.9352 (0.4305)   Prec@1 62.500 (86.035)   Prec@5 62.500 (86.035)   [2018-03-23 05:37:29]
  **Train** Prec@1 86.256 Prec@5 86.256 Error@1 13.744
  **VAL** Prec@1 93.539 Prec@5 93.539 Error@1 6.461

==>>[2018-03-23 05:38:39] [Epoch=130/250] [Need: 08:50:34] [learning_rate=0.0020] [Best : Accuracy=95.79, Error=4.21]

==>>Epoch=[130/250]], [2018-03-23 05:38:39], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [130][000/505]   Time 0.510 (0.510)   Data 0.104 (0.104)   Loss 0.8178 (0.8178)   Prec@1 62.500 (62.500)   Prec@5 62.500 (62.500)   [2018-03-23 05:38:40]
  Epoch: [130][200/505]   Time 0.499 (0.478)   Data 0.105 (0.084)   Loss 0.4785 (0.4513)   Prec@1 87.500 (85.510)   Prec@5 87.500 (85.510)   [2018-03-23 05:40:16]
  Epoch: [130][400/505]   Time 0.429 (0.480)   Data 0.036 (0.086)   Loss 0.3908 (0.4349)   Prec@1 62.500 (86.128)   Prec@5 62.500 (86.128)   [2018-03-23 05:41:52]
  **Train** Prec@1 85.958 Prec@5 85.958 Error@1 14.042
  **VAL** Prec@1 95.365 Prec@5 95.365 Error@1 4.635

==>>[2018-03-23 05:43:29] [Epoch=131/250] [Need: 08:46:06] [learning_rate=0.0020] [Best : Accuracy=95.79, Error=4.21]

==>>Epoch=[131/250]], [2018-03-23 05:43:29], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [131][000/505]   Time 0.468 (0.468)   Data 0.075 (0.075)   Loss 0.2257 (0.2257)   Prec@1 87.500 (87.500)   Prec@5 87.500 (87.500)   [2018-03-23 05:43:30]
  Epoch: [131][200/505]   Time 0.468 (0.475)   Data 0.076 (0.081)   Loss 0.6269 (0.4627)   Prec@1 75.000 (84.826)   Prec@5 75.000 (84.826)   [2018-03-23 05:45:05]
  Epoch: [131][400/505]   Time 0.454 (0.477)   Data 0.061 (0.083)   Loss 0.4516 (0.4331)   Prec@1 75.000 (85.131)   Prec@5 75.000 (85.131)   [2018-03-23 05:46:40]
  **Train** Prec@1 85.290 Prec@5 85.290 Error@1 14.710
  **VAL** Prec@1 93.118 Prec@5 93.118 Error@1 6.882

==>>[2018-03-23 05:47:52] [Epoch=132/250] [Need: 08:42:03] [learning_rate=0.0020] [Best : Accuracy=95.79, Error=4.21]

==>>Epoch=[132/250]], [2018-03-23 05:47:52], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [132][000/505]   Time 0.436 (0.436)   Data 0.036 (0.036)   Loss 0.4825 (0.4825)   Prec@1 87.500 (87.500)   Prec@5 87.500 (87.500)   [2018-03-23 05:47:53]
  Epoch: [132][200/505]   Time 0.444 (0.481)   Data 0.053 (0.087)   Loss 0.2464 (0.4284)   Prec@1 87.500 (85.137)   Prec@5 87.500 (85.137)   [2018-03-23 05:49:29]
  Epoch: [132][400/505]   Time 0.494 (0.479)   Data 0.102 (0.085)   Loss 0.1032 (0.4161)   Prec@1 100.000 (85.692)   Prec@5 100.000 (85.692)   [2018-03-23 05:51:04]
  **Train** Prec@1 86.157 Prec@5 86.157 Error@1 13.843
  **VAL** Prec@1 92.978 Prec@5 92.978 Error@1 7.022

==>>[2018-03-23 05:52:15] [Epoch=133/250] [Need: 08:37:36] [learning_rate=0.0020] [Best : Accuracy=95.79, Error=4.21]

==>>Epoch=[133/250]], [2018-03-23 05:52:15], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [133][000/505]   Time 0.460 (0.460)   Data 0.054 (0.054)   Loss 1.0216 (1.0216)   Prec@1 62.500 (62.500)   Prec@5 62.500 (62.500)   [2018-03-23 05:52:16]
  Epoch: [133][200/505]   Time 0.631 (0.479)   Data 0.231 (0.086)   Loss 0.0848 (0.4234)   Prec@1 100.000 (85.323)   Prec@5 100.000 (85.323)   [2018-03-23 05:53:52]
  Epoch: [133][400/505]   Time 0.434 (0.479)   Data 0.041 (0.085)   Loss 0.3217 (0.4483)   Prec@1 87.500 (84.757)   Prec@5 87.500 (84.757)   [2018-03-23 05:55:27]
  **Train** Prec@1 84.943 Prec@5 84.943 Error@1 15.057
  **VAL** Prec@1 93.258 Prec@5 93.258 Error@1 6.742

==>>[2018-03-23 05:56:38] [Epoch=134/250] [Need: 08:33:08] [learning_rate=0.0020] [Best : Accuracy=95.79, Error=4.21]

==>>Epoch=[134/250]], [2018-03-23 05:56:38], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [134][000/505]   Time 0.449 (0.449)   Data 0.047 (0.047)   Loss 0.3551 (0.3551)   Prec@1 75.000 (75.000)   Prec@5 75.000 (75.000)   [2018-03-23 05:56:39]
  Epoch: [134][200/505]   Time 0.427 (0.480)   Data 0.037 (0.086)   Loss 0.3588 (0.4103)   Prec@1 75.000 (85.075)   Prec@5 75.000 (85.075)   [2018-03-23 05:58:15]
  Epoch: [134][400/505]   Time 0.485 (0.479)   Data 0.093 (0.085)   Loss 0.1657 (0.4105)   Prec@1 100.000 (85.006)   Prec@5 100.000 (85.006)   [2018-03-23 05:59:51]
  **Train** Prec@1 85.463 Prec@5 85.463 Error@1 14.537
  **VAL** Prec@1 94.944 Prec@5 94.944 Error@1 5.056

==>>[2018-03-23 06:01:01] [Epoch=135/250] [Need: 08:28:40] [learning_rate=0.0020] [Best : Accuracy=95.79, Error=4.21]

==>>Epoch=[135/250]], [2018-03-23 06:01:01], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [135][000/505]   Time 0.498 (0.498)   Data 0.098 (0.098)   Loss 0.2484 (0.2484)   Prec@1 87.500 (87.500)   Prec@5 87.500 (87.500)   [2018-03-23 06:01:02]
  Epoch: [135][200/505]   Time 0.491 (0.483)   Data 0.096 (0.089)   Loss 0.2306 (0.3753)   Prec@1 87.500 (87.935)   Prec@5 87.500 (87.935)   [2018-03-23 06:02:38]
  Epoch: [135][400/505]   Time 0.506 (0.479)   Data 0.116 (0.085)   Loss 0.3249 (0.4135)   Prec@1 87.500 (86.315)   Prec@5 87.500 (86.315)   [2018-03-23 06:04:13]
  **Train** Prec@1 86.379 Prec@5 86.379 Error@1 13.621
  **VAL** Prec@1 93.258 Prec@5 93.258 Error@1 6.742

==>>[2018-03-23 06:05:24] [Epoch=136/250] [Need: 08:24:13] [learning_rate=0.0020] [Best : Accuracy=95.79, Error=4.21]

==>>Epoch=[136/250]], [2018-03-23 06:05:24], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [136][000/505]   Time 0.497 (0.497)   Data 0.091 (0.091)   Loss 0.0887 (0.0887)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-03-23 06:05:25]
  Epoch: [136][200/505]   Time 0.466 (0.474)   Data 0.076 (0.080)   Loss 0.1118 (0.4014)   Prec@1 100.000 (87.500)   Prec@5 100.000 (87.500)   [2018-03-23 06:07:00]
  Epoch: [136][400/505]   Time 0.439 (0.476)   Data 0.045 (0.082)   Loss 0.2123 (0.3990)   Prec@1 100.000 (87.219)   Prec@5 100.000 (87.219)   [2018-03-23 06:08:35]
  **Train** Prec@1 87.147 Prec@5 87.147 Error@1 12.853
  **VAL** Prec@1 94.944 Prec@5 94.944 Error@1 5.056

==>>[2018-03-23 06:09:48] [Epoch=137/250] [Need: 08:19:46] [learning_rate=0.0020] [Best : Accuracy=95.79, Error=4.21]

==>>Epoch=[137/250]], [2018-03-23 06:09:48], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [137][000/505]   Time 0.455 (0.455)   Data 0.053 (0.053)   Loss 0.2573 (0.2573)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-03-23 06:09:48]
  Epoch: [137][200/505]   Time 0.465 (0.482)   Data 0.075 (0.088)   Loss 1.6307 (0.4451)   Prec@1 75.000 (85.883)   Prec@5 75.000 (85.883)   [2018-03-23 06:11:24]
  Epoch: [137][400/505]   Time 0.455 (0.479)   Data 0.061 (0.085)   Loss 0.6125 (0.4202)   Prec@1 87.500 (86.502)   Prec@5 87.500 (86.502)   [2018-03-23 06:13:00]
  **Train** Prec@1 86.528 Prec@5 86.528 Error@1 13.472
  **VAL** Prec@1 93.680 Prec@5 93.680 Error@1 6.320

==>>[2018-03-23 06:14:11] [Epoch=138/250] [Need: 08:15:19] [learning_rate=0.0020] [Best : Accuracy=95.79, Error=4.21]

==>>Epoch=[138/250]], [2018-03-23 06:14:11], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [138][000/505]   Time 0.559 (0.559)   Data 0.158 (0.158)   Loss 0.6130 (0.6130)   Prec@1 87.500 (87.500)   Prec@5 87.500 (87.500)   [2018-03-23 06:14:11]
  Epoch: [138][200/505]   Time 0.441 (0.490)   Data 0.049 (0.087)   Loss 0.5597 (0.4065)   Prec@1 87.500 (87.500)   Prec@5 87.500 (87.500)   [2018-03-23 06:15:49]
  Epoch: [138][400/505]   Time 0.476 (0.493)   Data 0.049 (0.087)   Loss 0.1768 (0.4286)   Prec@1 100.000 (86.066)   Prec@5 100.000 (86.066)   [2018-03-23 06:17:28]
  **Train** Prec@1 85.884 Prec@5 85.884 Error@1 14.116
  **VAL** Prec@1 93.820 Prec@5 93.820 Error@1 6.180

==>>[2018-03-23 06:18:39] [Epoch=139/250] [Need: 08:10:56] [learning_rate=0.0020] [Best : Accuracy=95.79, Error=4.21]

==>>Epoch=[139/250]], [2018-03-23 06:18:39], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [139][000/505]   Time 0.496 (0.496)   Data 0.079 (0.079)   Loss 0.1521 (0.1521)   Prec@1 87.500 (87.500)   Prec@5 87.500 (87.500)   [2018-03-23 06:18:40]
  Epoch: [139][200/505]   Time 0.450 (0.479)   Data 0.047 (0.083)   Loss 1.6121 (0.4678)   Prec@1 50.000 (84.391)   Prec@5 50.000 (84.391)   [2018-03-23 06:20:16]
  Epoch: [139][400/505]   Time 0.481 (0.478)   Data 0.090 (0.083)   Loss 0.8439 (0.4631)   Prec@1 62.500 (84.726)   Prec@5 62.500 (84.726)   [2018-03-23 06:21:51]
  **Train** Prec@1 85.042 Prec@5 85.042 Error@1 14.958
  **VAL** Prec@1 94.663 Prec@5 94.663 Error@1 5.337

==>>[2018-03-23 06:23:03] [Epoch=140/250] [Need: 08:06:29] [learning_rate=0.0020] [Best : Accuracy=95.79, Error=4.21]

==>>Epoch=[140/250]], [2018-03-23 06:23:03], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [140][000/505]   Time 0.454 (0.454)   Data 0.044 (0.044)   Loss 0.8150 (0.8150)   Prec@1 87.500 (87.500)   Prec@5 87.500 (87.500)   [2018-03-23 06:23:03]
  Epoch: [140][200/505]   Time 0.461 (0.482)   Data 0.067 (0.086)   Loss 0.2553 (0.3946)   Prec@1 100.000 (87.562)   Prec@5 100.000 (87.562)   [2018-03-23 06:24:40]
  Epoch: [140][400/505]   Time 0.518 (0.481)   Data 0.123 (0.086)   Loss 0.0250 (0.4151)   Prec@1 100.000 (86.502)   Prec@5 100.000 (86.502)   [2018-03-23 06:26:16]
  **Train** Prec@1 86.454 Prec@5 86.454 Error@1 13.546
  **VAL** Prec@1 94.101 Prec@5 94.101 Error@1 5.899

==>>[2018-03-23 06:27:26] [Epoch=141/250] [Need: 08:02:02] [learning_rate=0.0020] [Best : Accuracy=95.79, Error=4.21]

==>>Epoch=[141/250]], [2018-03-23 06:27:26], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [141][000/505]   Time 0.536 (0.536)   Data 0.111 (0.111)   Loss 0.1837 (0.1837)   Prec@1 87.500 (87.500)   Prec@5 87.500 (87.500)   [2018-03-23 06:27:27]
  Epoch: [141][200/505]   Time 0.548 (0.480)   Data 0.161 (0.084)   Loss 0.1526 (0.3918)   Prec@1 100.000 (86.070)   Prec@5 100.000 (86.070)   [2018-03-23 06:29:03]
  Epoch: [141][400/505]   Time 0.499 (0.479)   Data 0.105 (0.084)   Loss 0.0184 (0.3863)   Prec@1 100.000 (86.627)   Prec@5 100.000 (86.627)   [2018-03-23 06:30:39]
  **Train** Prec@1 86.454 Prec@5 86.454 Error@1 13.546
  **VAL** Prec@1 94.944 Prec@5 94.944 Error@1 5.056

==>>[2018-03-23 06:31:50] [Epoch=142/250] [Need: 07:57:36] [learning_rate=0.0020] [Best : Accuracy=95.79, Error=4.21]

==>>Epoch=[142/250]], [2018-03-23 06:31:50], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [142][000/505]   Time 0.545 (0.545)   Data 0.112 (0.112)   Loss 0.3459 (0.3459)   Prec@1 87.500 (87.500)   Prec@5 87.500 (87.500)   [2018-03-23 06:31:51]
  Epoch: [142][200/505]   Time 0.455 (0.482)   Data 0.061 (0.086)   Loss 0.3142 (0.3581)   Prec@1 87.500 (87.998)   Prec@5 87.500 (87.998)   [2018-03-23 06:33:27]
  Epoch: [142][400/505]   Time 0.481 (0.480)   Data 0.086 (0.085)   Loss 0.4020 (0.4016)   Prec@1 87.500 (86.908)   Prec@5 87.500 (86.908)   [2018-03-23 06:35:02]
  **Train** Prec@1 86.875 Prec@5 86.875 Error@1 13.125
  **VAL** Prec@1 93.539 Prec@5 93.539 Error@1 6.461

==>>[2018-03-23 06:36:14] [Epoch=143/250] [Need: 07:53:09] [learning_rate=0.0020] [Best : Accuracy=95.79, Error=4.21]

==>>Epoch=[143/250]], [2018-03-23 06:36:14], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [143][000/505]   Time 0.756 (0.756)   Data 0.341 (0.341)   Loss 0.2174 (0.2174)   Prec@1 87.500 (87.500)   Prec@5 87.500 (87.500)   [2018-03-23 06:36:14]
  Epoch: [143][200/505]   Time 0.496 (0.484)   Data 0.076 (0.088)   Loss 1.3675 (0.4158)   Prec@1 62.500 (85.883)   Prec@5 62.500 (85.883)   [2018-03-23 06:37:51]
  Epoch: [143][400/505]   Time 0.482 (0.479)   Data 0.069 (0.085)   Loss 0.6861 (0.4047)   Prec@1 75.000 (86.596)   Prec@5 75.000 (86.596)   [2018-03-23 06:39:26]
  **Train** Prec@1 86.478 Prec@5 86.478 Error@1 13.522
  **VAL** Prec@1 93.680 Prec@5 93.680 Error@1 6.320

==>>[2018-03-23 06:40:37] [Epoch=144/250] [Need: 07:48:42] [learning_rate=0.0020] [Best : Accuracy=95.79, Error=4.21]

==>>Epoch=[144/250]], [2018-03-23 06:40:37], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [144][000/505]   Time 0.480 (0.480)   Data 0.065 (0.065)   Loss 0.0628 (0.0628)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-03-23 06:40:38]
  Epoch: [144][200/505]   Time 0.570 (0.482)   Data 0.170 (0.087)   Loss 0.7844 (0.4114)   Prec@1 62.500 (87.376)   Prec@5 62.500 (87.376)   [2018-03-23 06:42:14]
  Epoch: [144][400/505]   Time 0.485 (0.481)   Data 0.093 (0.086)   Loss 0.5036 (0.4114)   Prec@1 75.000 (87.032)   Prec@5 75.000 (87.032)   [2018-03-23 06:43:50]
  **Train** Prec@1 86.850 Prec@5 86.850 Error@1 13.150
  **VAL** Prec@1 95.225 Prec@5 95.225 Error@1 4.775

==>>[2018-03-23 06:45:27] [Epoch=145/250] [Need: 07:44:16] [learning_rate=0.0020] [Best : Accuracy=95.79, Error=4.21]

==>>Epoch=[145/250]], [2018-03-23 06:45:27], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [145][000/505]   Time 0.533 (0.533)   Data 0.125 (0.125)   Loss 0.2137 (0.2137)   Prec@1 87.500 (87.500)   Prec@5 87.500 (87.500)   [2018-03-23 06:45:28]
  Epoch: [145][200/505]   Time 0.468 (0.479)   Data 0.074 (0.084)   Loss 0.2191 (0.3496)   Prec@1 100.000 (88.122)   Prec@5 100.000 (88.122)   [2018-03-23 06:47:04]
  Epoch: [145][400/505]   Time 0.441 (0.480)   Data 0.047 (0.085)   Loss 0.2568 (0.3759)   Prec@1 87.500 (87.064)   Prec@5 87.500 (87.064)   [2018-03-23 06:48:40]
  **Train** Prec@1 87.246 Prec@5 87.246 Error@1 12.754
  **VAL** Prec@1 94.803 Prec@5 94.803 Error@1 5.197

==>>[2018-03-23 06:49:51] [Epoch=146/250] [Need: 07:40:08] [learning_rate=0.0020] [Best : Accuracy=95.79, Error=4.21]

==>>Epoch=[146/250]], [2018-03-23 06:49:51], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [146][000/505]   Time 0.481 (0.481)   Data 0.063 (0.063)   Loss 0.2862 (0.2862)   Prec@1 87.500 (87.500)   Prec@5 87.500 (87.500)   [2018-03-23 06:49:51]
  Epoch: [146][200/505]   Time 0.496 (0.479)   Data 0.099 (0.084)   Loss 0.7352 (0.4233)   Prec@1 87.500 (86.692)   Prec@5 87.500 (86.692)   [2018-03-23 06:51:27]
  Epoch: [146][400/505]   Time 0.444 (0.478)   Data 0.049 (0.083)   Loss 0.3425 (0.4463)   Prec@1 87.500 (85.536)   Prec@5 87.500 (85.536)   [2018-03-23 06:53:02]
  **Train** Prec@1 86.057 Prec@5 86.057 Error@1 13.943
  **VAL** Prec@1 95.927 Prec@5 95.927 Error@1 4.073

==>>[2018-03-23 06:54:41] [Epoch=147/250] [Need: 07:35:41] [learning_rate=0.0020] [Best : Accuracy=95.93, Error=4.07]

==>>Epoch=[147/250]], [2018-03-23 06:54:41], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [147][000/505]   Time 0.505 (0.505)   Data 0.105 (0.105)   Loss 0.1223 (0.1223)   Prec@1 87.500 (87.500)   Prec@5 87.500 (87.500)   [2018-03-23 06:54:41]
  Epoch: [147][200/505]   Time 0.448 (0.480)   Data 0.058 (0.086)   Loss 0.2423 (0.4179)   Prec@1 87.500 (86.007)   Prec@5 87.500 (86.007)   [2018-03-23 06:56:17]
  Epoch: [147][400/505]   Time 0.464 (0.480)   Data 0.073 (0.086)   Loss 0.0796 (0.4191)   Prec@1 100.000 (85.661)   Prec@5 100.000 (85.661)   [2018-03-23 06:57:53]
  **Train** Prec@1 85.736 Prec@5 85.736 Error@1 14.264
  **VAL** Prec@1 93.399 Prec@5 93.399 Error@1 6.601

==>>[2018-03-23 06:59:04] [Epoch=148/250] [Need: 07:31:33] [learning_rate=0.0020] [Best : Accuracy=95.93, Error=4.07]

==>>Epoch=[148/250]], [2018-03-23 06:59:04], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [148][000/505]   Time 0.479 (0.479)   Data 0.059 (0.059)   Loss 0.5710 (0.5710)   Prec@1 87.500 (87.500)   Prec@5 87.500 (87.500)   [2018-03-23 06:59:05]
  Epoch: [148][200/505]   Time 0.504 (0.479)   Data 0.114 (0.084)   Loss 0.7241 (0.3657)   Prec@1 75.000 (87.873)   Prec@5 75.000 (87.873)   [2018-03-23 07:00:40]
  Epoch: [148][400/505]   Time 0.652 (0.479)   Data 0.245 (0.085)   Loss 0.4189 (0.4180)   Prec@1 87.500 (86.845)   Prec@5 87.500 (86.845)   [2018-03-23 07:02:16]
  **Train** Prec@1 86.503 Prec@5 86.503 Error@1 13.497
  **VAL** Prec@1 95.506 Prec@5 95.506 Error@1 4.494

==>>[2018-03-23 07:03:54] [Epoch=149/250] [Need: 07:27:06] [learning_rate=0.0020] [Best : Accuracy=95.93, Error=4.07]

==>>Epoch=[149/250]], [2018-03-23 07:03:54], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [149][000/505]   Time 0.468 (0.468)   Data 0.063 (0.063)   Loss 0.1225 (0.1225)   Prec@1 87.500 (87.500)   Prec@5 87.500 (87.500)   [2018-03-23 07:03:55]
  Epoch: [149][200/505]   Time 0.428 (0.481)   Data 0.031 (0.087)   Loss 0.1324 (0.3970)   Prec@1 100.000 (87.065)   Prec@5 100.000 (87.065)   [2018-03-23 07:05:31]
  Epoch: [149][400/505]   Time 0.461 (0.480)   Data 0.065 (0.085)   Loss 0.7484 (0.4019)   Prec@1 75.000 (87.001)   Prec@5 75.000 (87.001)   [2018-03-23 07:07:07]
  **Train** Prec@1 87.172 Prec@5 87.172 Error@1 12.828
  **VAL** Prec@1 95.225 Prec@5 95.225 Error@1 4.775

==>>[2018-03-23 07:08:44] [Epoch=150/250] [Need: 07:22:56] [learning_rate=0.0002] [Best : Accuracy=95.93, Error=4.07]

==>>Epoch=[150/250]], [2018-03-23 07:08:44], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [150][000/505]   Time 0.512 (0.512)   Data 0.100 (0.100)   Loss 0.2536 (0.2536)   Prec@1 87.500 (87.500)   Prec@5 87.500 (87.500)   [2018-03-23 07:08:45]
  Epoch: [150][200/505]   Time 0.452 (0.480)   Data 0.060 (0.085)   Loss 0.6965 (0.3616)   Prec@1 87.500 (88.868)   Prec@5 87.500 (88.868)   [2018-03-23 07:10:21]
  Epoch: [150][400/505]   Time 0.450 (0.477)   Data 0.054 (0.083)   Loss 0.5809 (0.3483)   Prec@1 87.500 (88.747)   Prec@5 87.500 (88.747)   [2018-03-23 07:11:56]
  **Train** Prec@1 88.435 Prec@5 88.435 Error@1 11.565
  **VAL** Prec@1 95.787 Prec@5 95.787 Error@1 4.213

==>>[2018-03-23 07:13:34] [Epoch=151/250] [Need: 07:18:46] [learning_rate=0.0002] [Best : Accuracy=95.93, Error=4.07]

==>>Epoch=[151/250]], [2018-03-23 07:13:34], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [151][000/505]   Time 0.446 (0.446)   Data 0.045 (0.045)   Loss 0.2993 (0.2993)   Prec@1 87.500 (87.500)   Prec@5 87.500 (87.500)   [2018-03-23 07:13:35]
  Epoch: [151][200/505]   Time 0.441 (0.478)   Data 0.050 (0.083)   Loss 0.1283 (0.3417)   Prec@1 100.000 (88.806)   Prec@5 100.000 (88.806)   [2018-03-23 07:15:11]
  Epoch: [151][400/505]   Time 0.507 (0.479)   Data 0.109 (0.085)   Loss 0.7460 (0.3372)   Prec@1 62.500 (88.965)   Prec@5 62.500 (88.965)   [2018-03-23 07:16:47]
  **Train** Prec@1 88.856 Prec@5 88.856 Error@1 11.144
  **VAL** Prec@1 96.208 Prec@5 96.208 Error@1 3.792

==>>[2018-03-23 07:18:25] [Epoch=152/250] [Need: 07:14:36] [learning_rate=0.0002] [Best : Accuracy=96.21, Error=3.79]

==>>Epoch=[152/250]], [2018-03-23 07:18:25], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [152][000/505]   Time 0.444 (0.444)   Data 0.043 (0.043)   Loss 0.0486 (0.0486)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-03-23 07:18:25]
  Epoch: [152][200/505]   Time 0.438 (0.482)   Data 0.046 (0.087)   Loss 0.4122 (0.2977)   Prec@1 87.500 (90.609)   Prec@5 87.500 (90.609)   [2018-03-23 07:20:02]
  Epoch: [152][400/505]   Time 0.486 (0.480)   Data 0.092 (0.085)   Loss 0.1163 (0.2981)   Prec@1 100.000 (90.274)   Prec@5 100.000 (90.274)   [2018-03-23 07:21:37]
  **Train** Prec@1 89.871 Prec@5 89.871 Error@1 10.129
  **VAL** Prec@1 95.927 Prec@5 95.927 Error@1 4.073

==>>[2018-03-23 07:23:15] [Epoch=153/250] [Need: 07:10:25] [learning_rate=0.0002] [Best : Accuracy=96.21, Error=3.79]

==>>Epoch=[153/250]], [2018-03-23 07:23:15], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [153][000/505]   Time 0.502 (0.502)   Data 0.087 (0.087)   Loss 0.1386 (0.1386)   Prec@1 87.500 (87.500)   Prec@5 87.500 (87.500)   [2018-03-23 07:23:15]
  Epoch: [153][200/505]   Time 0.499 (0.477)   Data 0.108 (0.082)   Loss 0.2648 (0.3003)   Prec@1 87.500 (90.050)   Prec@5 87.500 (90.050)   [2018-03-23 07:24:51]
  Epoch: [153][400/505]   Time 0.449 (0.480)   Data 0.056 (0.085)   Loss 0.2836 (0.3236)   Prec@1 87.500 (89.433)   Prec@5 87.500 (89.433)   [2018-03-23 07:26:27]
  **Train** Prec@1 89.425 Prec@5 89.425 Error@1 10.575
  **VAL** Prec@1 96.208 Prec@5 96.208 Error@1 3.792

==>>[2018-03-23 07:28:05] [Epoch=154/250] [Need: 07:06:14] [learning_rate=0.0002] [Best : Accuracy=96.21, Error=3.79]

==>>Epoch=[154/250]], [2018-03-23 07:28:05], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [154][000/505]   Time 0.457 (0.457)   Data 0.054 (0.054)   Loss 0.2362 (0.2362)   Prec@1 87.500 (87.500)   Prec@5 87.500 (87.500)   [2018-03-23 07:28:05]
  Epoch: [154][200/505]   Time 0.464 (0.481)   Data 0.067 (0.086)   Loss 0.0296 (0.2987)   Prec@1 100.000 (89.863)   Prec@5 100.000 (89.863)   [2018-03-23 07:29:41]
  Epoch: [154][400/505]   Time 0.447 (0.478)   Data 0.055 (0.083)   Loss 0.4534 (0.3009)   Prec@1 87.500 (90.025)   Prec@5 87.500 (90.025)   [2018-03-23 07:31:16]
  **Train** Prec@1 89.747 Prec@5 89.747 Error@1 10.253
  **VAL** Prec@1 96.067 Prec@5 96.067 Error@1 3.933

==>>[2018-03-23 07:32:55] [Epoch=155/250] [Need: 07:02:02] [learning_rate=0.0002] [Best : Accuracy=96.21, Error=3.79]

==>>Epoch=[155/250]], [2018-03-23 07:32:55], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [155][000/505]   Time 0.478 (0.478)   Data 0.068 (0.068)   Loss 0.1017 (0.1017)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-03-23 07:32:55]
  Epoch: [155][200/505]   Time 0.515 (0.476)   Data 0.124 (0.081)   Loss 0.4584 (0.2950)   Prec@1 87.500 (90.361)   Prec@5 87.500 (90.361)   [2018-03-23 07:34:30]
  Epoch: [155][400/505]   Time 0.475 (0.478)   Data 0.081 (0.084)   Loss 0.0892 (0.3131)   Prec@1 100.000 (89.495)   Prec@5 100.000 (89.495)   [2018-03-23 07:36:07]
  **Train** Prec@1 89.277 Prec@5 89.277 Error@1 10.723
  **VAL** Prec@1 95.927 Prec@5 95.927 Error@1 4.073

==>>[2018-03-23 07:37:45] [Epoch=156/250] [Need: 06:57:49] [learning_rate=0.0002] [Best : Accuracy=96.21, Error=3.79]

==>>Epoch=[156/250]], [2018-03-23 07:37:45], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [156][000/505]   Time 0.460 (0.460)   Data 0.058 (0.058)   Loss 0.4449 (0.4449)   Prec@1 62.500 (62.500)   Prec@5 62.500 (62.500)   [2018-03-23 07:37:45]
  Epoch: [156][200/505]   Time 0.655 (0.475)   Data 0.253 (0.080)   Loss 0.4610 (0.2819)   Prec@1 87.500 (90.174)   Prec@5 87.500 (90.174)   [2018-03-23 07:39:20]
  Epoch: [156][400/505]   Time 0.509 (0.480)   Data 0.117 (0.085)   Loss 0.2941 (0.3034)   Prec@1 87.500 (89.651)   Prec@5 87.500 (89.651)   [2018-03-23 07:40:57]
  **Train** Prec@1 89.227 Prec@5 89.227 Error@1 10.773
  **VAL** Prec@1 96.348 Prec@5 96.348 Error@1 3.652

==>>[2018-03-23 07:42:35] [Epoch=157/250] [Need: 06:53:37] [learning_rate=0.0002] [Best : Accuracy=96.35, Error=3.65]

==>>Epoch=[157/250]], [2018-03-23 07:42:35], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [157][000/505]   Time 0.452 (0.452)   Data 0.046 (0.046)   Loss 0.4832 (0.4832)   Prec@1 87.500 (87.500)   Prec@5 87.500 (87.500)   [2018-03-23 07:42:36]
  Epoch: [157][200/505]   Time 0.464 (0.479)   Data 0.071 (0.084)   Loss 0.0610 (0.3003)   Prec@1 100.000 (91.294)   Prec@5 100.000 (91.294)   [2018-03-23 07:44:11]
  Epoch: [157][400/505]   Time 0.509 (0.481)   Data 0.110 (0.086)   Loss 0.1369 (0.3074)   Prec@1 100.000 (90.368)   Prec@5 100.000 (90.368)   [2018-03-23 07:45:48]
  **Train** Prec@1 90.193 Prec@5 90.193 Error@1 9.807
  **VAL** Prec@1 95.646 Prec@5 95.646 Error@1 4.354

==>>[2018-03-23 07:47:25] [Epoch=158/250] [Need: 06:49:24] [learning_rate=0.0002] [Best : Accuracy=96.35, Error=3.65]

==>>Epoch=[158/250]], [2018-03-23 07:47:25], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [158][000/505]   Time 0.480 (0.480)   Data 0.076 (0.076)   Loss 0.2107 (0.2107)   Prec@1 87.500 (87.500)   Prec@5 87.500 (87.500)   [2018-03-23 07:47:26]
  Epoch: [158][200/505]   Time 0.438 (0.482)   Data 0.045 (0.087)   Loss 0.5444 (0.3313)   Prec@1 87.500 (89.366)   Prec@5 87.500 (89.366)   [2018-03-23 07:49:02]
  Epoch: [158][400/505]   Time 0.450 (0.480)   Data 0.055 (0.086)   Loss 0.5907 (0.3203)   Prec@1 62.500 (89.589)   Prec@5 62.500 (89.589)   [2018-03-23 07:50:38]
  **Train** Prec@1 89.599 Prec@5 89.599 Error@1 10.401
  **VAL** Prec@1 96.208 Prec@5 96.208 Error@1 3.792

==>>[2018-03-23 07:52:16] [Epoch=159/250] [Need: 06:45:10] [learning_rate=0.0002] [Best : Accuracy=96.35, Error=3.65]

==>>Epoch=[159/250]], [2018-03-23 07:52:16], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [159][000/505]   Time 0.453 (0.453)   Data 0.054 (0.054)   Loss 0.2796 (0.2796)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-03-23 07:52:16]
  Epoch: [159][200/505]   Time 0.450 (0.479)   Data 0.058 (0.084)   Loss 0.3384 (0.3129)   Prec@1 87.500 (89.614)   Prec@5 87.500 (89.614)   [2018-03-23 07:53:52]
  Epoch: [159][400/505]   Time 0.486 (0.480)   Data 0.094 (0.085)   Loss 0.3263 (0.3048)   Prec@1 87.500 (90.056)   Prec@5 87.500 (90.056)   [2018-03-23 07:55:28]
  **Train** Prec@1 90.119 Prec@5 90.119 Error@1 9.881
  **VAL** Prec@1 96.208 Prec@5 96.208 Error@1 3.792

==>>[2018-03-23 07:57:06] [Epoch=160/250] [Need: 06:40:56] [learning_rate=0.0002] [Best : Accuracy=96.35, Error=3.65]

==>>Epoch=[160/250]], [2018-03-23 07:57:06], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [160][000/505]   Time 0.476 (0.476)   Data 0.071 (0.071)   Loss 0.0412 (0.0412)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-03-23 07:57:06]
  Epoch: [160][200/505]   Time 0.502 (0.484)   Data 0.109 (0.089)   Loss 0.4650 (0.3144)   Prec@1 75.000 (89.490)   Prec@5 75.000 (89.490)   [2018-03-23 07:58:43]
  Epoch: [160][400/505]   Time 0.482 (0.480)   Data 0.092 (0.085)   Loss 0.0576 (0.3042)   Prec@1 100.000 (89.931)   Prec@5 100.000 (89.931)   [2018-03-23 08:00:18]
  **Train** Prec@1 90.168 Prec@5 90.168 Error@1 9.832
  **VAL** Prec@1 95.787 Prec@5 95.787 Error@1 4.213

==>>[2018-03-23 08:01:56] [Epoch=161/250] [Need: 06:36:41] [learning_rate=0.0002] [Best : Accuracy=96.35, Error=3.65]

==>>Epoch=[161/250]], [2018-03-23 08:01:56], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [161][000/505]   Time 0.531 (0.531)   Data 0.109 (0.109)   Loss 0.2749 (0.2749)   Prec@1 87.500 (87.500)   Prec@5 87.500 (87.500)   [2018-03-23 08:01:56]
  Epoch: [161][200/505]   Time 0.460 (0.477)   Data 0.068 (0.082)   Loss 0.5872 (0.3117)   Prec@1 75.000 (89.552)   Prec@5 75.000 (89.552)   [2018-03-23 08:03:32]
  Epoch: [161][400/505]   Time 0.512 (0.481)   Data 0.115 (0.086)   Loss 0.0859 (0.3077)   Prec@1 100.000 (89.900)   Prec@5 100.000 (89.900)   [2018-03-23 08:05:09]
  **Train** Prec@1 90.069 Prec@5 90.069 Error@1 9.931
  **VAL** Prec@1 95.927 Prec@5 95.927 Error@1 4.073

==>>[2018-03-23 08:06:46] [Epoch=162/250] [Need: 06:32:26] [learning_rate=0.0002] [Best : Accuracy=96.35, Error=3.65]

==>>Epoch=[162/250]], [2018-03-23 08:06:46], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [162][000/505]   Time 0.458 (0.458)   Data 0.058 (0.058)   Loss 0.2841 (0.2841)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-03-23 08:06:47]
  Epoch: [162][200/505]   Time 0.476 (0.482)   Data 0.078 (0.087)   Loss 0.0818 (0.2844)   Prec@1 100.000 (90.734)   Prec@5 100.000 (90.734)   [2018-03-23 08:08:23]
  Epoch: [162][400/505]   Time 0.551 (0.482)   Data 0.157 (0.087)   Loss 0.0239 (0.2969)   Prec@1 100.000 (90.212)   Prec@5 100.000 (90.212)   [2018-03-23 08:10:00]
  **Train** Prec@1 89.946 Prec@5 89.946 Error@1 10.054
  **VAL** Prec@1 95.927 Prec@5 95.927 Error@1 4.073

==>>[2018-03-23 08:11:36] [Epoch=163/250] [Need: 06:28:11] [learning_rate=0.0002] [Best : Accuracy=96.35, Error=3.65]

==>>Epoch=[163/250]], [2018-03-23 08:11:36], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [163][000/505]   Time 0.532 (0.532)   Data 0.110 (0.110)   Loss 0.1822 (0.1822)   Prec@1 87.500 (87.500)   Prec@5 87.500 (87.500)   [2018-03-23 08:11:37]
  Epoch: [163][200/505]   Time 0.457 (0.483)   Data 0.063 (0.088)   Loss 0.2961 (0.2908)   Prec@1 87.500 (90.609)   Prec@5 87.500 (90.609)   [2018-03-23 08:13:14]
  Epoch: [163][400/505]   Time 0.446 (0.480)   Data 0.039 (0.086)   Loss 0.2879 (0.3011)   Prec@1 87.500 (89.900)   Prec@5 87.500 (89.900)   [2018-03-23 08:14:49]
  **Train** Prec@1 90.218 Prec@5 90.218 Error@1 9.782
  **VAL** Prec@1 96.348 Prec@5 96.348 Error@1 3.652

==>>[2018-03-23 08:16:27] [Epoch=164/250] [Need: 06:23:55] [learning_rate=0.0002] [Best : Accuracy=96.35, Error=3.65]

==>>Epoch=[164/250]], [2018-03-23 08:16:27], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [164][000/505]   Time 0.446 (0.446)   Data 0.047 (0.047)   Loss 0.6115 (0.6115)   Prec@1 75.000 (75.000)   Prec@5 75.000 (75.000)   [2018-03-23 08:16:27]
  Epoch: [164][200/505]   Time 0.476 (0.485)   Data 0.081 (0.090)   Loss 0.0300 (0.3016)   Prec@1 100.000 (90.547)   Prec@5 100.000 (90.547)   [2018-03-23 08:18:04]
  Epoch: [164][400/505]   Time 0.453 (0.480)   Data 0.059 (0.085)   Loss 0.1529 (0.2889)   Prec@1 100.000 (90.586)   Prec@5 100.000 (90.586)   [2018-03-23 08:19:39]
  **Train** Prec@1 90.614 Prec@5 90.614 Error@1 9.386
  **VAL** Prec@1 96.348 Prec@5 96.348 Error@1 3.652

==>>[2018-03-23 08:21:17] [Epoch=165/250] [Need: 06:19:38] [learning_rate=0.0002] [Best : Accuracy=96.35, Error=3.65]

==>>Epoch=[165/250]], [2018-03-23 08:21:17], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [165][000/505]   Time 0.549 (0.549)   Data 0.122 (0.122)   Loss 0.3504 (0.3504)   Prec@1 87.500 (87.500)   Prec@5 87.500 (87.500)   [2018-03-23 08:21:17]
  Epoch: [165][200/505]   Time 0.578 (0.476)   Data 0.188 (0.081)   Loss 0.6427 (0.2758)   Prec@1 75.000 (91.107)   Prec@5 75.000 (91.107)   [2018-03-23 08:22:53]
  Epoch: [165][400/505]   Time 0.469 (0.480)   Data 0.075 (0.086)   Loss 0.5375 (0.2781)   Prec@1 75.000 (90.524)   Prec@5 75.000 (90.524)   [2018-03-23 08:24:29]
  **Train** Prec@1 90.515 Prec@5 90.515 Error@1 9.485
  **VAL** Prec@1 96.348 Prec@5 96.348 Error@1 3.652

==>>[2018-03-23 08:26:07] [Epoch=166/250] [Need: 06:15:21] [learning_rate=0.0002] [Best : Accuracy=96.35, Error=3.65]

==>>Epoch=[166/250]], [2018-03-23 08:26:07], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [166][000/505]   Time 0.507 (0.507)   Data 0.089 (0.089)   Loss 0.2182 (0.2182)   Prec@1 87.500 (87.500)   Prec@5 87.500 (87.500)   [2018-03-23 08:26:07]
  Epoch: [166][200/505]   Time 0.426 (0.483)   Data 0.034 (0.088)   Loss 0.1245 (0.2986)   Prec@1 100.000 (89.677)   Prec@5 100.000 (89.677)   [2018-03-23 08:27:44]
  Epoch: [166][400/505]   Time 0.439 (0.481)   Data 0.046 (0.086)   Loss 1.7043 (0.2992)   Prec@1 62.500 (89.557)   Prec@5 62.500 (89.557)   [2018-03-23 08:29:20]
  **Train** Prec@1 89.525 Prec@5 89.525 Error@1 10.475
  **VAL** Prec@1 96.348 Prec@5 96.348 Error@1 3.652

==>>[2018-03-23 08:30:57] [Epoch=167/250] [Need: 06:11:04] [learning_rate=0.0002] [Best : Accuracy=96.35, Error=3.65]

==>>Epoch=[167/250]], [2018-03-23 08:30:57], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [167][000/505]   Time 0.600 (0.600)   Data 0.176 (0.176)   Loss 0.0358 (0.0358)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-03-23 08:30:58]
  Epoch: [167][200/505]   Time 0.438 (0.480)   Data 0.047 (0.085)   Loss 0.5819 (0.2931)   Prec@1 75.000 (90.112)   Prec@5 75.000 (90.112)   [2018-03-23 08:32:34]
  Epoch: [167][400/505]   Time 0.500 (0.479)   Data 0.106 (0.084)   Loss 0.7369 (0.3122)   Prec@1 75.000 (89.401)   Prec@5 75.000 (89.401)   [2018-03-23 08:34:09]
  **Train** Prec@1 89.698 Prec@5 89.698 Error@1 10.302
  **VAL** Prec@1 96.489 Prec@5 96.489 Error@1 3.511

==>>[2018-03-23 08:35:47] [Epoch=168/250] [Need: 06:06:47] [learning_rate=0.0002] [Best : Accuracy=96.49, Error=3.51]

==>>Epoch=[168/250]], [2018-03-23 08:35:47], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [168][000/505]   Time 0.474 (0.474)   Data 0.066 (0.066)   Loss 0.0480 (0.0480)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-03-23 08:35:48]
  Epoch: [168][200/505]   Time 0.439 (0.483)   Data 0.047 (0.087)   Loss 0.3846 (0.2914)   Prec@1 87.500 (89.739)   Prec@5 87.500 (89.739)   [2018-03-23 08:37:24]
  Epoch: [168][400/505]   Time 0.471 (0.482)   Data 0.063 (0.086)   Loss 0.2197 (0.2927)   Prec@1 87.500 (89.931)   Prec@5 87.500 (89.931)   [2018-03-23 08:39:01]
  **Train** Prec@1 90.119 Prec@5 90.119 Error@1 9.881
  **VAL** Prec@1 96.629 Prec@5 96.629 Error@1 3.371

==>>[2018-03-23 08:40:38] [Epoch=169/250] [Need: 06:02:29] [learning_rate=0.0002] [Best : Accuracy=96.63, Error=3.37]

==>>Epoch=[169/250]], [2018-03-23 08:40:38], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [169][000/505]   Time 0.464 (0.464)   Data 0.063 (0.063)   Loss 0.3337 (0.3337)   Prec@1 87.500 (87.500)   Prec@5 87.500 (87.500)   [2018-03-23 08:40:38]
  Epoch: [169][200/505]   Time 0.455 (0.480)   Data 0.061 (0.084)   Loss 0.3015 (0.3015)   Prec@1 87.500 (89.988)   Prec@5 87.500 (89.988)   [2018-03-23 08:42:14]
  Epoch: [169][400/505]   Time 0.453 (0.479)   Data 0.059 (0.085)   Loss 0.2976 (0.3173)   Prec@1 87.500 (89.869)   Prec@5 87.500 (89.869)   [2018-03-23 08:43:50]
  **Train** Prec@1 90.218 Prec@5 90.218 Error@1 9.782
  **VAL** Prec@1 96.629 Prec@5 96.629 Error@1 3.371

==>>[2018-03-23 08:45:28] [Epoch=170/250] [Need: 05:58:11] [learning_rate=0.0002] [Best : Accuracy=96.63, Error=3.37]

==>>Epoch=[170/250]], [2018-03-23 08:45:28], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [170][000/505]   Time 0.583 (0.583)   Data 0.165 (0.165)   Loss 0.0654 (0.0654)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-03-23 08:45:28]
  Epoch: [170][200/505]   Time 0.445 (0.478)   Data 0.052 (0.083)   Loss 0.0812 (0.3042)   Prec@1 100.000 (90.361)   Prec@5 100.000 (90.361)   [2018-03-23 08:47:04]
  Epoch: [170][400/505]   Time 0.466 (0.479)   Data 0.075 (0.085)   Loss 0.5143 (0.2941)   Prec@1 75.000 (90.337)   Prec@5 75.000 (90.337)   [2018-03-23 08:48:40]
  **Train** Prec@1 90.292 Prec@5 90.292 Error@1 9.708
  **VAL** Prec@1 96.067 Prec@5 96.067 Error@1 3.933

==>>[2018-03-23 08:50:18] [Epoch=171/250] [Need: 05:53:52] [learning_rate=0.0002] [Best : Accuracy=96.63, Error=3.37]

==>>Epoch=[171/250]], [2018-03-23 08:50:18], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [171][000/505]   Time 0.459 (0.459)   Data 0.068 (0.068)   Loss 0.1739 (0.1739)   Prec@1 87.500 (87.500)   Prec@5 87.500 (87.500)   [2018-03-23 08:50:18]
  Epoch: [171][200/505]   Time 0.466 (0.483)   Data 0.073 (0.089)   Loss 0.3522 (0.2821)   Prec@1 75.000 (91.107)   Prec@5 75.000 (91.107)   [2018-03-23 08:51:55]
  Epoch: [171][400/505]   Time 0.455 (0.481)   Data 0.057 (0.086)   Loss 0.0149 (0.2982)   Prec@1 100.000 (90.368)   Prec@5 100.000 (90.368)   [2018-03-23 08:53:31]
  **Train** Prec@1 90.193 Prec@5 90.193 Error@1 9.807
  **VAL** Prec@1 95.927 Prec@5 95.927 Error@1 4.073

==>>[2018-03-23 08:55:08] [Epoch=172/250] [Need: 05:49:33] [learning_rate=0.0002] [Best : Accuracy=96.63, Error=3.37]

==>>Epoch=[172/250]], [2018-03-23 08:55:08], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [172][000/505]   Time 0.540 (0.540)   Data 0.116 (0.116)   Loss 0.0733 (0.0733)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-03-23 08:55:09]
  Epoch: [172][200/505]   Time 0.485 (0.478)   Data 0.079 (0.083)   Loss 0.2571 (0.2604)   Prec@1 87.500 (91.667)   Prec@5 87.500 (91.667)   [2018-03-23 08:56:44]
  Epoch: [172][400/505]   Time 0.442 (0.481)   Data 0.044 (0.086)   Loss 0.3605 (0.2948)   Prec@1 87.500 (90.337)   Prec@5 87.500 (90.337)   [2018-03-23 08:58:21]
  **Train** Prec@1 90.317 Prec@5 90.317 Error@1 9.683
  **VAL** Prec@1 96.489 Prec@5 96.489 Error@1 3.511

==>>[2018-03-23 08:59:58] [Epoch=173/250] [Need: 05:45:13] [learning_rate=0.0002] [Best : Accuracy=96.63, Error=3.37]

==>>Epoch=[173/250]], [2018-03-23 08:59:58], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [173][000/505]   Time 0.504 (0.504)   Data 0.101 (0.101)   Loss 0.0077 (0.0077)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-03-23 08:59:59]
  Epoch: [173][200/505]   Time 0.494 (0.479)   Data 0.103 (0.084)   Loss 0.2381 (0.3166)   Prec@1 87.500 (89.241)   Prec@5 87.500 (89.241)   [2018-03-23 09:01:35]
  Epoch: [173][400/505]   Time 0.442 (0.481)   Data 0.047 (0.086)   Loss 0.5002 (0.3088)   Prec@1 87.500 (89.651)   Prec@5 87.500 (89.651)   [2018-03-23 09:03:11]
  **Train** Prec@1 90.144 Prec@5 90.144 Error@1 9.856
  **VAL** Prec@1 96.208 Prec@5 96.208 Error@1 3.792

==>>[2018-03-23 09:04:48] [Epoch=174/250] [Need: 05:40:54] [learning_rate=0.0002] [Best : Accuracy=96.63, Error=3.37]

==>>Epoch=[174/250]], [2018-03-23 09:04:48], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [174][000/505]   Time 0.479 (0.479)   Data 0.068 (0.068)   Loss 0.1630 (0.1630)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-03-23 09:04:49]
  Epoch: [174][200/505]   Time 0.497 (0.479)   Data 0.104 (0.084)   Loss 0.1043 (0.2689)   Prec@1 100.000 (91.107)   Prec@5 100.000 (91.107)   [2018-03-23 09:06:25]
  Epoch: [174][400/505]   Time 0.449 (0.480)   Data 0.057 (0.086)   Loss 0.5149 (0.2719)   Prec@1 62.500 (90.898)   Prec@5 62.500 (90.898)   [2018-03-23 09:08:01]
  **Train** Prec@1 90.317 Prec@5 90.317 Error@1 9.683
  **VAL** Prec@1 96.489 Prec@5 96.489 Error@1 3.511

==>>[2018-03-23 09:09:39] [Epoch=175/250] [Need: 05:36:33] [learning_rate=0.0002] [Best : Accuracy=96.63, Error=3.37]

==>>Epoch=[175/250]], [2018-03-23 09:09:39], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [175][000/505]   Time 0.480 (0.480)   Data 0.075 (0.075)   Loss 0.1886 (0.1886)   Prec@1 87.500 (87.500)   Prec@5 87.500 (87.500)   [2018-03-23 09:09:39]
  Epoch: [175][200/505]   Time 0.442 (0.484)   Data 0.049 (0.088)   Loss 0.0700 (0.3269)   Prec@1 100.000 (88.184)   Prec@5 100.000 (88.184)   [2018-03-23 09:11:16]
  Epoch: [175][400/505]   Time 0.461 (0.481)   Data 0.071 (0.086)   Loss 0.2604 (0.3091)   Prec@1 87.500 (89.401)   Prec@5 87.500 (89.401)   [2018-03-23 09:12:52]
  **Train** Prec@1 89.401 Prec@5 89.401 Error@1 10.599
  **VAL** Prec@1 96.629 Prec@5 96.629 Error@1 3.371

==>>[2018-03-23 09:14:29] [Epoch=176/250] [Need: 05:32:13] [learning_rate=0.0002] [Best : Accuracy=96.63, Error=3.37]

==>>Epoch=[176/250]], [2018-03-23 09:14:29], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [176][000/505]   Time 0.492 (0.492)   Data 0.082 (0.082)   Loss 0.1628 (0.1628)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-03-23 09:14:29]
  Epoch: [176][200/505]   Time 0.508 (0.484)   Data 0.115 (0.089)   Loss 0.3945 (0.2934)   Prec@1 87.500 (89.925)   Prec@5 87.500 (89.925)   [2018-03-23 09:16:06]
  Epoch: [176][400/505]   Time 0.493 (0.480)   Data 0.103 (0.085)   Loss 0.0353 (0.2905)   Prec@1 100.000 (90.181)   Prec@5 100.000 (90.181)   [2018-03-23 09:17:41]
  **Train** Prec@1 90.045 Prec@5 90.045 Error@1 9.955
  **VAL** Prec@1 96.770 Prec@5 96.770 Error@1 3.230

==>>[2018-03-23 09:19:19] [Epoch=177/250] [Need: 05:27:52] [learning_rate=0.0002] [Best : Accuracy=96.77, Error=3.23]

==>>Epoch=[177/250]], [2018-03-23 09:19:19], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [177][000/505]   Time 0.453 (0.453)   Data 0.047 (0.047)   Loss 1.0163 (1.0163)   Prec@1 75.000 (75.000)   Prec@5 75.000 (75.000)   [2018-03-23 09:19:20]
  Epoch: [177][200/505]   Time 0.495 (0.480)   Data 0.105 (0.085)   Loss 0.2375 (0.2889)   Prec@1 87.500 (90.423)   Prec@5 87.500 (90.423)   [2018-03-23 09:20:56]
  Epoch: [177][400/505]   Time 0.469 (0.481)   Data 0.063 (0.087)   Loss 0.7071 (0.3052)   Prec@1 87.500 (89.931)   Prec@5 87.500 (89.931)   [2018-03-23 09:22:32]
  **Train** Prec@1 90.094 Prec@5 90.094 Error@1 9.906
  **VAL** Prec@1 96.348 Prec@5 96.348 Error@1 3.652

==>>[2018-03-23 09:24:10] [Epoch=178/250] [Need: 05:23:31] [learning_rate=0.0002] [Best : Accuracy=96.77, Error=3.23]

==>>Epoch=[178/250]], [2018-03-23 09:24:10], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [178][000/505]   Time 0.511 (0.511)   Data 0.093 (0.093)   Loss 1.2735 (1.2735)   Prec@1 62.500 (62.500)   Prec@5 62.500 (62.500)   [2018-03-23 09:24:10]
  Epoch: [178][200/505]   Time 0.569 (0.480)   Data 0.172 (0.084)   Loss 0.1517 (0.2898)   Prec@1 100.000 (89.925)   Prec@5 100.000 (89.925)   [2018-03-23 09:25:46]
  Epoch: [178][400/505]   Time 0.495 (0.482)   Data 0.100 (0.087)   Loss 0.0790 (0.2886)   Prec@1 100.000 (90.087)   Prec@5 100.000 (90.087)   [2018-03-23 09:27:23]
  **Train** Prec@1 90.119 Prec@5 90.119 Error@1 9.881
  **VAL** Prec@1 96.348 Prec@5 96.348 Error@1 3.652

==>>[2018-03-23 09:29:00] [Epoch=179/250] [Need: 05:19:10] [learning_rate=0.0002] [Best : Accuracy=96.77, Error=3.23]

==>>Epoch=[179/250]], [2018-03-23 09:29:00], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [179][000/505]   Time 0.472 (0.472)   Data 0.061 (0.061)   Loss 0.0850 (0.0850)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-03-23 09:29:00]
  Epoch: [179][200/505]   Time 0.477 (0.480)   Data 0.084 (0.085)   Loss 0.4831 (0.2954)   Prec@1 87.500 (90.423)   Prec@5 87.500 (90.423)   [2018-03-23 09:30:36]
  Epoch: [179][400/505]   Time 0.429 (0.480)   Data 0.037 (0.085)   Loss 0.3608 (0.2963)   Prec@1 87.500 (90.274)   Prec@5 87.500 (90.274)   [2018-03-23 09:32:12]
  **Train** Prec@1 90.788 Prec@5 90.788 Error@1 9.212
  **VAL** Prec@1 96.489 Prec@5 96.489 Error@1 3.511

==>>[2018-03-23 09:33:50] [Epoch=180/250] [Need: 05:14:48] [learning_rate=0.0002] [Best : Accuracy=96.77, Error=3.23]

==>>Epoch=[180/250]], [2018-03-23 09:33:50], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [180][000/505]   Time 0.460 (0.460)   Data 0.058 (0.058)   Loss 0.0979 (0.0979)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-03-23 09:33:51]
  Epoch: [180][200/505]   Time 0.448 (0.478)   Data 0.056 (0.083)   Loss 0.0720 (0.3050)   Prec@1 100.000 (89.614)   Prec@5 100.000 (89.614)   [2018-03-23 09:35:26]
  Epoch: [180][400/505]   Time 0.492 (0.480)   Data 0.099 (0.086)   Loss 0.3786 (0.2935)   Prec@1 87.500 (90.399)   Prec@5 87.500 (90.399)   [2018-03-23 09:37:03]
  **Train** Prec@1 90.688 Prec@5 90.688 Error@1 9.312
  **VAL** Prec@1 96.208 Prec@5 96.208 Error@1 3.792

==>>[2018-03-23 09:38:41] [Epoch=181/250] [Need: 05:10:26] [learning_rate=0.0002] [Best : Accuracy=96.77, Error=3.23]

==>>Epoch=[181/250]], [2018-03-23 09:38:41], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [181][000/505]   Time 0.437 (0.437)   Data 0.031 (0.031)   Loss 0.1405 (0.1405)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-03-23 09:38:41]
  Epoch: [181][200/505]   Time 0.462 (0.478)   Data 0.071 (0.083)   Loss 0.0364 (0.2713)   Prec@1 100.000 (90.858)   Prec@5 100.000 (90.858)   [2018-03-23 09:40:17]
  Epoch: [181][400/505]   Time 0.472 (0.479)   Data 0.077 (0.084)   Loss 0.4824 (0.2843)   Prec@1 87.500 (90.680)   Prec@5 87.500 (90.680)   [2018-03-23 09:41:53]
  **Train** Prec@1 90.515 Prec@5 90.515 Error@1 9.485
  **VAL** Prec@1 96.208 Prec@5 96.208 Error@1 3.792

==>>[2018-03-23 09:43:31] [Epoch=182/250] [Need: 05:06:04] [learning_rate=0.0002] [Best : Accuracy=96.77, Error=3.23]

==>>Epoch=[182/250]], [2018-03-23 09:43:31], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [182][000/505]   Time 0.442 (0.442)   Data 0.042 (0.042)   Loss 0.3420 (0.3420)   Prec@1 87.500 (87.500)   Prec@5 87.500 (87.500)   [2018-03-23 09:43:31]
  Epoch: [182][200/505]   Time 0.459 (0.478)   Data 0.062 (0.084)   Loss 0.1730 (0.2960)   Prec@1 100.000 (90.734)   Prec@5 100.000 (90.734)   [2018-03-23 09:45:07]
  Epoch: [182][400/505]   Time 0.479 (0.481)   Data 0.085 (0.086)   Loss 0.4972 (0.2857)   Prec@1 75.000 (90.399)   Prec@5 75.000 (90.399)   [2018-03-23 09:46:44]
  **Train** Prec@1 90.738 Prec@5 90.738 Error@1 9.262
  **VAL** Prec@1 96.208 Prec@5 96.208 Error@1 3.792

==>>[2018-03-23 09:48:21] [Epoch=183/250] [Need: 05:01:41] [learning_rate=0.0002] [Best : Accuracy=96.77, Error=3.23]

==>>Epoch=[183/250]], [2018-03-23 09:48:21], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [183][000/505]   Time 0.559 (0.559)   Data 0.125 (0.125)   Loss 0.4982 (0.4982)   Prec@1 87.500 (87.500)   Prec@5 87.500 (87.500)   [2018-03-23 09:48:21]
  Epoch: [183][200/505]   Time 0.453 (0.480)   Data 0.063 (0.085)   Loss 0.8714 (0.3076)   Prec@1 75.000 (90.920)   Prec@5 75.000 (90.920)   [2018-03-23 09:49:57]
  Epoch: [183][400/505]   Time 0.463 (0.480)   Data 0.071 (0.085)   Loss 0.2518 (0.2915)   Prec@1 87.500 (91.022)   Prec@5 87.500 (91.022)   [2018-03-23 09:51:33]
  **Train** Prec@1 91.258 Prec@5 91.258 Error@1 8.742
  **VAL** Prec@1 96.067 Prec@5 96.067 Error@1 3.933

==>>[2018-03-23 09:53:11] [Epoch=184/250] [Need: 04:57:18] [learning_rate=0.0002] [Best : Accuracy=96.77, Error=3.23]

==>>Epoch=[184/250]], [2018-03-23 09:53:11], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [184][000/505]   Time 0.487 (0.487)   Data 0.083 (0.083)   Loss 0.3619 (0.3619)   Prec@1 87.500 (87.500)   Prec@5 87.500 (87.500)   [2018-03-23 09:53:12]
  Epoch: [184][200/505]   Time 0.486 (0.479)   Data 0.099 (0.084)   Loss 0.4119 (0.3061)   Prec@1 62.500 (89.055)   Prec@5 62.500 (89.055)   [2018-03-23 09:54:48]
  Epoch: [184][400/505]   Time 0.465 (0.480)   Data 0.062 (0.086)   Loss 0.1903 (0.3023)   Prec@1 87.500 (89.308)   Prec@5 87.500 (89.308)   [2018-03-23 09:56:24]
  **Train** Prec@1 89.822 Prec@5 89.822 Error@1 10.178
  **VAL** Prec@1 96.770 Prec@5 96.770 Error@1 3.230

==>>[2018-03-23 09:58:01] [Epoch=185/250] [Need: 04:52:55] [learning_rate=0.0002] [Best : Accuracy=96.77, Error=3.23]

==>>Epoch=[185/250]], [2018-03-23 09:58:01], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [185][000/505]   Time 0.482 (0.482)   Data 0.067 (0.067)   Loss 0.0824 (0.0824)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-03-23 09:58:02]
  Epoch: [185][200/505]   Time 0.454 (0.480)   Data 0.063 (0.085)   Loss 0.2108 (0.3060)   Prec@1 100.000 (89.988)   Prec@5 100.000 (89.988)   [2018-03-23 09:59:38]
  Epoch: [185][400/505]   Time 0.470 (0.479)   Data 0.075 (0.085)   Loss 0.6152 (0.2839)   Prec@1 75.000 (90.305)   Prec@5 75.000 (90.305)   [2018-03-23 10:01:14]
  **Train** Prec@1 90.144 Prec@5 90.144 Error@1 9.856
  **VAL** Prec@1 96.910 Prec@5 96.910 Error@1 3.090

==>>[2018-03-23 10:02:52] [Epoch=186/250] [Need: 04:48:31] [learning_rate=0.0002] [Best : Accuracy=96.91, Error=3.09]

==>>Epoch=[186/250]], [2018-03-23 10:02:52], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [186][000/505]   Time 0.531 (0.531)   Data 0.098 (0.098)   Loss 0.1925 (0.1925)   Prec@1 87.500 (87.500)   Prec@5 87.500 (87.500)   [2018-03-23 10:02:52]
  Epoch: [186][200/505]   Time 0.441 (0.486)   Data 0.047 (0.091)   Loss 0.1823 (0.2878)   Prec@1 100.000 (91.107)   Prec@5 100.000 (91.107)   [2018-03-23 10:04:29]
  Epoch: [186][400/505]   Time 0.473 (0.480)   Data 0.082 (0.085)   Loss 0.1005 (0.2781)   Prec@1 87.500 (91.241)   Prec@5 87.500 (91.241)   [2018-03-23 10:06:04]
  **Train** Prec@1 91.555 Prec@5 91.555 Error@1 8.445
  **VAL** Prec@1 96.629 Prec@5 96.629 Error@1 3.371

==>>[2018-03-23 10:07:42] [Epoch=187/250] [Need: 04:44:07] [learning_rate=0.0002] [Best : Accuracy=96.91, Error=3.09]

==>>Epoch=[187/250]], [2018-03-23 10:07:42], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [187][000/505]   Time 0.571 (0.571)   Data 0.148 (0.148)   Loss 0.1430 (0.1430)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-03-23 10:07:43]
  Epoch: [187][200/505]   Time 0.453 (0.475)   Data 0.063 (0.080)   Loss 0.0733 (0.2613)   Prec@1 100.000 (91.853)   Prec@5 100.000 (91.853)   [2018-03-23 10:09:18]
  Epoch: [187][400/505]   Time 0.464 (0.479)   Data 0.068 (0.084)   Loss 0.4718 (0.2713)   Prec@1 87.500 (91.365)   Prec@5 87.500 (91.365)   [2018-03-23 10:10:54]
  **Train** Prec@1 91.109 Prec@5 91.109 Error@1 8.891
  **VAL** Prec@1 96.629 Prec@5 96.629 Error@1 3.371

==>>[2018-03-23 10:12:32] [Epoch=188/250] [Need: 04:39:43] [learning_rate=0.0002] [Best : Accuracy=96.91, Error=3.09]

==>>Epoch=[188/250]], [2018-03-23 10:12:32], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [188][000/505]   Time 0.489 (0.489)   Data 0.075 (0.075)   Loss 0.2823 (0.2823)   Prec@1 87.500 (87.500)   Prec@5 87.500 (87.500)   [2018-03-23 10:12:33]
  Epoch: [188][200/505]   Time 0.534 (0.477)   Data 0.139 (0.083)   Loss 0.4096 (0.2838)   Prec@1 75.000 (90.485)   Prec@5 75.000 (90.485)   [2018-03-23 10:14:08]
  Epoch: [188][400/505]   Time 0.435 (0.479)   Data 0.044 (0.085)   Loss 0.4286 (0.2893)   Prec@1 75.000 (90.617)   Prec@5 75.000 (90.617)   [2018-03-23 10:15:44]
  **Train** Prec@1 90.639 Prec@5 90.639 Error@1 9.361
  **VAL** Prec@1 96.348 Prec@5 96.348 Error@1 3.652

==>>[2018-03-23 10:17:22] [Epoch=189/250] [Need: 04:35:19] [learning_rate=0.0002] [Best : Accuracy=96.91, Error=3.09]

==>>Epoch=[189/250]], [2018-03-23 10:17:22], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [189][000/505]   Time 0.471 (0.471)   Data 0.062 (0.062)   Loss 0.4010 (0.4010)   Prec@1 75.000 (75.000)   Prec@5 75.000 (75.000)   [2018-03-23 10:17:23]
  Epoch: [189][200/505]   Time 0.448 (0.480)   Data 0.049 (0.085)   Loss 0.4009 (0.3048)   Prec@1 75.000 (90.236)   Prec@5 75.000 (90.236)   [2018-03-23 10:18:59]
  Epoch: [189][400/505]   Time 0.488 (0.481)   Data 0.096 (0.086)   Loss 0.8012 (0.2910)   Prec@1 62.500 (90.648)   Prec@5 62.500 (90.648)   [2018-03-23 10:20:35]
  **Train** Prec@1 90.045 Prec@5 90.045 Error@1 9.955
  **VAL** Prec@1 96.208 Prec@5 96.208 Error@1 3.792

==>>[2018-03-23 10:22:13] [Epoch=190/250] [Need: 04:30:54] [learning_rate=0.0002] [Best : Accuracy=96.91, Error=3.09]

==>>Epoch=[190/250]], [2018-03-23 10:22:13], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [190][000/505]   Time 0.487 (0.487)   Data 0.070 (0.070)   Loss 0.0653 (0.0653)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-03-23 10:22:13]
  Epoch: [190][200/505]   Time 0.469 (0.484)   Data 0.078 (0.088)   Loss 0.4700 (0.2826)   Prec@1 75.000 (91.231)   Prec@5 75.000 (91.231)   [2018-03-23 10:23:50]
  Epoch: [190][400/505]   Time 0.602 (0.480)   Data 0.201 (0.086)   Loss 0.2457 (0.2885)   Prec@1 100.000 (90.461)   Prec@5 100.000 (90.461)   [2018-03-23 10:25:25]
  **Train** Prec@1 90.639 Prec@5 90.639 Error@1 9.361
  **VAL** Prec@1 96.629 Prec@5 96.629 Error@1 3.371

==>>[2018-03-23 10:27:03] [Epoch=191/250] [Need: 04:26:29] [learning_rate=0.0002] [Best : Accuracy=96.91, Error=3.09]

==>>Epoch=[191/250]], [2018-03-23 10:27:03], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [191][000/505]   Time 0.494 (0.494)   Data 0.086 (0.086)   Loss 0.1560 (0.1560)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-03-23 10:27:03]
  Epoch: [191][200/505]   Time 0.534 (0.486)   Data 0.142 (0.091)   Loss 0.0382 (0.2666)   Prec@1 100.000 (91.480)   Prec@5 100.000 (91.480)   [2018-03-23 10:28:40]
  Epoch: [191][400/505]   Time 0.483 (0.481)   Data 0.078 (0.086)   Loss 0.4748 (0.2607)   Prec@1 100.000 (91.272)   Prec@5 100.000 (91.272)   [2018-03-23 10:30:16]
  **Train** Prec@1 90.688 Prec@5 90.688 Error@1 9.312
  **VAL** Prec@1 97.051 Prec@5 97.051 Error@1 2.949

==>>[2018-03-23 10:31:53] [Epoch=192/250] [Need: 04:22:04] [learning_rate=0.0002] [Best : Accuracy=97.05, Error=2.95]

==>>Epoch=[192/250]], [2018-03-23 10:31:53], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [192][000/505]   Time 0.472 (0.472)   Data 0.063 (0.063)   Loss 0.4281 (0.4281)   Prec@1 87.500 (87.500)   Prec@5 87.500 (87.500)   [2018-03-23 10:31:53]
  Epoch: [192][200/505]   Time 0.453 (0.482)   Data 0.063 (0.087)   Loss 0.2026 (0.3320)   Prec@1 87.500 (88.619)   Prec@5 87.500 (88.619)   [2018-03-23 10:33:30]
  Epoch: [192][400/505]   Time 0.442 (0.480)   Data 0.063 (0.085)   Loss 0.4253 (0.3043)   Prec@1 87.500 (89.931)   Prec@5 87.500 (89.931)   [2018-03-23 10:35:05]
  **Train** Prec@1 89.871 Prec@5 89.871 Error@1 10.129
  **VAL** Prec@1 97.191 Prec@5 97.191 Error@1 2.809

==>>[2018-03-23 10:36:43] [Epoch=193/250] [Need: 04:17:39] [learning_rate=0.0002] [Best : Accuracy=97.19, Error=2.81]

==>>Epoch=[193/250]], [2018-03-23 10:36:43], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [193][000/505]   Time 0.507 (0.507)   Data 0.080 (0.080)   Loss 0.0477 (0.0477)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-03-23 10:36:44]
  Epoch: [193][200/505]   Time 0.544 (0.476)   Data 0.156 (0.081)   Loss 0.2743 (0.3038)   Prec@1 87.500 (89.925)   Prec@5 87.500 (89.925)   [2018-03-23 10:38:19]
  Epoch: [193][400/505]   Time 0.487 (0.479)   Data 0.094 (0.084)   Loss 0.1005 (0.2920)   Prec@1 100.000 (89.963)   Prec@5 100.000 (89.963)   [2018-03-23 10:39:55]
  **Train** Prec@1 89.995 Prec@5 89.995 Error@1 10.005
  **VAL** Prec@1 96.629 Prec@5 96.629 Error@1 3.371

==>>[2018-03-23 10:41:33] [Epoch=194/250] [Need: 04:13:13] [learning_rate=0.0002] [Best : Accuracy=97.19, Error=2.81]

==>>Epoch=[194/250]], [2018-03-23 10:41:33], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [194][000/505]   Time 0.455 (0.455)   Data 0.052 (0.052)   Loss 0.1645 (0.1645)   Prec@1 87.500 (87.500)   Prec@5 87.500 (87.500)   [2018-03-23 10:41:34]
  Epoch: [194][200/505]   Time 0.445 (0.478)   Data 0.053 (0.083)   Loss 0.4039 (0.3031)   Prec@1 75.000 (89.801)   Prec@5 75.000 (89.801)   [2018-03-23 10:43:09]
  Epoch: [194][400/505]   Time 0.501 (0.481)   Data 0.114 (0.087)   Loss 0.0560 (0.2895)   Prec@1 100.000 (90.087)   Prec@5 100.000 (90.087)   [2018-03-23 10:44:46]
  **Train** Prec@1 90.515 Prec@5 90.515 Error@1 9.485
  **VAL** Prec@1 96.770 Prec@5 96.770 Error@1 3.230

==>>[2018-03-23 10:46:23] [Epoch=195/250] [Need: 04:08:47] [learning_rate=0.0002] [Best : Accuracy=97.19, Error=2.81]

==>>Epoch=[195/250]], [2018-03-23 10:46:23], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [195][000/505]   Time 0.481 (0.481)   Data 0.063 (0.063)   Loss 0.3544 (0.3544)   Prec@1 87.500 (87.500)   Prec@5 87.500 (87.500)   [2018-03-23 10:46:24]
  Epoch: [195][200/505]   Time 0.824 (0.484)   Data 0.428 (0.089)   Loss 0.5851 (0.2919)   Prec@1 75.000 (90.423)   Prec@5 75.000 (90.423)   [2018-03-23 10:48:01]
  Epoch: [195][400/505]   Time 0.445 (0.482)   Data 0.054 (0.087)   Loss 0.2775 (0.3015)   Prec@1 87.500 (89.869)   Prec@5 87.500 (89.869)   [2018-03-23 10:49:37]
  **Train** Prec@1 89.723 Prec@5 89.723 Error@1 10.277
  **VAL** Prec@1 96.910 Prec@5 96.910 Error@1 3.090

==>>[2018-03-23 10:51:14] [Epoch=196/250] [Need: 04:04:21] [learning_rate=0.0002] [Best : Accuracy=97.19, Error=2.81]

==>>Epoch=[196/250]], [2018-03-23 10:51:14], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [196][000/505]   Time 0.489 (0.489)   Data 0.078 (0.078)   Loss 0.3555 (0.3555)   Prec@1 87.500 (87.500)   Prec@5 87.500 (87.500)   [2018-03-23 10:51:14]
  Epoch: [196][200/505]   Time 0.531 (0.477)   Data 0.125 (0.082)   Loss 0.4870 (0.3129)   Prec@1 75.000 (89.428)   Prec@5 75.000 (89.428)   [2018-03-23 10:52:50]
  Epoch: [196][400/505]   Time 0.501 (0.479)   Data 0.109 (0.084)   Loss 0.3044 (0.3040)   Prec@1 87.500 (90.274)   Prec@5 87.500 (90.274)   [2018-03-23 10:54:26]
  **Train** Prec@1 90.540 Prec@5 90.540 Error@1 9.460
  **VAL** Prec@1 96.910 Prec@5 96.910 Error@1 3.090

==>>[2018-03-23 10:56:04] [Epoch=197/250] [Need: 03:59:54] [learning_rate=0.0002] [Best : Accuracy=97.19, Error=2.81]

==>>Epoch=[197/250]], [2018-03-23 10:56:04], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [197][000/505]   Time 0.455 (0.455)   Data 0.054 (0.054)   Loss 0.6139 (0.6139)   Prec@1 75.000 (75.000)   Prec@5 75.000 (75.000)   [2018-03-23 10:56:05]
  Epoch: [197][200/505]   Time 0.457 (0.480)   Data 0.078 (0.085)   Loss 0.1453 (0.2672)   Prec@1 100.000 (90.983)   Prec@5 100.000 (90.983)   [2018-03-23 10:57:41]
  Epoch: [197][400/505]   Time 0.495 (0.481)   Data 0.098 (0.086)   Loss 0.1919 (0.2625)   Prec@1 87.500 (91.521)   Prec@5 87.500 (91.521)   [2018-03-23 10:59:17]
  **Train** Prec@1 91.283 Prec@5 91.283 Error@1 8.717
  **VAL** Prec@1 96.910 Prec@5 96.910 Error@1 3.090

==>>[2018-03-23 11:00:55] [Epoch=198/250] [Need: 03:55:28] [learning_rate=0.0002] [Best : Accuracy=97.19, Error=2.81]

==>>Epoch=[198/250]], [2018-03-23 11:00:55], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [198][000/505]   Time 0.497 (0.497)   Data 0.086 (0.086)   Loss 0.1426 (0.1426)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-03-23 11:00:55]
  Epoch: [198][200/505]   Time 0.424 (0.479)   Data 0.033 (0.084)   Loss 0.7024 (0.2841)   Prec@1 75.000 (90.858)   Prec@5 75.000 (90.858)   [2018-03-23 11:02:31]
  Epoch: [198][400/505]   Time 0.451 (0.479)   Data 0.057 (0.085)   Loss 0.3867 (0.2771)   Prec@1 87.500 (91.272)   Prec@5 87.500 (91.272)   [2018-03-23 11:04:07]
  **Train** Prec@1 91.308 Prec@5 91.308 Error@1 8.692
  **VAL** Prec@1 96.348 Prec@5 96.348 Error@1 3.652

==>>[2018-03-23 11:05:45] [Epoch=199/250] [Need: 03:51:01] [learning_rate=0.0002] [Best : Accuracy=97.19, Error=2.81]

==>>Epoch=[199/250]], [2018-03-23 11:05:45], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [199][000/505]   Time 0.500 (0.500)   Data 0.078 (0.078)   Loss 0.1990 (0.1990)   Prec@1 87.500 (87.500)   Prec@5 87.500 (87.500)   [2018-03-23 11:05:45]
  Epoch: [199][200/505]   Time 0.494 (0.481)   Data 0.103 (0.086)   Loss 0.0547 (0.2784)   Prec@1 100.000 (90.299)   Prec@5 100.000 (90.299)   [2018-03-23 11:07:22]
  Epoch: [199][400/505]   Time 0.437 (0.480)   Data 0.047 (0.085)   Loss 0.6756 (0.2825)   Prec@1 87.500 (90.835)   Prec@5 87.500 (90.835)   [2018-03-23 11:08:58]
  **Train** Prec@1 90.837 Prec@5 90.837 Error@1 9.163
  **VAL** Prec@1 96.489 Prec@5 96.489 Error@1 3.511

==>>[2018-03-23 11:10:35] [Epoch=200/250] [Need: 03:46:33] [learning_rate=0.0002] [Best : Accuracy=97.19, Error=2.81]

==>>Epoch=[200/250]], [2018-03-23 11:10:35], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [200][000/505]   Time 0.502 (0.502)   Data 0.075 (0.075)   Loss 0.0882 (0.0882)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-03-23 11:10:36]
  Epoch: [200][200/505]   Time 0.472 (0.477)   Data 0.070 (0.082)   Loss 0.4039 (0.2918)   Prec@1 75.000 (89.988)   Prec@5 75.000 (89.988)   [2018-03-23 11:12:11]
  Epoch: [200][400/505]   Time 0.469 (0.480)   Data 0.078 (0.085)   Loss 0.4553 (0.2882)   Prec@1 87.500 (90.150)   Prec@5 87.500 (90.150)   [2018-03-23 11:13:48]
  **Train** Prec@1 90.317 Prec@5 90.317 Error@1 9.683
  **VAL** Prec@1 96.629 Prec@5 96.629 Error@1 3.371

==>>[2018-03-23 11:15:25] [Epoch=201/250] [Need: 03:42:06] [learning_rate=0.0002] [Best : Accuracy=97.19, Error=2.81]

==>>Epoch=[201/250]], [2018-03-23 11:15:25], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [201][000/505]   Time 0.464 (0.464)   Data 0.056 (0.056)   Loss 0.1087 (0.1087)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-03-23 11:15:26]
  Epoch: [201][200/505]   Time 0.494 (0.480)   Data 0.101 (0.085)   Loss 0.3041 (0.2693)   Prec@1 87.500 (90.858)   Prec@5 87.500 (90.858)   [2018-03-23 11:17:02]
  Epoch: [201][400/505]   Time 0.442 (0.480)   Data 0.045 (0.085)   Loss 0.0865 (0.2701)   Prec@1 100.000 (90.804)   Prec@5 100.000 (90.804)   [2018-03-23 11:18:38]
  **Train** Prec@1 90.862 Prec@5 90.862 Error@1 9.138
  **VAL** Prec@1 96.208 Prec@5 96.208 Error@1 3.792

==>>[2018-03-23 11:20:16] [Epoch=202/250] [Need: 03:37:38] [learning_rate=0.0002] [Best : Accuracy=97.19, Error=2.81]

==>>Epoch=[202/250]], [2018-03-23 11:20:16], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [202][000/505]   Time 0.536 (0.536)   Data 0.098 (0.098)   Loss 0.0546 (0.0546)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-03-23 11:20:16]
  Epoch: [202][200/505]   Time 0.456 (0.478)   Data 0.063 (0.083)   Loss 0.1321 (0.2970)   Prec@1 100.000 (89.677)   Prec@5 100.000 (89.677)   [2018-03-23 11:21:52]
  Epoch: [202][400/505]   Time 0.469 (0.481)   Data 0.078 (0.086)   Loss 0.0633 (0.2764)   Prec@1 100.000 (90.555)   Prec@5 100.000 (90.555)   [2018-03-23 11:23:29]
  **Train** Prec@1 90.267 Prec@5 90.267 Error@1 9.733
  **VAL** Prec@1 96.489 Prec@5 96.489 Error@1 3.511

==>>[2018-03-23 11:25:06] [Epoch=203/250] [Need: 03:33:11] [learning_rate=0.0002] [Best : Accuracy=97.19, Error=2.81]

==>>Epoch=[203/250]], [2018-03-23 11:25:06], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [203][000/505]   Time 0.513 (0.513)   Data 0.099 (0.099)   Loss 0.0399 (0.0399)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-03-23 11:25:06]
  Epoch: [203][200/505]   Time 0.442 (0.479)   Data 0.050 (0.084)   Loss 0.1058 (0.2707)   Prec@1 100.000 (91.978)   Prec@5 100.000 (91.978)   [2018-03-23 11:26:42]
  Epoch: [203][400/505]   Time 0.489 (0.480)   Data 0.094 (0.085)   Loss 0.1430 (0.2705)   Prec@1 100.000 (91.584)   Prec@5 100.000 (91.584)   [2018-03-23 11:28:18]
  **Train** Prec@1 91.580 Prec@5 91.580 Error@1 8.420
  **VAL** Prec@1 96.770 Prec@5 96.770 Error@1 3.230

==>>[2018-03-23 11:29:56] [Epoch=204/250] [Need: 03:28:42] [learning_rate=0.0002] [Best : Accuracy=97.19, Error=2.81]

==>>Epoch=[204/250]], [2018-03-23 11:29:56], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [204][000/505]   Time 0.472 (0.472)   Data 0.063 (0.063)   Loss 0.1883 (0.1883)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-03-23 11:29:56]
  Epoch: [204][200/505]   Time 0.463 (0.485)   Data 0.070 (0.089)   Loss 0.0545 (0.2545)   Prec@1 100.000 (92.040)   Prec@5 100.000 (92.040)   [2018-03-23 11:31:33]
  Epoch: [204][400/505]   Time 0.453 (0.480)   Data 0.063 (0.085)   Loss 0.0854 (0.2747)   Prec@1 100.000 (90.867)   Prec@5 100.000 (90.867)   [2018-03-23 11:33:08]
  **Train** Prec@1 90.961 Prec@5 90.961 Error@1 9.039
  **VAL** Prec@1 96.067 Prec@5 96.067 Error@1 3.933

==>>[2018-03-23 11:34:46] [Epoch=205/250] [Need: 03:24:14] [learning_rate=0.0002] [Best : Accuracy=97.19, Error=2.81]

==>>Epoch=[205/250]], [2018-03-23 11:34:46], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [205][000/505]   Time 0.479 (0.479)   Data 0.071 (0.071)   Loss 0.0919 (0.0919)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-03-23 11:34:47]
  Epoch: [205][200/505]   Time 0.438 (0.481)   Data 0.047 (0.087)   Loss 0.1013 (0.2780)   Prec@1 100.000 (90.609)   Prec@5 100.000 (90.609)   [2018-03-23 11:36:23]
  Epoch: [205][400/505]   Time 0.501 (0.480)   Data 0.109 (0.086)   Loss 0.3282 (0.2714)   Prec@1 87.500 (90.929)   Prec@5 87.500 (90.929)   [2018-03-23 11:37:59]
  **Train** Prec@1 90.738 Prec@5 90.738 Error@1 9.262
  **VAL** Prec@1 96.629 Prec@5 96.629 Error@1 3.371

==>>[2018-03-23 11:39:37] [Epoch=206/250] [Need: 03:19:46] [learning_rate=0.0002] [Best : Accuracy=97.19, Error=2.81]

==>>Epoch=[206/250]], [2018-03-23 11:39:37], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [206][000/505]   Time 0.461 (0.461)   Data 0.061 (0.061)   Loss 0.2017 (0.2017)   Prec@1 87.500 (87.500)   Prec@5 87.500 (87.500)   [2018-03-23 11:39:37]
  Epoch: [206][200/505]   Time 0.462 (0.482)   Data 0.063 (0.086)   Loss 0.2678 (0.2808)   Prec@1 87.500 (90.609)   Prec@5 87.500 (90.609)   [2018-03-23 11:41:14]
  Epoch: [206][400/505]   Time 0.427 (0.480)   Data 0.036 (0.085)   Loss 0.2364 (0.2970)   Prec@1 87.500 (89.869)   Prec@5 87.500 (89.869)   [2018-03-23 11:42:49]
  **Train** Prec@1 90.342 Prec@5 90.342 Error@1 9.658
  **VAL** Prec@1 96.067 Prec@5 96.067 Error@1 3.933

==>>[2018-03-23 11:44:27] [Epoch=207/250] [Need: 03:15:17] [learning_rate=0.0002] [Best : Accuracy=97.19, Error=2.81]

==>>Epoch=[207/250]], [2018-03-23 11:44:27], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [207][000/505]   Time 0.479 (0.479)   Data 0.067 (0.067)   Loss 0.4176 (0.4176)   Prec@1 75.000 (75.000)   Prec@5 75.000 (75.000)   [2018-03-23 11:44:27]
  Epoch: [207][200/505]   Time 0.501 (0.479)   Data 0.108 (0.084)   Loss 0.5727 (0.3006)   Prec@1 75.000 (89.925)   Prec@5 75.000 (89.925)   [2018-03-23 11:46:03]
  Epoch: [207][400/505]   Time 0.494 (0.481)   Data 0.094 (0.086)   Loss 0.0095 (0.2965)   Prec@1 100.000 (90.150)   Prec@5 100.000 (90.150)   [2018-03-23 11:47:40]
  **Train** Prec@1 90.490 Prec@5 90.490 Error@1 9.510
  **VAL** Prec@1 96.629 Prec@5 96.629 Error@1 3.371

==>>[2018-03-23 11:49:17] [Epoch=208/250] [Need: 03:10:48] [learning_rate=0.0002] [Best : Accuracy=97.19, Error=2.81]

==>>Epoch=[208/250]], [2018-03-23 11:49:17], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [208][000/505]   Time 0.463 (0.463)   Data 0.058 (0.058)   Loss 0.1678 (0.1678)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-03-23 11:49:18]
  Epoch: [208][200/505]   Time 0.453 (0.483)   Data 0.068 (0.088)   Loss 0.1004 (0.2565)   Prec@1 100.000 (91.542)   Prec@5 100.000 (91.542)   [2018-03-23 11:50:54]
  Epoch: [208][400/505]   Time 0.464 (0.479)   Data 0.071 (0.085)   Loss 0.0517 (0.2624)   Prec@1 100.000 (91.428)   Prec@5 100.000 (91.428)   [2018-03-23 11:52:30]
  **Train** Prec@1 91.555 Prec@5 91.555 Error@1 8.445
  **VAL** Prec@1 96.208 Prec@5 96.208 Error@1 3.792

==>>[2018-03-23 11:54:08] [Epoch=209/250] [Need: 03:06:19] [learning_rate=0.0002] [Best : Accuracy=97.19, Error=2.81]

==>>Epoch=[209/250]], [2018-03-23 11:54:08], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [209][000/505]   Time 0.442 (0.442)   Data 0.038 (0.038)   Loss 0.6762 (0.6762)   Prec@1 87.500 (87.500)   Prec@5 87.500 (87.500)   [2018-03-23 11:54:08]
  Epoch: [209][200/505]   Time 0.468 (0.480)   Data 0.075 (0.085)   Loss 0.5971 (0.2784)   Prec@1 75.000 (90.547)   Prec@5 75.000 (90.547)   [2018-03-23 11:55:44]
  Epoch: [209][400/505]   Time 0.487 (0.480)   Data 0.096 (0.085)   Loss 0.1865 (0.2702)   Prec@1 87.500 (91.272)   Prec@5 87.500 (91.272)   [2018-03-23 11:57:20]
  **Train** Prec@1 90.986 Prec@5 90.986 Error@1 9.014
  **VAL** Prec@1 96.770 Prec@5 96.770 Error@1 3.230

==>>[2018-03-23 11:58:58] [Epoch=210/250] [Need: 03:01:50] [learning_rate=0.0002] [Best : Accuracy=97.19, Error=2.81]

==>>Epoch=[210/250]], [2018-03-23 11:58:58], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [210][000/505]   Time 0.466 (0.466)   Data 0.064 (0.064)   Loss 0.1774 (0.1774)   Prec@1 87.500 (87.500)   Prec@5 87.500 (87.500)   [2018-03-23 11:58:59]
  Epoch: [210][200/505]   Time 0.523 (0.485)   Data 0.107 (0.088)   Loss 0.3817 (0.2707)   Prec@1 75.000 (90.112)   Prec@5 75.000 (90.112)   [2018-03-23 12:00:36]
  Epoch: [210][400/505]   Time 0.472 (0.494)   Data 0.086 (0.087)   Loss 0.1027 (0.2732)   Prec@1 100.000 (90.617)   Prec@5 100.000 (90.617)   [2018-03-23 12:02:16]
  **Train** Prec@1 90.614 Prec@5 90.614 Error@1 9.386
  **VAL** Prec@1 96.629 Prec@5 96.629 Error@1 3.371

==>>[2018-03-23 12:03:54] [Epoch=211/250] [Need: 02:57:21] [learning_rate=0.0002] [Best : Accuracy=97.19, Error=2.81]

==>>Epoch=[211/250]], [2018-03-23 12:03:54], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [211][000/505]   Time 0.450 (0.450)   Data 0.058 (0.058)   Loss 0.1122 (0.1122)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-03-23 12:03:54]
  Epoch: [211][200/505]   Time 0.459 (0.482)   Data 0.064 (0.087)   Loss 0.0607 (0.2873)   Prec@1 100.000 (90.734)   Prec@5 100.000 (90.734)   [2018-03-23 12:05:31]
  Epoch: [211][400/505]   Time 0.450 (0.480)   Data 0.056 (0.085)   Loss 1.0008 (0.2923)   Prec@1 87.500 (90.524)   Prec@5 87.500 (90.524)   [2018-03-23 12:07:06]
  **Train** Prec@1 90.664 Prec@5 90.664 Error@1 9.336
  **VAL** Prec@1 96.208 Prec@5 96.208 Error@1 3.792

==>>[2018-03-23 12:08:44] [Epoch=212/250] [Need: 02:52:51] [learning_rate=0.0002] [Best : Accuracy=97.19, Error=2.81]

==>>Epoch=[212/250]], [2018-03-23 12:08:44], LR=[0.002], Batch=[8] [Model=IceResNet]
  Epoch: [212][000/505]   Time 0.558 (0.558)   Data 0.157 (0.157)   Loss 0.0907 (0.0907)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-03-23 12:08:45]
  Epoch: [212][200/505]   Time 0.475 (0.481)   Data 0.084 (0.086)   Loss 0.0468 (0.3164)   Prec@1 100.000 (89.428)   Prec@5 100.000 (89.428)   [2018-03-23 12:10:21]
  Epoch: [212][400/505]   Time 0.477 (0.479)   Data 0.084 (0.084)   Loss 0.2227 (0.2890)   Prec@1 100.000 (90.430)   Prec@5 100.000 (90.430)   [2018-03-23 12:11:56]
  **Train** Prec@1 90.466 Prec@5 90.466 Error@1 9.534
  **VAL** Prec@1 96.208 Prec@5 96.208 Error@1 3.792
